{
  "version": 3,
  "sources": ["../../.pnpm/@livestore+common@0.3.1_505c75a1204e4cf21acbbd6b3e225a6b/node_modules/@livestore/common/src/leader-thread/connection.ts", "../../.pnpm/@livestore+common@0.3.1_505c75a1204e4cf21acbbd6b3e225a6b/node_modules/@livestore/common/src/leader-thread/types.ts", "../../.pnpm/@livestore+common@0.3.1_505c75a1204e4cf21acbbd6b3e225a6b/node_modules/@livestore/common/src/leader-thread/eventlog.ts", "../../.pnpm/@livestore+common@0.3.1_505c75a1204e4cf21acbbd6b3e225a6b/node_modules/@livestore/common/src/sql-queries/misc.ts", "../../.pnpm/@livestore+common@0.3.1_505c75a1204e4cf21acbbd6b3e225a6b/node_modules/@livestore/common/src/sql-queries/types.ts", "../../.pnpm/@livestore+common@0.3.1_505c75a1204e4cf21acbbd6b3e225a6b/node_modules/@livestore/common/src/sql-queries/sql-queries.ts", "../../.pnpm/@livestore+common@0.3.1_505c75a1204e4cf21acbbd6b3e225a6b/node_modules/@livestore/common/src/leader-thread/leader-worker-devtools.ts", "../../.pnpm/@livestore+common@0.3.1_505c75a1204e4cf21acbbd6b3e225a6b/node_modules/@livestore/common/src/leader-thread/materialize-event.ts", "../../.pnpm/@livestore+common@0.3.1_505c75a1204e4cf21acbbd6b3e225a6b/node_modules/@livestore/common/src/leader-thread/LeaderSyncProcessor.ts", "../../.pnpm/@livestore+common@0.3.1_505c75a1204e4cf21acbbd6b3e225a6b/node_modules/@livestore/common/src/leader-thread/recreate-db.ts", "../../.pnpm/@livestore+common@0.3.1_505c75a1204e4cf21acbbd6b3e225a6b/node_modules/@livestore/common/src/leader-thread/make-leader-thread-layer.ts", "../../.pnpm/@livestore+common@0.3.1_505c75a1204e4cf21acbbd6b3e225a6b/node_modules/@livestore/common/src/leader-thread/shutdown-channel.ts", "../../.pnpm/@livestore+devtools-web-common@0.3.1_a2602a20d83ff4e94e4a35c6aa299805/node_modules/@livestore/devtools-web-common/src/worker/schema.ts", "../../.pnpm/@livestore+devtools-web-common@0.3.1_a2602a20d83ff4e94e4a35c6aa299805/node_modules/@livestore/devtools-web-common/src/worker/mod.ts", "../../.pnpm/@livestore+sqlite-wasm@0.3.1_a2602a20d83ff4e94e4a35c6aa299805/node_modules/@livestore/sqlite-wasm/src/in-memory-vfs.ts", "../../.pnpm/@livestore+sqlite-wasm@0.3.1_a2602a20d83ff4e94e4a35c6aa299805/node_modules/@livestore/sqlite-wasm/src/make-sqlite-db.ts", "../../.pnpm/@livestore+sqlite-wasm@0.3.1_a2602a20d83ff4e94e4a35c6aa299805/node_modules/@livestore/sqlite-wasm/src/browser/opfs/AccessHandlePoolVFS.ts", "../../.pnpm/@livestore+sqlite-wasm@0.3.1_a2602a20d83ff4e94e4a35c6aa299805/node_modules/@livestore/sqlite-wasm/src/FacadeVFS.ts", "../../.pnpm/@livestore+sqlite-wasm@0.3.1_a2602a20d83ff4e94e4a35c6aa299805/node_modules/@livestore/sqlite-wasm/src/browser/opfs/index.ts", "../../.pnpm/@livestore+sqlite-wasm@0.3.1_a2602a20d83ff4e94e4a35c6aa299805/node_modules/@livestore/sqlite-wasm/src/browser/opfs/opfs-sah-pool.ts", "../../.pnpm/@livestore+sqlite-wasm@0.3.1_a2602a20d83ff4e94e4a35c6aa299805/node_modules/@livestore/sqlite-wasm/src/browser/mod.ts", "../../.pnpm/@livestore+sqlite-wasm@0.3.1_a2602a20d83ff4e94e4a35c6aa299805/node_modules/@livestore/sqlite-wasm/src/load-wasm/mod.browser.ts", "../../.pnpm/@livestore+adapter-web@0.3.1_505c75a1204e4cf21acbbd6b3e225a6b/node_modules/@livestore/adapter-web/src/opfs-utils.ts", "../../.pnpm/@livestore+adapter-web@0.3.1_505c75a1204e4cf21acbbd6b3e225a6b/node_modules/@livestore/adapter-web/src/web-worker/common/persisted-sqlite.ts", "../../.pnpm/@livestore+adapter-web@0.3.1_505c75a1204e4cf21acbbd6b3e225a6b/node_modules/@livestore/adapter-web/src/web-worker/common/shutdown-channel.ts", "../../.pnpm/@livestore+adapter-web@0.3.1_505c75a1204e4cf21acbbd6b3e225a6b/node_modules/@livestore/adapter-web/src/web-worker/common/worker-schema.ts"],
  "sourcesContent": ["// import type { WaSqlite } from '@livestore/sqlite-wasm'\nimport { Effect } from '@livestore/utils/effect'\n\nimport type { SqliteDb } from '../adapter-types.js'\nimport { SqliteError } from '../adapter-types.js'\nimport type { BindValues } from '../sql-queries/index.js'\nimport type { PreparedBindValues } from '../util.js'\nimport { prepareBindValues, sql } from '../util.js'\n\n// TODO\nnamespace WaSqlite {\n  export type SQLiteError = any\n}\n\ntype ConnectionOptions = {\n  /**\n   * The database connection locking mode.\n   *\n   * @remarks\n   *\n   * This **option is ignored** when used on an **in-memory database** as they can only operate in exclusive locking mode.\n   * In-memory databases can’t share state between connections (unless using a\n   * {@link https://www.sqlite.org/sharedcache.html#shared_cache_and_in_memory_databases|shared cache}),\n   * making concurrent access impossible. This is functionally equivalent to exclusive locking.\n   *\n   * @defaultValue\n   * The default is `\"NORMAL\"` unless it was unless overridden at compile-time using `SQLITE_DEFAULT_LOCKING_MODE`.\n   *\n   * @see {@link https://www.sqlite.org/pragma.html#pragma_locking_mode|`locking_mode` pragma}\n   */\n  lockingMode?: 'NORMAL' | 'EXCLUSIVE'\n\n  /**\n   * Whether to enforce foreign key constraints.\n   *\n   * @privateRemarks\n   *\n   * We require a value for this option to minimize future problems, as the default value might change in future\n   * versions of SQLite.\n   *\n   * @see {@link https://www.sqlite.org/pragma.html#pragma_foreign_keys|`foreign_keys` pragma}\n   */\n  foreignKeys: boolean\n}\n\nexport const configureConnection = (sqliteDb: SqliteDb, { foreignKeys, lockingMode }: ConnectionOptions) =>\n  execSql(\n    sqliteDb,\n    // We use the WAL journal mode is significantly faster in most scenarios than the traditional rollback journal mode.\n    // It specifically significantly improves write performance. However, when using the WAL journal mode, transactions\n    // that involve changes against multiple ATTACHed databases are atomic for each database but are not atomic\n    // across all databases as a set. Additionally, it is not possible to change the page size after entering WAL mode,\n    // whether on an empty database or by using VACUUM or the backup API. To change the page size, we must switch to the\n    // rollback journal mode.\n    //\n    // When connected to an in-memory database, the WAL journal mode option is ignored because an in-memory database can\n    // only be in either the MEMORY or OFF options. By default, an in-memory database is in the MEMORY option, which\n    // means that it stores the rollback journal in volatile RAM. This saves disk I/O but at the expense of safety and\n    // integrity. If the thread using SQLite crashes in the middle of a transaction, then the database file will very\n    // likely go corrupt.\n    sql`\n    -- disable WAL until we have it working properly\n    -- PRAGMA journal_mode=WAL;\n    PRAGMA page_size=8192;\n    PRAGMA foreign_keys=${foreignKeys ? 'ON' : 'OFF'};\n    ${lockingMode === undefined ? '' : sql`PRAGMA locking_mode=${lockingMode};`}\n  `,\n    {},\n  )\n\nexport const execSql = (sqliteDb: SqliteDb, sql: string, bind: BindValues) => {\n  const bindValues = prepareBindValues(bind, sql)\n  return Effect.try({\n    try: () => sqliteDb.execute(sql, bindValues),\n    catch: (cause) =>\n      new SqliteError({ cause, query: { bindValues, sql }, code: (cause as WaSqlite.SQLiteError).code }),\n  }).pipe(\n    Effect.asVoid,\n    // Effect.logDuration(`@livestore/common:execSql:${sql}`),\n    Effect.withSpan(`@livestore/common:execSql`, {\n      attributes: { 'span.label': sql, sql, bindValueKeys: Object.keys(bindValues) },\n    }),\n  )\n}\n\n// const selectSqlPrepared = <T>(stmt: PreparedStatement, bind: BindValues) => {\n//   const bindValues = prepareBindValues(bind, stmt.sql)\n//   return Effect.try({\n//     try: () => stmt.select<T>(bindValues),\n//     catch: (cause) =>\n//       new SqliteError({ cause, query: { bindValues, sql: stmt.sql }, code: (cause as WaSqlite.SQLiteError).code }),\n//   })\n// }\n\n// TODO actually use prepared statements\nexport const execSqlPrepared = (sqliteDb: SqliteDb, sql: string, bindValues: PreparedBindValues) => {\n  return Effect.try({\n    try: () => sqliteDb.execute(sql, bindValues),\n    catch: (cause) =>\n      new SqliteError({ cause, query: { bindValues, sql }, code: (cause as WaSqlite.SQLiteError).code }),\n  }).pipe(\n    Effect.asVoid,\n    // Effect.logDuration(`@livestore/common:execSqlPrepared:${sql}`),\n    Effect.withSpan(`@livestore/common:execSqlPrepared`, {\n      attributes: {\n        'span.label': sql,\n        sql,\n        bindValueKeys: Object.keys(bindValues),\n      },\n    }),\n  )\n}\n", "import type {\n  Deferred,\n  Effect,\n  HttpClient,\n  Option,\n  Queue,\n  Scope,\n  Stream,\n  Subscribable,\n  SubscriptionRef,\n} from '@livestore/utils/effect'\nimport { Context, Schema } from '@livestore/utils/effect'\nimport type { MeshNode } from '@livestore/webmesh'\n\nimport type { LeaderPullCursor, SqliteError } from '../adapter-types.js'\nimport type {\n  BootStatus,\n  Devtools,\n  LeaderAheadError,\n  MakeSqliteDb,\n  MigrationsReport,\n  PersistenceInfo,\n  SqliteDb,\n  SyncBackend,\n  UnexpectedError,\n} from '../index.js'\nimport type { EventSequenceNumber, LiveStoreEvent, LiveStoreSchema } from '../schema/mod.js'\nimport type * as SyncState from '../sync/syncstate.js'\nimport type { ShutdownChannel } from './shutdown-channel.js'\n\nexport type ShutdownState = 'running' | 'shutting-down'\n\nexport const InitialSyncOptionsSkip = Schema.TaggedStruct('Skip', {})\nexport type InitialSyncOptionsSkip = typeof InitialSyncOptionsSkip.Type\n\nexport const InitialSyncOptionsBlocking = Schema.TaggedStruct('Blocking', {\n  timeout: Schema.Union(Schema.DurationFromMillis, Schema.Number),\n})\n\nexport type InitialSyncOptionsBlocking = typeof InitialSyncOptionsBlocking.Type\n\nexport const InitialSyncOptions = Schema.Union(InitialSyncOptionsSkip, InitialSyncOptionsBlocking)\nexport type InitialSyncOptions = typeof InitialSyncOptions.Type\n\nexport type InitialSyncInfo = Option.Option<{\n  cursor: EventSequenceNumber.EventSequenceNumber\n  metadata: Option.Option<Schema.JsonValue>\n}>\n\n// export type InitialSetup =\n//   | { _tag: 'Recreate'; snapshotRef: Ref.Ref<Uint8Array | undefined>; syncInfo: InitialSyncInfo }\n//   | { _tag: 'Reuse'; syncInfo: InitialSyncInfo }\n\nexport type LeaderSqliteDb = SqliteDb<{ dbPointer: number; persistenceInfo: PersistenceInfo }>\nexport type PersistenceInfoPair = { state: PersistenceInfo; eventlog: PersistenceInfo }\n\nexport type DevtoolsOptions =\n  | {\n      enabled: false\n    }\n  | {\n      enabled: true\n      boot: Effect.Effect<\n        {\n          node: MeshNode\n          persistenceInfo: PersistenceInfoPair\n          mode: 'proxy' | 'direct'\n        },\n        UnexpectedError,\n        Scope.Scope | HttpClient.HttpClient | LeaderThreadCtx\n      >\n    }\n\nexport type DevtoolsContext =\n  | {\n      enabled: true\n      // syncBackendPullLatch: Effect.Latch\n      // syncBackendPushLatch: Effect.Latch\n      syncBackendLatch: Effect.Latch\n      syncBackendLatchState: SubscriptionRef.SubscriptionRef<{ latchClosed: boolean }>\n    }\n  | {\n      enabled: false\n    }\n\nexport class LeaderThreadCtx extends Context.Tag('LeaderThreadCtx')<\n  LeaderThreadCtx,\n  {\n    schema: LiveStoreSchema\n    storeId: string\n    clientId: string\n    makeSqliteDb: MakeSqliteDb\n    dbState: LeaderSqliteDb\n    dbEventlog: LeaderSqliteDb\n    bootStatusQueue: Queue.Queue<BootStatus>\n    // TODO we should find a more elegant way to handle cases which need this ref for their implementation\n    shutdownStateSubRef: SubscriptionRef.SubscriptionRef<ShutdownState>\n    shutdownChannel: ShutdownChannel\n    eventSchema: LiveStoreEvent.ForEventDefRecord<any>\n    devtools: DevtoolsContext\n    syncBackend: SyncBackend | undefined\n    syncProcessor: LeaderSyncProcessor\n    materializeEvent: MaterializeEvent\n    initialState: {\n      leaderHead: EventSequenceNumber.EventSequenceNumber\n      migrationsReport: MigrationsReport\n    }\n    /**\n     * e.g. used for `store._dev` APIs\n     *\n     * This is currently separated from `.devtools` as it also needs to work when devtools are disabled\n     */\n    extraIncomingMessagesQueue: Queue.Queue<Devtools.Leader.MessageToApp>\n  }\n>() {}\n\nexport type MaterializeEvent = (\n  eventEncoded: LiveStoreEvent.EncodedWithMeta,\n  options?: {\n    /** Needed for rematerializeFromEventlog */\n    skipEventlog?: boolean\n  },\n) => Effect.Effect<\n  {\n    sessionChangeset: { _tag: 'sessionChangeset'; data: Uint8Array; debug: any } | { _tag: 'no-op' }\n    hash: Option.Option<number>\n  },\n  SqliteError | UnexpectedError\n>\n\nexport type InitialBlockingSyncContext = {\n  blockingDeferred: Deferred.Deferred<void> | undefined\n  update: (_: { remaining: number; processed: number }) => Effect.Effect<void>\n}\n\nexport interface LeaderSyncProcessor {\n  /** Used by client sessions to subscribe to upstream sync state changes */\n  pull: (args: {\n    cursor: LeaderPullCursor\n  }) => Stream.Stream<{ payload: typeof SyncState.PayloadUpstream.Type; mergeCounter: number }, UnexpectedError>\n  /** The `pullQueue` API can be used instead of `pull` when more convenient */\n  pullQueue: (args: {\n    cursor: LeaderPullCursor\n  }) => Effect.Effect<\n    Queue.Queue<{ payload: typeof SyncState.PayloadUpstream.Type; mergeCounter: number }>,\n    UnexpectedError,\n    Scope.Scope\n  >\n\n  /** Used by client sessions to push events to the leader thread */\n  push: (\n    /** `batch` needs to follow the same rules as `batch` in `SyncBackend.push` */\n    batch: ReadonlyArray<LiveStoreEvent.EncodedWithMeta>,\n    options?: {\n      /**\n       * If true, the effect will only finish when the local push has been processed (i.e. succeeded or was rejected).\n       * @default false\n       */\n      waitForProcessing?: boolean\n    },\n  ) => Effect.Effect<void, LeaderAheadError>\n\n  /** Currently only used by devtools which don't provide their own event numbers */\n  pushPartial: (args: {\n    event: LiveStoreEvent.PartialAnyEncoded\n    clientId: string\n    sessionId: string\n  }) => Effect.Effect<void, UnexpectedError>\n\n  boot: Effect.Effect<\n    { initialLeaderHead: EventSequenceNumber.EventSequenceNumber },\n    UnexpectedError,\n    LeaderThreadCtx | Scope.Scope | HttpClient.HttpClient\n  >\n  syncState: Subscribable.Subscribable<SyncState.SyncState>\n  getMergeCounter: () => number\n}\n", "import { LS_DEV, shouldNeverHappen } from '@livestore/utils'\nimport { Effect, Option, Schema } from '@livestore/utils/effect'\n\nimport type { SqliteDb } from '../adapter-types.js'\nimport * as EventSequenceNumber from '../schema/EventSequenceNumber.js'\nimport * as LiveStoreEvent from '../schema/LiveStoreEvent.js'\nimport {\n  EVENTLOG_META_TABLE,\n  eventlogMetaTable,\n  eventlogSystemTables,\n  sessionChangesetMetaTable,\n  SYNC_STATUS_TABLE,\n} from '../schema/state/sqlite/system-tables.js'\nimport { migrateTable } from '../schema-management/migrations.js'\nimport { insertRow, updateRows } from '../sql-queries/sql-queries.js'\nimport type { PreparedBindValues } from '../util.js'\nimport { prepareBindValues, sql } from '../util.js'\nimport { execSql } from './connection.js'\nimport type { InitialSyncInfo } from './types.js'\nimport { LeaderThreadCtx } from './types.js'\n\nexport const initEventlogDb = (dbEventlog: SqliteDb) =>\n  Effect.gen(function* () {\n    for (const tableDef of eventlogSystemTables) {\n      yield* migrateTable({\n        db: dbEventlog,\n        behaviour: 'create-if-not-exists',\n        tableAst: tableDef.sqliteDef.ast,\n        skipMetaTable: true,\n      })\n    }\n\n    // Create sync status row if it doesn't exist\n    yield* execSql(\n      dbEventlog,\n      sql`INSERT INTO ${SYNC_STATUS_TABLE} (head)\n          SELECT ${EventSequenceNumber.ROOT.global}\n          WHERE NOT EXISTS (SELECT 1 FROM ${SYNC_STATUS_TABLE})`,\n      {},\n    )\n  })\n\n/** Exclusive of the \"since event\" */\nexport const getEventsSince = (\n  since: EventSequenceNumber.EventSequenceNumber,\n): Effect.Effect<ReadonlyArray<LiveStoreEvent.EncodedWithMeta>, never, LeaderThreadCtx> =>\n  Effect.gen(function* () {\n    const { dbEventlog, dbState } = yield* LeaderThreadCtx\n\n    const query = eventlogMetaTable.where('seqNumGlobal', '>=', since.global).asSql()\n    const pendingEventsRaw = dbEventlog.select(query.query, prepareBindValues(query.bindValues, query.query))\n    const pendingEvents = Schema.decodeUnknownSync(eventlogMetaTable.rowSchema.pipe(Schema.Array))(pendingEventsRaw)\n\n    const sessionChangesetRows = sessionChangesetMetaTable.where('seqNumGlobal', '>=', since.global).asSql()\n    const sessionChangesetRowsRaw = dbState.select(\n      sessionChangesetRows.query,\n      prepareBindValues(sessionChangesetRows.bindValues, sessionChangesetRows.query),\n    )\n    const sessionChangesetRowsDecoded = Schema.decodeUnknownSync(\n      sessionChangesetMetaTable.rowSchema.pipe(Schema.Array),\n    )(sessionChangesetRowsRaw)\n\n    return pendingEvents\n      .map((eventlogEvent) => {\n        const sessionChangeset = sessionChangesetRowsDecoded.find(\n          (readModelEvent) =>\n            readModelEvent.seqNumGlobal === eventlogEvent.seqNumGlobal &&\n            readModelEvent.seqNumClient === eventlogEvent.seqNumClient,\n        )\n        return LiveStoreEvent.EncodedWithMeta.make({\n          name: eventlogEvent.name,\n          args: eventlogEvent.argsJson,\n          seqNum: { global: eventlogEvent.seqNumGlobal, client: eventlogEvent.seqNumClient },\n          parentSeqNum: { global: eventlogEvent.parentSeqNumGlobal, client: eventlogEvent.parentSeqNumClient },\n          clientId: eventlogEvent.clientId,\n          sessionId: eventlogEvent.sessionId,\n          meta: {\n            sessionChangeset:\n              sessionChangeset && sessionChangeset.changeset !== null\n                ? {\n                    _tag: 'sessionChangeset' as const,\n                    data: sessionChangeset.changeset,\n                    debug: sessionChangeset.debug,\n                  }\n                : { _tag: 'unset' as const },\n            syncMetadata: eventlogEvent.syncMetadataJson,\n            materializerHashLeader: Option.none(),\n            materializerHashSession: Option.none(),\n          },\n        })\n      })\n      .filter((_) => EventSequenceNumber.compare(_.seqNum, since) > 0)\n      .sort((a, b) => EventSequenceNumber.compare(a.seqNum, b.seqNum))\n  })\n\nexport const getClientHeadFromDb = (dbEventlog: SqliteDb): EventSequenceNumber.EventSequenceNumber => {\n  const res = dbEventlog.select<{\n    seqNumGlobal: EventSequenceNumber.GlobalEventSequenceNumber\n    seqNumClient: EventSequenceNumber.ClientEventSequenceNumber\n  }>(\n    sql`select seqNumGlobal, seqNumClient from ${EVENTLOG_META_TABLE} order by seqNumGlobal DESC, seqNumClient DESC limit 1`,\n  )[0]\n\n  return res ? { global: res.seqNumGlobal, client: res.seqNumClient } : EventSequenceNumber.ROOT\n}\n\nexport const getBackendHeadFromDb = (dbEventlog: SqliteDb): EventSequenceNumber.GlobalEventSequenceNumber =>\n  dbEventlog.select<{ head: EventSequenceNumber.GlobalEventSequenceNumber }>(\n    sql`select head from ${SYNC_STATUS_TABLE}`,\n  )[0]?.head ?? EventSequenceNumber.ROOT.global\n\n// TODO use prepared statements\nexport const updateBackendHead = (dbEventlog: SqliteDb, head: EventSequenceNumber.EventSequenceNumber) =>\n  dbEventlog.execute(sql`UPDATE ${SYNC_STATUS_TABLE} SET head = ${head.global}`)\n\nexport const insertIntoEventlog = (\n  eventEncoded: LiveStoreEvent.EncodedWithMeta,\n  dbEventlog: SqliteDb,\n  eventDefSchemaHash: number,\n  clientId: string,\n  sessionId: string,\n) =>\n  Effect.gen(function* () {\n    // Check history consistency during LS_DEV\n    if (LS_DEV && eventEncoded.parentSeqNum.global !== EventSequenceNumber.ROOT.global) {\n      const parentEventExists =\n        dbEventlog.select<{ count: number }>(\n          `SELECT COUNT(*) as count FROM ${EVENTLOG_META_TABLE} WHERE seqNumGlobal = ? AND seqNumClient = ?`,\n          [eventEncoded.parentSeqNum.global, eventEncoded.parentSeqNum.client] as any as PreparedBindValues,\n        )[0]!.count === 1\n\n      if (parentEventExists === false) {\n        shouldNeverHappen(\n          `Parent mutation ${eventEncoded.parentSeqNum.global},${eventEncoded.parentSeqNum.client} does not exist`,\n        )\n      }\n    }\n\n    // TODO use prepared statements\n    yield* execSql(\n      dbEventlog,\n      ...insertRow({\n        tableName: EVENTLOG_META_TABLE,\n        columns: eventlogMetaTable.sqliteDef.columns,\n        values: {\n          seqNumGlobal: eventEncoded.seqNum.global,\n          seqNumClient: eventEncoded.seqNum.client,\n          parentSeqNumGlobal: eventEncoded.parentSeqNum.global,\n          parentSeqNumClient: eventEncoded.parentSeqNum.client,\n          name: eventEncoded.name,\n          argsJson: eventEncoded.args ?? {},\n          clientId,\n          sessionId,\n          schemaHash: eventDefSchemaHash,\n          syncMetadataJson: eventEncoded.meta.syncMetadata,\n        },\n      }),\n    )\n  })\n\nexport const updateSyncMetadata = (items: ReadonlyArray<LiveStoreEvent.EncodedWithMeta>) =>\n  Effect.gen(function* () {\n    const { dbEventlog } = yield* LeaderThreadCtx\n\n    // TODO try to do this in a single query\n    for (let i = 0; i < items.length; i++) {\n      const event = items[i]!\n\n      yield* execSql(\n        dbEventlog,\n        ...updateRows({\n          tableName: EVENTLOG_META_TABLE,\n          columns: eventlogMetaTable.sqliteDef.columns,\n          where: { seqNumGlobal: event.seqNum.global, seqNumClient: event.seqNum.client },\n          updateValues: { syncMetadataJson: event.meta.syncMetadata },\n        }),\n      )\n    }\n  })\n\nexport const getSyncBackendCursorInfo = (remoteHead: EventSequenceNumber.GlobalEventSequenceNumber) =>\n  Effect.gen(function* () {\n    const { dbEventlog } = yield* LeaderThreadCtx\n\n    if (remoteHead === EventSequenceNumber.ROOT.global) return Option.none()\n\n    const EventlogQuerySchema = Schema.Struct({\n      syncMetadataJson: Schema.parseJson(Schema.Option(Schema.JsonValue)),\n    }).pipe(Schema.pluck('syncMetadataJson'), Schema.Array, Schema.head)\n\n    const syncMetadataOption = yield* Effect.sync(() =>\n      dbEventlog.select<{ syncMetadataJson: string }>(\n        sql`SELECT syncMetadataJson FROM ${EVENTLOG_META_TABLE} WHERE seqNumGlobal = ${remoteHead} ORDER BY seqNumClient ASC LIMIT 1`,\n      ),\n    ).pipe(Effect.andThen(Schema.decode(EventlogQuerySchema)), Effect.map(Option.flatten), Effect.orDie)\n\n    return Option.some({\n      cursor: { global: remoteHead, client: EventSequenceNumber.clientDefault },\n      metadata: syncMetadataOption,\n    }) satisfies InitialSyncInfo\n  }).pipe(Effect.withSpan('@livestore/common:eventlog:getSyncBackendCursorInfo', { attributes: { remoteHead } }))\n", "export const objectEntries = <T extends Record<string, any>>(obj: T): [keyof T & string, T[keyof T]][] =>\n  Object.entries(obj) as [keyof T & string, T[keyof T]][]\n", "import type { Prettify } from '@livestore/utils'\nimport type { Schema } from '@livestore/utils/effect'\n\nimport type { SqliteDsl } from '../schema/state/sqlite/db-schema/mod.js'\n\nexport type DecodedValuesForTableAll<TSchema extends SqliteDsl.DbSchema, TTableName extends keyof TSchema> = {\n  [K in keyof GetColumns<TSchema, TTableName>]: Schema.Schema.Type<GetColumn<TSchema, TTableName, K>['schema']>\n}\n\nexport type DecodedValuesForTablePretty<\n  TSchema extends SqliteDsl.DbSchema,\n  TTableName extends keyof TSchema,\n> = Prettify<DecodedValuesForTable<TSchema, TTableName>>\n\nexport type DecodedValuesForTable<TSchema extends SqliteDsl.DbSchema, TTableName extends keyof TSchema> = Partial<\n  Pick<DecodedValuesForTableAll<TSchema, TTableName>, GetNullableColumnNamesForTable<TSchema, TTableName>>\n> &\n  Omit<DecodedValuesForTableAll<TSchema, TTableName>, GetNullableColumnNamesForTable<TSchema, TTableName>>\n\nexport type DecodedValuesForTableOrNull<\n  TSchema extends SqliteDsl.DbSchema,\n  TTableName extends keyof TSchema,\n> = NullableObj<\n  Pick<DecodedValuesForTableAll<TSchema, TTableName>, GetNullableColumnNamesForTable<TSchema, TTableName>>\n> &\n  Omit<DecodedValuesForTableAll<TSchema, TTableName>, GetNullableColumnNamesForTable<TSchema, TTableName>>\n\nexport type WhereValuesForTable<TSchema extends SqliteDsl.DbSchema, TTableName extends keyof TSchema> = PartialOrNull<{\n  [K in keyof DecodedValuesForTableAll<TSchema, TTableName>]: WhereValueForDecoded<\n    DecodedValuesForTableAll<TSchema, TTableName>[K]\n  >\n}>\n\nexport type WhereValueForDecoded<TDecoded> = TDecoded | { op: WhereOp; val: TDecoded } | { op: 'in'; val: TDecoded[] }\nexport type WhereOp = '>' | '<' | '='\n\nexport const isValidWhereOp = (op: string): op is WhereOp => {\n  const validWhereOps = ['>', '<', '=']\n  return validWhereOps.includes(op)\n}\n\nexport type EncodedValuesForTableAll<TSchema extends SqliteDsl.DbSchema, TTableName extends keyof TSchema> = {\n  [K in keyof GetColumns<TSchema, TTableName>]: Schema.Schema.Type<GetColumn<TSchema, TTableName, K>['schema']>\n}\n\nexport type EncodedValuesForTable<TSchema extends SqliteDsl.DbSchema, TTableName extends keyof TSchema> = Partial<\n  Pick<EncodedValuesForTableAll<TSchema, TTableName>, GetNullableColumnNamesForTable<TSchema, TTableName>>\n> &\n  Omit<EncodedValuesForTableAll<TSchema, TTableName>, GetNullableColumnNamesForTable<TSchema, TTableName>>\n\nexport type GetNullableColumnNamesForTable<\n  TSchema extends SqliteDsl.DbSchema,\n  TTableName extends keyof TSchema,\n> = keyof {\n  [K in keyof GetColumns<TSchema, TTableName> as GetColumn<TSchema, TTableName, K>['nullable'] extends true\n    ? K\n    : never]: {}\n}\n\nexport type GetColumns<\n  TSchema extends SqliteDsl.DbSchema,\n  TTableName extends keyof TSchema,\n> = TSchema[TTableName]['columns']\n\nexport type GetColumn<\n  TSchema extends SqliteDsl.DbSchema,\n  TTableName extends keyof TSchema,\n  TColumnName extends keyof TSchema[TTableName]['columns'],\n> = TSchema[TTableName]['columns'][TColumnName]\n\nexport type DecodedValuesForColumnsAll<TColumns extends SqliteDsl.Columns> = {\n  [K in keyof TColumns]: Schema.Schema.Type<TColumns[K]['schema']>\n}\n\nexport type DecodedValuesForColumns<TColumns extends SqliteDsl.Columns> = Partial<\n  Pick<DecodedValuesForColumnsAll<TColumns>, GetNullableColumnNames<TColumns>>\n> &\n  Omit<DecodedValuesForColumnsAll<TColumns>, GetNullableColumnNames<TColumns>>\n\nexport type EncodedValuesForColumnsAll<TColumns extends SqliteDsl.Columns> = {\n  [K in keyof TColumns]: Schema.Schema.Encoded<TColumns[K]['schema']>\n}\n\nexport type EncodedValuesForColumns<TColumns extends SqliteDsl.Columns> = Partial<\n  Pick<EncodedValuesForColumnsAll<TColumns>, GetNullableColumnNames<TColumns>>\n> &\n  Omit<EncodedValuesForColumnsAll<TColumns>, GetNullableColumnNames<TColumns>>\n\nexport type WhereValuesForColumns<TColumns extends SqliteDsl.Columns> = PartialOrNull<{\n  [K in keyof EncodedValuesForColumns<TColumns>]: WhereValueForDecoded<DecodedValuesForColumnsAll<TColumns>[K]>\n}>\n\nexport type GetNullableColumnNames<TColumns extends SqliteDsl.Columns> = keyof {\n  [K in keyof TColumns as TColumns[K] extends SqliteDsl.ColumnDefinition<any, true> ? K : never]: unknown\n}\n\nexport type PartialOrNull<T> = { [P in keyof T]?: T[P] | null }\n\nexport type NullableObj<T> = { [P in keyof T]: T[P] | null }\n", "import { shouldNeverHappen } from '@livestore/utils'\nimport { pipe, ReadonlyArray, Schema, TreeFormatter } from '@livestore/utils/effect'\n\nimport type { SqliteDsl } from '../schema/state/sqlite/db-schema/mod.js'\nimport { sql } from '../util.js'\nimport { objectEntries } from './misc.js'\nimport * as ClientTypes from './types.js'\n\nexport type BindValues = {\n  readonly [columnName: string]: any\n}\n\nexport const findManyRows = <TColumns extends SqliteDsl.Columns>({\n  columns,\n  tableName,\n  where,\n  limit,\n}: {\n  tableName: string\n  columns: TColumns\n  where: ClientTypes.WhereValuesForColumns<TColumns>\n  limit?: number\n}): [string, BindValues] => {\n  const whereSql = buildWhereSql({ where })\n  const whereModifier = whereSql === '' ? '' : `WHERE ${whereSql}`\n  const limitModifier = limit ? `LIMIT ${limit}` : ''\n\n  const whereBindValues = makeBindValues({ columns, values: where, variablePrefix: 'where_', skipNil: true })\n\n  return [sql`SELECT * FROM ${tableName} ${whereModifier} ${limitModifier}`, whereBindValues]\n}\n\nexport const countRows = <TColumns extends SqliteDsl.Columns>({\n  columns,\n  tableName,\n  where,\n}: {\n  tableName: string\n  columns: TColumns\n  where: ClientTypes.WhereValuesForColumns<TColumns>\n}): [string, BindValues] => {\n  const whereSql = buildWhereSql({ where })\n  const whereModifier = whereSql === '' ? '' : `WHERE ${whereSql}`\n\n  const whereBindValues = makeBindValues({ columns, values: where, variablePrefix: 'where_', skipNil: true })\n\n  return [sql`SELECT count(1) FROM ${tableName} ${whereModifier}`, whereBindValues]\n}\n\nexport const insertRow = <TColumns extends SqliteDsl.Columns>({\n  tableName,\n  columns,\n  values,\n  options = { orReplace: false },\n}: {\n  tableName: string\n  columns: TColumns\n  values: ClientTypes.DecodedValuesForColumns<TColumns>\n  options?: { orReplace: boolean }\n}): [string, BindValues] => {\n  const stmt = insertRowPrepared({\n    tableName,\n    columns,\n    options: { orReplace: options?.orReplace, keys: Object.keys(values) },\n  })\n\n  return [stmt, makeBindValues({ columns, values })]\n}\n\nexport const insertRowPrepared = <TColumns extends SqliteDsl.Columns>({\n  tableName,\n  columns,\n  options = { orReplace: false },\n}: {\n  tableName: string\n  columns: TColumns\n  options?: { orReplace: boolean; keys?: string[] }\n}): string => {\n  const keys = options?.keys ?? Object.keys(columns)\n  const keysStr = keys.join(', ')\n  const valuesStr = keys.map((key) => `$${key}`).join(', ')\n\n  return sql`INSERT ${options.orReplace ? 'OR REPLACE ' : ''}INTO ${tableName} (${keysStr}) VALUES (${valuesStr})`\n}\n\nexport const insertRows = <TColumns extends SqliteDsl.Columns>({\n  columns,\n  tableName,\n  valuesArray,\n}: {\n  tableName: string\n  columns: TColumns\n  valuesArray: ClientTypes.DecodedValuesForColumns<TColumns>[]\n}): [string, BindValues] => {\n  const keysStr = Object.keys(valuesArray[0]!).join(', ')\n\n  // NOTE consider batching for large arrays (https://sqlite.org/forum/info/f832398c19d30a4a)\n  const valuesStrs = valuesArray\n    .map((values, itemIndex) =>\n      Object.keys(values)\n        .map((_) => `$item_${itemIndex}_${_}`)\n        .join(', '),\n    )\n    .map((_) => `(${_})`)\n    .join(', ')\n\n  const bindValues = valuesArray.reduce(\n    (acc, values, itemIndex) => ({\n      ...acc,\n      ...makeBindValues({ columns, values, variablePrefix: `item_${itemIndex}_` }),\n    }),\n    {},\n  )\n\n  return [sql`INSERT INTO ${tableName} (${keysStr}) VALUES ${valuesStrs}`, bindValues]\n}\n\nexport const insertOrIgnoreRow = <TColumns extends SqliteDsl.Columns>({\n  columns,\n  tableName,\n  values: values_,\n  returnRow,\n}: {\n  tableName: string\n  columns: TColumns\n  values: ClientTypes.DecodedValuesForColumns<TColumns>\n  returnRow: boolean\n}): [string, BindValues] => {\n  const values = filterUndefinedFields(values_)\n  const keysStr = Object.keys(values).join(', ')\n  const valuesStr = Object.keys(values)\n    .map((_) => `$${_}`)\n    .join(', ')\n\n  const bindValues = makeBindValues({ columns, values })\n  const returningStmt = returnRow ? 'RETURNING *' : ''\n\n  return [sql`INSERT OR IGNORE INTO ${tableName} (${keysStr}) VALUES (${valuesStr}) ${returningStmt}`, bindValues]\n}\n\nexport const updateRows = <TColumns extends SqliteDsl.Columns>({\n  columns,\n  tableName,\n  updateValues: updateValues_,\n  where,\n}: {\n  columns: TColumns\n  tableName: string\n  updateValues: Partial<ClientTypes.DecodedValuesForColumnsAll<TColumns>>\n  where: ClientTypes.WhereValuesForColumns<TColumns>\n}): [string, BindValues] => {\n  const updateValues = filterUndefinedFields(updateValues_)\n\n  // TODO return an Option instead of `select 1` if there are no update values\n  if (Object.keys(updateValues).length === 0) {\n    return [sql`select 1`, {}]\n  }\n\n  const updateValueStr = Object.keys(updateValues)\n    .map((columnName) => `${columnName} = $update_${columnName}`)\n    .join(', ')\n\n  const bindValues = {\n    ...makeBindValues({ columns, values: updateValues, variablePrefix: 'update_' }),\n    ...makeBindValues({ columns, values: where, variablePrefix: 'where_', skipNil: true }),\n  }\n\n  const whereSql = buildWhereSql({ where })\n  const whereModifier = whereSql === '' ? '' : `WHERE ${whereSql}`\n\n  return [sql`UPDATE ${tableName} SET ${updateValueStr} ${whereModifier}`, bindValues]\n}\n\nexport const deleteRows = <TColumns extends SqliteDsl.Columns>({\n  columns,\n  tableName,\n  where,\n}: {\n  columns: TColumns\n  tableName: string\n  where: ClientTypes.WhereValuesForColumns<TColumns>\n}): [string, BindValues] => {\n  const bindValues = {\n    ...makeBindValues({ columns, values: where, variablePrefix: 'where_', skipNil: true }),\n  }\n\n  const whereSql = buildWhereSql({ where })\n  const whereModifier = whereSql === '' ? '' : `WHERE ${whereSql}`\n\n  return [sql`DELETE FROM ${tableName} ${whereModifier}`, bindValues]\n}\n\nexport const upsertRow = <TColumns extends SqliteDsl.Columns>({\n  tableName,\n  columns,\n  createValues: createValues_,\n  updateValues: updateValues_,\n  where,\n}: {\n  tableName: string\n  columns: TColumns\n  createValues: ClientTypes.DecodedValuesForColumns<TColumns>\n  updateValues: Partial<ClientTypes.DecodedValuesForColumnsAll<TColumns>>\n  // TODO where VALUES are actually not used here. Maybe adjust API?\n  where: ClientTypes.WhereValuesForColumns<TColumns>\n}): [string, BindValues] => {\n  const createValues = filterUndefinedFields(createValues_)\n  const updateValues = filterUndefinedFields(updateValues_)\n\n  const keysStr = Object.keys(createValues).join(', ')\n\n  const createValuesStr = Object.keys(createValues)\n    .map((_) => `$create_${_}`)\n    .join(', ')\n\n  const conflictStr = Object.keys(where).join(', ')\n\n  const updateValueStr = Object.keys(updateValues)\n    .map((columnName) => `${columnName} = $update_${columnName}`)\n    .join(', ')\n\n  const bindValues = {\n    ...makeBindValues({ columns, values: createValues, variablePrefix: 'create_' }),\n    ...makeBindValues({ columns, values: updateValues, variablePrefix: 'update_' }),\n  }\n\n  return [\n    sql`\n      INSERT INTO ${tableName} (${keysStr})\n       VALUES (${createValuesStr})\n       ON CONFLICT (${conflictStr}) DO UPDATE SET ${updateValueStr}\n    `,\n    bindValues,\n  ]\n}\n\nexport const createTable = ({\n  table,\n  tableName,\n}: {\n  table: SqliteDsl.TableDefinition<any, SqliteDsl.Columns>\n  tableName: string\n}): string => {\n  const primaryKeys = Object.entries(table.columns)\n    .filter(([_, columnDef]) => columnDef.primaryKey)\n    .map(([columnName, _]) => columnName)\n  const columnDefStrs = Object.entries(table.columns).map(([columnName, columnDef]) => {\n    const nullModifier = columnDef.nullable === true ? '' : 'NOT NULL'\n    const defaultModifier = columnDef.default._tag === 'None' ? '' : `DEFAULT ${columnDef.default.value}`\n    return sql`${columnName} ${columnDef.columnType} ${nullModifier} ${defaultModifier}`\n  })\n\n  if (primaryKeys.length > 0) {\n    columnDefStrs.push(`PRIMARY KEY (${primaryKeys.join(', ')})`)\n  }\n\n  return sql`CREATE TABLE ${tableName} (${columnDefStrs.join(', ')});`\n}\n\nexport const makeBindValues = <TColumns extends SqliteDsl.Columns, TKeys extends keyof TColumns>({\n  columns,\n  values,\n  variablePrefix = '',\n  skipNil,\n}: {\n  columns: TColumns\n  values: Partial<Record<TKeys, any>>\n  variablePrefix?: string\n  /** So far only used to prepare `where` statements */\n  skipNil?: boolean\n}): Record<string, any> => {\n  const codecMap = pipe(\n    columns,\n    objectEntries,\n    ReadonlyArray.map(([columnName, columnDef]) => [\n      columnName,\n      (value: any) => {\n        if (columnDef.nullable === true && (value === null || value === undefined)) return null\n        const res = Schema.encodeEither(columnDef.schema)(value)\n        if (res._tag === 'Left') {\n          const parseErrorStr = TreeFormatter.formatErrorSync(res.left)\n          const expectedSchemaStr = String(columnDef.schema.ast)\n\n          console.error(\n            `\\\nError making bind values for SQL query for column \"${columnName}\".\n\nExpected schema: ${expectedSchemaStr}\n\nError: ${parseErrorStr}\n\nValue:`,\n            value,\n          )\n          debugger\n          throw res.left\n        } else {\n          return res.right\n        }\n      },\n    ]),\n    Object.fromEntries,\n  )\n\n  return pipe(\n    Object.entries(values)\n      // NOTE null/undefined values are handled via explicit SQL syntax and don't need to be provided as bind values\n      .filter(([, value]) => skipNil !== true || (value !== null && value !== undefined))\n      .flatMap(([columnName, value]: [string, any]) => {\n        const codec = codecMap[columnName] ?? shouldNeverHappen(`No codec found for column \"${columnName}\"`)\n        // remap complex where-values with `op`\n        if (typeof value === 'object' && value !== null && 'op' in value) {\n          switch (value.op) {\n            case 'in': {\n              return value.val.map((value: any, i: number) => [`${variablePrefix}${columnName}_${i}`, codec(value)])\n            }\n            case '=':\n            case '>':\n            case '<': {\n              return [[`${variablePrefix}${columnName}`, codec(value.val)]]\n            }\n            default: {\n              throw new Error(`Unknown op: ${value.op}`)\n            }\n          }\n        } else {\n          return [[`${variablePrefix}${columnName}`, codec(value)]]\n        }\n      }),\n    Object.fromEntries,\n  )\n}\n\nconst buildWhereSql = <TColumns extends SqliteDsl.Columns>({\n  where,\n}: {\n  where: ClientTypes.WhereValuesForColumns<TColumns>\n}) => {\n  const getWhereOp = (columnName: string, value: ClientTypes.WhereValueForDecoded<any>) => {\n    if (value === null) {\n      return `IS NULL`\n    } else if (typeof value === 'object' && typeof value.op === 'string' && ClientTypes.isValidWhereOp(value.op)) {\n      return `${value.op} $where_${columnName}`\n    } else if (typeof value === 'object' && typeof value.op === 'string' && value.op === 'in') {\n      return `in (${value.val.map((_: any, i: number) => `$where_${columnName}_${i}`).join(', ')})`\n    } else {\n      return `= $where_${columnName}`\n    }\n  }\n\n  return pipe(\n    where,\n    objectEntries,\n    ReadonlyArray.map(([columnName, value]) => `${columnName} ${getWhereOp(columnName, value)}`),\n    ReadonlyArray.join(' AND '),\n  )\n}\n\n// TODO better typing\nconst filterUndefinedFields = <T extends Record<string, any>>(obj: T): T => {\n  return Object.fromEntries(Object.entries(obj).filter(([, value]) => value !== undefined)) as T\n}\n", "import { Effect, FiberMap, Option, Stream, SubscriptionRef } from '@livestore/utils/effect'\nimport { nanoid } from '@livestore/utils/nanoid'\n\nimport { Devtools, IntentionalShutdownCause, liveStoreVersion, UnexpectedError } from '../index.js'\nimport { SystemTables } from '../schema/mod.js'\nimport type { DevtoolsOptions, PersistenceInfoPair } from './types.js'\nimport { LeaderThreadCtx } from './types.js'\n\ntype SendMessageToDevtools = (message: Devtools.Leader.MessageFromApp) => Effect.Effect<void>\n\n// TODO bind scope to the webchannel lifetime\nexport const bootDevtools = (options: DevtoolsOptions) =>\n  Effect.gen(function* () {\n    if (options.enabled === false) {\n      return\n    }\n\n    const { syncProcessor, extraIncomingMessagesQueue, clientId, storeId } = yield* LeaderThreadCtx\n\n    yield* listenToDevtools({\n      incomingMessages: Stream.fromQueue(extraIncomingMessagesQueue),\n      sendMessage: () => Effect.void,\n    }).pipe(Effect.tapCauseLogPretty, Effect.forkScoped)\n\n    const { node, persistenceInfo, mode } = yield* options.boot\n\n    yield* node.listenForChannel.pipe(\n      Stream.filter(\n        (res) =>\n          Devtools.isChannelName.devtoolsClientLeader(res.channelName, { storeId, clientId }) && res.mode === mode,\n      ),\n      Stream.tap(({ channelName, source }) =>\n        Effect.gen(function* () {\n          const channel = yield* node.makeChannel({\n            target: source,\n            channelName,\n            schema: { listen: Devtools.Leader.MessageToApp, send: Devtools.Leader.MessageFromApp },\n            mode,\n          })\n\n          const sendMessage: SendMessageToDevtools = (message) =>\n            channel\n              .send(message)\n              .pipe(\n                Effect.withSpan('@livestore/common:leader-thread:devtools:sendToDevtools'),\n                Effect.interruptible,\n                Effect.ignoreLogged,\n              )\n\n          const syncState = yield* syncProcessor.syncState\n          const mergeCounter = syncProcessor.getMergeCounter()\n\n          yield* syncProcessor.pull({ cursor: { mergeCounter, eventNum: syncState.localHead } }).pipe(\n            Stream.tap(({ payload }) => sendMessage(Devtools.Leader.SyncPull.make({ payload, liveStoreVersion }))),\n            Stream.runDrain,\n            Effect.forkScoped,\n          )\n\n          yield* listenToDevtools({\n            incomingMessages: channel.listen.pipe(Stream.flatten(), Stream.orDie),\n            sendMessage,\n            persistenceInfo,\n          })\n        }).pipe(Effect.tapCauseLogPretty, Effect.forkScoped),\n      ),\n      Stream.runDrain,\n    )\n  }).pipe(Effect.withSpan('@livestore/common:leader-thread:devtools:boot'))\n\nconst listenToDevtools = ({\n  incomingMessages,\n  sendMessage,\n  persistenceInfo,\n}: {\n  incomingMessages: Stream.Stream<Devtools.Leader.MessageToApp>\n  sendMessage: SendMessageToDevtools\n  persistenceInfo?: PersistenceInfoPair\n}) =>\n  Effect.gen(function* () {\n    const {\n      syncBackend,\n      makeSqliteDb,\n      dbState,\n      dbEventlog,\n      shutdownStateSubRef,\n      shutdownChannel,\n      syncProcessor,\n      clientId,\n      devtools,\n    } = yield* LeaderThreadCtx\n\n    type SubscriptionId = string\n    const subscriptionFiberMap = yield* FiberMap.make<SubscriptionId>()\n\n    type RequestId = string\n    const handledRequestIds = new Set<RequestId>()\n\n    yield* incomingMessages.pipe(\n      Stream.tap((decodedEvent) =>\n        Effect.gen(function* () {\n          const { requestId } = decodedEvent\n          const reqPayload = { requestId, liveStoreVersion, clientId }\n\n          // yield* Effect.logDebug(\n          //   `[@livestore/common:leader-thread:devtools] incomingMessage: ${decodedEvent._tag} (${requestId})`,\n          //   decodedEvent,\n          // )\n\n          if (decodedEvent._tag === 'LSD.Leader.Disconnect') {\n            return\n          }\n\n          // TODO we should try to move the duplicate message handling on the webmesh layer\n          // So far I could only observe this problem with webmesh proxy channels (e.g. for Expo)\n          // Proof: https://share.cleanshot.com/V9G87B0B\n          // Also see `store/devtools.ts` for same problem\n          if (handledRequestIds.has(requestId)) {\n            // yield* Effect.logWarning(`Duplicate message`, decodedEvent)\n            return\n          }\n\n          handledRequestIds.add(requestId)\n\n          switch (decodedEvent._tag) {\n            case 'LSD.Leader.Ping': {\n              yield* sendMessage(Devtools.Leader.Pong.make({ ...reqPayload }))\n              return\n            }\n            case 'LSD.Leader.SnapshotReq': {\n              const snapshot = dbState.export()\n\n              yield* sendMessage(Devtools.Leader.SnapshotRes.make({ snapshot, ...reqPayload }))\n\n              return\n            }\n            case 'LSD.Leader.LoadDatabaseFile.Request': {\n              const { data } = decodedEvent\n\n              let tableNames: Set<string>\n\n              try {\n                const tmpDb = yield* makeSqliteDb({ _tag: 'in-memory' })\n                tmpDb.import(data)\n                const tableNameResults = tmpDb.select<{ name: string }>(\n                  `select name from sqlite_master where type = 'table'`,\n                )\n\n                tableNames = new Set(tableNameResults.map((_) => _.name))\n\n                tmpDb.close()\n              } catch (cause) {\n                yield* Effect.logError(`Error importing database file`, cause)\n                yield* sendMessage(\n                  Devtools.Leader.LoadDatabaseFile.Error.make({\n                    ...reqPayload,\n                    cause: { _tag: 'unexpected-error', cause },\n                  }),\n                )\n\n                return\n              }\n\n              try {\n                if (tableNames.has(SystemTables.EVENTLOG_META_TABLE)) {\n                  // Is eventlog db\n                  yield* SubscriptionRef.set(shutdownStateSubRef, 'shutting-down')\n\n                  dbEventlog.import(data)\n\n                  dbState.destroy()\n                } else if (\n                  tableNames.has(SystemTables.SCHEMA_META_TABLE) &&\n                  tableNames.has(SystemTables.SCHEMA_EVENT_DEFS_META_TABLE)\n                ) {\n                  // Is state db\n                  yield* SubscriptionRef.set(shutdownStateSubRef, 'shutting-down')\n\n                  dbState.import(data)\n\n                  dbEventlog.destroy()\n                } else {\n                  yield* sendMessage(\n                    Devtools.Leader.LoadDatabaseFile.Error.make({\n                      ...reqPayload,\n                      cause: { _tag: 'unsupported-database' },\n                    }),\n                  )\n                  return\n                }\n\n                yield* sendMessage(Devtools.Leader.LoadDatabaseFile.Success.make({ ...reqPayload }))\n                yield* shutdownChannel.send(IntentionalShutdownCause.make({ reason: 'devtools-import' })) ?? Effect.void\n\n                return\n              } catch (cause) {\n                yield* Effect.logError(`Error importing database file`, cause)\n                yield* sendMessage(\n                  Devtools.Leader.LoadDatabaseFile.Error.make({\n                    ...reqPayload,\n                    cause: { _tag: 'unexpected-error', cause },\n                  }),\n                )\n                return\n              }\n            }\n            case 'LSD.Leader.ResetAllData.Request': {\n              const { mode } = decodedEvent\n\n              yield* SubscriptionRef.set(shutdownStateSubRef, 'shutting-down')\n\n              dbState.destroy()\n\n              if (mode === 'all-data') {\n                dbEventlog.destroy()\n              }\n\n              yield* sendMessage(Devtools.Leader.ResetAllData.Success.make({ ...reqPayload }))\n\n              yield* shutdownChannel.send(IntentionalShutdownCause.make({ reason: 'devtools-reset' })) ?? Effect.void\n\n              return\n            }\n            case 'LSD.Leader.DatabaseFileInfoReq': {\n              if (persistenceInfo === undefined) {\n                console.log('[@livestore/common:leader-thread:devtools] persistenceInfo is required for this request')\n                return\n              }\n\n              const dbSizeQuery = `SELECT page_count * page_size as size FROM pragma_page_count(), pragma_page_size();`\n              const dbFileSize = dbState.select<{ size: number }>(dbSizeQuery, undefined)[0]!.size\n              const eventlogFileSize = dbEventlog.select<{ size: number }>(dbSizeQuery, undefined)[0]!.size\n\n              yield* sendMessage(\n                Devtools.Leader.DatabaseFileInfoRes.make({\n                  state: { fileSize: dbFileSize, persistenceInfo: persistenceInfo.state },\n                  eventlog: { fileSize: eventlogFileSize, persistenceInfo: persistenceInfo.eventlog },\n                  ...reqPayload,\n                }),\n              )\n\n              return\n            }\n            case 'LSD.Leader.EventlogReq': {\n              const eventlog = dbEventlog.export()\n\n              yield* sendMessage(Devtools.Leader.EventlogRes.make({ eventlog, ...reqPayload }))\n\n              return\n            }\n            case 'LSD.Leader.CommitEventReq': {\n              yield* syncProcessor.pushPartial({\n                event: decodedEvent.eventEncoded,\n                clientId: `devtools-${clientId}`,\n                sessionId: `devtools-${clientId}`,\n              })\n\n              yield* sendMessage(Devtools.Leader.CommitEventRes.make({ ...reqPayload }))\n\n              return\n            }\n            case 'LSD.Leader.SyncHistorySubscribe': {\n              const { subscriptionId } = decodedEvent\n\n              if (syncBackend !== undefined) {\n                // TODO consider piggybacking on the existing leader-thread sync-pulling\n                yield* syncBackend.pull(Option.none()).pipe(\n                  Stream.map((_) => _.batch),\n                  Stream.flattenIterables,\n                  Stream.tap(({ eventEncoded, metadata }) =>\n                    sendMessage(\n                      Devtools.Leader.SyncHistoryRes.make({\n                        eventEncoded,\n                        metadata,\n                        subscriptionId,\n                        ...reqPayload,\n                        requestId: nanoid(10),\n                      }),\n                    ),\n                  ),\n                  Stream.runDrain,\n                  Effect.interruptible,\n                  Effect.tapCauseLogPretty,\n                  FiberMap.run(subscriptionFiberMap, subscriptionId),\n                )\n              }\n\n              return\n            }\n            case 'LSD.Leader.SyncHistoryUnsubscribe': {\n              const { requestId } = decodedEvent\n              console.log('LSD.SyncHistoryUnsubscribe', requestId)\n\n              yield* FiberMap.remove(subscriptionFiberMap, requestId)\n\n              return\n            }\n            case 'LSD.Leader.SyncingInfoReq': {\n              const syncingInfo = Devtools.Leader.SyncingInfo.make({\n                enabled: syncBackend !== undefined,\n                metadata: syncBackend?.metadata ?? {},\n              })\n\n              yield* sendMessage(Devtools.Leader.SyncingInfoRes.make({ syncingInfo, ...reqPayload }))\n\n              return\n            }\n            case 'LSD.Leader.NetworkStatusSubscribe': {\n              if (syncBackend !== undefined) {\n                const { subscriptionId } = decodedEvent\n\n                // TODO investigate and fix bug. seems that when sending messages right after\n                // the devtools have connected get sometimes lost\n                // This is probably the same \"flaky databrowser loading\" bug as we're seeing in the playwright tests\n                yield* Effect.sleep(1000)\n\n                yield* Stream.zipLatest(\n                  syncBackend.isConnected.changes,\n                  devtools.enabled ? devtools.syncBackendLatchState.changes : Stream.make({ latchClosed: false }),\n                ).pipe(\n                  Stream.tap(([isConnected, { latchClosed }]) =>\n                    sendMessage(\n                      Devtools.Leader.NetworkStatusRes.make({\n                        networkStatus: { isConnected, timestampMs: Date.now(), latchClosed },\n                        subscriptionId,\n                        ...reqPayload,\n                        requestId: nanoid(10),\n                      }),\n                    ),\n                  ),\n                  Stream.runDrain,\n                  Effect.interruptible,\n                  Effect.tapCauseLogPretty,\n                  FiberMap.run(subscriptionFiberMap, subscriptionId),\n                )\n              }\n\n              return\n            }\n            case 'LSD.Leader.NetworkStatusUnsubscribe': {\n              const { requestId } = decodedEvent\n\n              yield* FiberMap.remove(subscriptionFiberMap, requestId)\n\n              return\n            }\n            case 'LSD.Leader.SyncHeadSubscribe': {\n              const { subscriptionId } = decodedEvent\n\n              yield* syncProcessor.syncState.changes.pipe(\n                Stream.tap((syncState) =>\n                  sendMessage(\n                    Devtools.Leader.SyncHeadRes.make({\n                      local: syncState.localHead,\n                      upstream: syncState.upstreamHead,\n                      subscriptionId,\n                      ...reqPayload,\n                      requestId: nanoid(10),\n                    }),\n                  ),\n                ),\n                Stream.runDrain,\n                Effect.interruptible,\n                Effect.tapCauseLogPretty,\n                FiberMap.run(subscriptionFiberMap, subscriptionId),\n              )\n\n              return\n            }\n            case 'LSD.Leader.SyncHeadUnsubscribe': {\n              const { subscriptionId } = decodedEvent\n\n              yield* FiberMap.remove(subscriptionFiberMap, subscriptionId)\n\n              return\n            }\n            case 'LSD.Leader.SetSyncLatch.Request': {\n              const { closeLatch } = decodedEvent\n\n              if (devtools.enabled === false) return\n\n              if (closeLatch === true) {\n                yield* devtools.syncBackendLatch.close\n              } else {\n                yield* devtools.syncBackendLatch.open\n              }\n\n              yield* SubscriptionRef.set(devtools.syncBackendLatchState, { latchClosed: closeLatch })\n\n              yield* sendMessage(Devtools.Leader.SetSyncLatch.Success.make({ ...reqPayload }))\n\n              return\n            }\n            default: {\n              yield* Effect.logWarning(`TODO implement devtools message`, decodedEvent)\n            }\n          }\n        }).pipe(Effect.withSpan(`@livestore/common:leader-thread:onDevtoolsMessage:${decodedEvent._tag}`)),\n      ),\n      UnexpectedError.mapToUnexpectedErrorStream,\n      Stream.runDrain,\n    )\n  })\n", "import { isDevEnv, LS_DEV, shouldNeverHappen } from '@livestore/utils'\nimport { Effect, Option, ReadonlyArray, Schema } from '@livestore/utils/effect'\n\nimport { type SqliteDb, UnexpectedError } from '../adapter-types.js'\nimport { getExecStatementsFromMaterializer, hashMaterializerResults } from '../materializer-helper.js'\nimport type { LiveStoreSchema } from '../schema/mod.js'\nimport { EventSequenceNumber, getEventDef, SystemTables } from '../schema/mod.js'\nimport { insertRow } from '../sql-queries/index.js'\nimport { sql } from '../util.js'\nimport { execSql, execSqlPrepared } from './connection.js'\nimport * as Eventlog from './eventlog.js'\nimport type { MaterializeEvent } from './types.js'\n\nexport const makeMaterializeEvent = ({\n  schema,\n  dbState,\n  dbEventlog,\n}: {\n  schema: LiveStoreSchema\n  dbState: SqliteDb\n  dbEventlog: SqliteDb\n}): Effect.Effect<MaterializeEvent, UnexpectedError> =>\n  Effect.gen(function* () {\n    const eventDefSchemaHashMap = new Map(\n      // TODO Running `Schema.hash` can be a bottleneck for larger schemas. There is an opportunity to run this\n      // at build time and lookup the pre-computed hash at runtime.\n      // Also see https://github.com/Effect-TS/effect/issues/2719\n      [...schema.eventsDefsMap.entries()].map(([k, v]) => [k, Schema.hash(v.schema)] as const),\n    )\n\n    return (eventEncoded, options) =>\n      Effect.gen(function* () {\n        const skipEventlog = options?.skipEventlog ?? false\n\n        const eventName = eventEncoded.name\n        const { eventDef, materializer } = getEventDef(schema, eventName)\n\n        const execArgsArr = getExecStatementsFromMaterializer({\n          eventDef,\n          materializer,\n          dbState,\n          event: { decoded: undefined, encoded: eventEncoded },\n        })\n\n        const materializerHash = isDevEnv() ? Option.some(hashMaterializerResults(execArgsArr)) : Option.none()\n\n        if (\n          materializerHash._tag === 'Some' &&\n          eventEncoded.meta.materializerHashSession._tag === 'Some' &&\n          eventEncoded.meta.materializerHashSession.value !== materializerHash.value\n        ) {\n          yield* UnexpectedError.make({\n            cause: `Materializer hash mismatch detected for event \"${eventEncoded.name}\".`,\n            note: `Please make sure your event materializer is a pure function without side effects.`,\n          })\n        }\n\n        // NOTE we might want to bring this back if we want to debug no-op events\n        // const makeExecuteOptions = (statementSql: string, bindValues: any) => ({\n        //   onRowsChanged: (rowsChanged: number) => {\n        //     if (rowsChanged === 0) {\n        //       console.warn(`Event \"${eventDef.name}\" did not affect any rows:`, statementSql, bindValues)\n        //     }\n        //   },\n        // })\n\n        // console.group('[@livestore/common:leader-thread:materializeEvent]', { eventName })\n\n        const session = dbState.session()\n\n        for (const { statementSql, bindValues } of execArgsArr) {\n          // console.debug(eventName, statementSql, bindValues)\n          // TODO use cached prepared statements instead of exec\n          yield* execSqlPrepared(dbState, statementSql, bindValues)\n        }\n\n        const changeset = session.changeset()\n        session.finish()\n\n        // TODO use prepared statements\n        yield* execSql(\n          dbState,\n          ...insertRow({\n            tableName: SystemTables.SESSION_CHANGESET_META_TABLE,\n            columns: SystemTables.sessionChangesetMetaTable.sqliteDef.columns,\n            values: {\n              seqNumGlobal: eventEncoded.seqNum.global,\n              seqNumClient: eventEncoded.seqNum.client,\n              // NOTE the changeset will be empty (i.e. null) for no-op events\n              changeset: changeset ?? null,\n              debug: LS_DEV ? execArgsArr : null,\n            },\n          }),\n        )\n\n        // console.groupEnd()\n\n        // write to eventlog\n        if (skipEventlog === false) {\n          const eventName = eventEncoded.name\n          const eventDefSchemaHash =\n            eventDefSchemaHashMap.get(eventName) ?? shouldNeverHappen(`Unknown event definition: ${eventName}`)\n\n          yield* Eventlog.insertIntoEventlog(\n            eventEncoded,\n            dbEventlog,\n            eventDefSchemaHash,\n            eventEncoded.clientId,\n            eventEncoded.sessionId,\n          )\n        } else {\n          //   console.debug('[@livestore/common:leader-thread] skipping eventlog write', mutation, statementSql, bindValues)\n        }\n\n        return {\n          sessionChangeset: changeset\n            ? {\n                _tag: 'sessionChangeset' as const,\n                data: changeset,\n                debug: LS_DEV ? execArgsArr : null,\n              }\n            : { _tag: 'no-op' as const },\n          hash: materializerHash,\n        }\n      }).pipe(\n        Effect.withSpan(`@livestore/common:leader-thread:materializeEvent`, {\n          attributes: {\n            eventName: eventEncoded.name,\n            eventNum: eventEncoded.seqNum,\n            'span.label': `${EventSequenceNumber.toString(eventEncoded.seqNum)} ${eventEncoded.name}`,\n          },\n        }),\n        // Effect.logDuration('@livestore/common:leader-thread:materializeEvent'),\n      )\n  })\n\nexport const rollback = ({\n  dbState,\n  dbEventlog,\n  eventNumsToRollback,\n}: {\n  dbState: SqliteDb\n  dbEventlog: SqliteDb\n  eventNumsToRollback: EventSequenceNumber.EventSequenceNumber[]\n}) =>\n  Effect.gen(function* () {\n    const rollbackEvents = dbState\n      .select<SystemTables.SessionChangesetMetaRow>(\n        sql`SELECT * FROM ${SystemTables.SESSION_CHANGESET_META_TABLE} WHERE (seqNumGlobal, seqNumClient) IN (${eventNumsToRollback.map((id) => `(${id.global}, ${id.client})`).join(', ')})`,\n      )\n      .map((_) => ({\n        seqNum: { global: _.seqNumGlobal, client: _.seqNumClient },\n        changeset: _.changeset,\n        debug: _.debug,\n      }))\n      .toSorted((a, b) => EventSequenceNumber.compare(a.seqNum, b.seqNum))\n\n    // Apply changesets in reverse order\n    for (let i = rollbackEvents.length - 1; i >= 0; i--) {\n      const { changeset } = rollbackEvents[i]!\n      if (changeset !== null) {\n        dbState.makeChangeset(changeset).invert().apply()\n      }\n    }\n\n    const eventNumPairChunks = ReadonlyArray.chunksOf(100)(\n      eventNumsToRollback.map((seqNum) => `(${seqNum.global}, ${seqNum.client})`),\n    )\n\n    // Delete the changeset rows\n    for (const eventNumPairChunk of eventNumPairChunks) {\n      dbState.execute(\n        sql`DELETE FROM ${SystemTables.SESSION_CHANGESET_META_TABLE} WHERE (seqNumGlobal, seqNumClient) IN (${eventNumPairChunk.join(', ')})`,\n      )\n    }\n\n    // Delete the eventlog rows\n    for (const eventNumPairChunk of eventNumPairChunks) {\n      dbEventlog.execute(\n        sql`DELETE FROM ${SystemTables.EVENTLOG_META_TABLE} WHERE (seqNumGlobal, seqNumClient) IN (${eventNumPairChunk.join(', ')})`,\n      )\n    }\n  }).pipe(\n    Effect.withSpan('@livestore/common:LeaderSyncProcessor:rollback', {\n      attributes: { count: eventNumsToRollback.length },\n    }),\n  )\n", "import { casesHandled, isNotUndefined, LS_DEV, shouldNeverHappen, TRACE_VERBOSE } from '@livestore/utils'\nimport type { HttpClient, Runtime, Scope, Tracer } from '@livestore/utils/effect'\nimport {\n  BucketQueue,\n  Deferred,\n  Effect,\n  Exit,\n  FiberHandle,\n  Option,\n  OtelTracer,\n  Queue,\n  ReadonlyArray,\n  Stream,\n  Subscribable,\n  SubscriptionRef,\n} from '@livestore/utils/effect'\nimport type * as otel from '@opentelemetry/api'\n\nimport type { SqliteDb } from '../adapter-types.js'\nimport { UnexpectedError } from '../adapter-types.js'\nimport { makeMaterializerHash } from '../materializer-helper.js'\nimport type { LiveStoreSchema } from '../schema/mod.js'\nimport { EventSequenceNumber, getEventDef, LiveStoreEvent, SystemTables } from '../schema/mod.js'\nimport { LeaderAheadError } from '../sync/sync.js'\nimport * as SyncState from '../sync/syncstate.js'\nimport { sql } from '../util.js'\nimport * as Eventlog from './eventlog.js'\nimport { rollback } from './materialize-event.js'\nimport type { InitialBlockingSyncContext, LeaderSyncProcessor } from './types.js'\nimport { LeaderThreadCtx } from './types.js'\n\ntype LocalPushQueueItem = [\n  event: LiveStoreEvent.EncodedWithMeta,\n  deferred: Deferred.Deferred<void, LeaderAheadError> | undefined,\n  /** Used to determine whether the batch has become invalid due to a rejected local push batch */\n  generation: number,\n]\n\n/**\n * The LeaderSyncProcessor manages synchronization of events between\n * the local state and the sync backend, ensuring efficient and orderly processing.\n *\n * In the LeaderSyncProcessor, pulling always has precedence over pushing.\n *\n * Responsibilities:\n * - Queueing incoming local events in a localPushesQueue.\n * - Broadcasting events to client sessions via pull queues.\n * - Pushing events to the sync backend.\n *\n * Notes:\n *\n * local push processing:\n * - localPushesQueue:\n *   - Maintains events in ascending order.\n *   - Uses `Deferred` objects to resolve/reject events based on application success.\n * - Processes events from the queue, applying events in batches.\n * - Controlled by a `Latch` to manage execution flow.\n * - The latch closes on pull receipt and re-opens post-pull completion.\n * - Processes up to `maxBatchSize` events per cycle.\n *\n * Currently we're advancing the db read model and eventlog in lockstep, but we could also decouple this in the future\n *\n * Tricky concurrency scenarios:\n * - Queued local push batches becoming invalid due to a prior local push item being rejected.\n *   Solution: Introduce a generation number for local push batches which is used to filter out old batches items in case of rejection.\n *\n */\nexport const makeLeaderSyncProcessor = ({\n  schema,\n  dbEventlogMissing,\n  dbEventlog,\n  dbState,\n  dbStateMissing,\n  initialBlockingSyncContext,\n  onError,\n  params,\n  testing,\n}: {\n  schema: LiveStoreSchema\n  /** Only used to know whether we can safely query dbEventlog during setup execution */\n  dbEventlogMissing: boolean\n  dbEventlog: SqliteDb\n  dbState: SqliteDb\n  /** Only used to know whether we can safely query dbState during setup execution */\n  dbStateMissing: boolean\n  initialBlockingSyncContext: InitialBlockingSyncContext\n  onError: 'shutdown' | 'ignore'\n  params: {\n    /**\n     * @default 10\n     */\n    localPushBatchSize?: number\n    /**\n     * @default 50\n     */\n    backendPushBatchSize?: number\n  }\n  testing: {\n    delays?: {\n      localPushProcessing?: Effect.Effect<void>\n    }\n  }\n}): Effect.Effect<LeaderSyncProcessor, UnexpectedError, Scope.Scope> =>\n  Effect.gen(function* () {\n    const syncBackendPushQueue = yield* BucketQueue.make<LiveStoreEvent.EncodedWithMeta>()\n    const localPushBatchSize = params.localPushBatchSize ?? 10\n    const backendPushBatchSize = params.backendPushBatchSize ?? 50\n\n    const syncStateSref = yield* SubscriptionRef.make<SyncState.SyncState | undefined>(undefined)\n\n    const isClientEvent = (eventEncoded: LiveStoreEvent.EncodedWithMeta) => {\n      const { eventDef } = getEventDef(schema, eventEncoded.name)\n      return eventDef.options.clientOnly\n    }\n\n    const connectedClientSessionPullQueues = yield* makePullQueueSet\n\n    /**\n     * Tracks generations of queued local push events.\n     * If a local-push batch is rejected, all subsequent push queue items with the same generation are also rejected,\n     * even if they would be valid on their own.\n     */\n    // TODO get rid of this in favour of the `mergeGeneration` event sequence number field\n    const currentLocalPushGenerationRef = { current: 0 }\n\n    type MergeCounter = number\n    const mergeCounterRef = { current: dbStateMissing ? 0 : yield* getMergeCounterFromDb(dbState) }\n    const mergePayloads = new Map<MergeCounter, typeof SyncState.PayloadUpstream.Type>()\n\n    // This context depends on data from `boot`, we should find a better implementation to avoid this ref indirection.\n    const ctxRef = {\n      current: undefined as\n        | undefined\n        | {\n            otelSpan: otel.Span | undefined\n            span: Tracer.Span\n            devtoolsLatch: Effect.Latch | undefined\n            runtime: Runtime.Runtime<LeaderThreadCtx>\n          },\n    }\n\n    const localPushesQueue = yield* BucketQueue.make<LocalPushQueueItem>()\n    const localPushesLatch = yield* Effect.makeLatch(true)\n    const pullLatch = yield* Effect.makeLatch(true)\n\n    /**\n     * Additionally to the `syncStateSref` we also need the `pushHeadRef` in order to prevent old/duplicate\n     * events from being pushed in a scenario like this:\n     * - client session A pushes e1\n     * - leader sync processor takes a bit and hasn't yet taken e1 from the localPushesQueue\n     * - client session B also pushes e1 (which should be rejected)\n     *\n     * Thus the purpoe of the pushHeadRef is the guard the integrity of the local push queue\n     */\n    const pushHeadRef = { current: EventSequenceNumber.ROOT }\n    const advancePushHead = (eventNum: EventSequenceNumber.EventSequenceNumber) => {\n      pushHeadRef.current = EventSequenceNumber.max(pushHeadRef.current, eventNum)\n    }\n\n    // NOTE: New events are only pushed to sync backend after successful local push processing\n    const push: LeaderSyncProcessor['push'] = (newEvents, options) =>\n      Effect.gen(function* () {\n        if (newEvents.length === 0) return\n\n        yield* validatePushBatch(newEvents, pushHeadRef.current)\n\n        advancePushHead(newEvents.at(-1)!.seqNum)\n\n        const waitForProcessing = options?.waitForProcessing ?? false\n        const generation = currentLocalPushGenerationRef.current\n\n        if (waitForProcessing) {\n          const deferreds = yield* Effect.forEach(newEvents, () => Deferred.make<void, LeaderAheadError>())\n\n          const items = newEvents.map(\n            (eventEncoded, i) => [eventEncoded, deferreds[i], generation] as LocalPushQueueItem,\n          )\n\n          yield* BucketQueue.offerAll(localPushesQueue, items)\n\n          yield* Effect.all(deferreds)\n        } else {\n          const items = newEvents.map((eventEncoded) => [eventEncoded, undefined, generation] as LocalPushQueueItem)\n          yield* BucketQueue.offerAll(localPushesQueue, items)\n        }\n      }).pipe(\n        Effect.withSpan('@livestore/common:LeaderSyncProcessor:push', {\n          attributes: {\n            batchSize: newEvents.length,\n            batch: TRACE_VERBOSE ? newEvents : undefined,\n          },\n          links: ctxRef.current?.span ? [{ _tag: 'SpanLink', span: ctxRef.current.span, attributes: {} }] : undefined,\n        }),\n      )\n\n    const pushPartial: LeaderSyncProcessor['pushPartial'] = ({ event: { name, args }, clientId, sessionId }) =>\n      Effect.gen(function* () {\n        const syncState = yield* syncStateSref\n        if (syncState === undefined) return shouldNeverHappen('Not initialized')\n\n        const { eventDef } = getEventDef(schema, name)\n\n        const eventEncoded = new LiveStoreEvent.EncodedWithMeta({\n          name,\n          args,\n          clientId,\n          sessionId,\n          ...EventSequenceNumber.nextPair(syncState.localHead, eventDef.options.clientOnly),\n        })\n\n        yield* push([eventEncoded])\n      }).pipe(Effect.catchTag('LeaderAheadError', Effect.orDie))\n\n    // Starts various background loops\n    const boot: LeaderSyncProcessor['boot'] = Effect.gen(function* () {\n      const span = yield* Effect.currentSpan.pipe(Effect.orDie)\n      const otelSpan = yield* OtelTracer.currentOtelSpan.pipe(Effect.catchAll(() => Effect.succeed(undefined)))\n      const { devtools, shutdownChannel } = yield* LeaderThreadCtx\n      const runtime = yield* Effect.runtime<LeaderThreadCtx>()\n\n      ctxRef.current = {\n        otelSpan,\n        span,\n        devtoolsLatch: devtools.enabled ? devtools.syncBackendLatch : undefined,\n        runtime,\n      }\n\n      const initialLocalHead = dbEventlogMissing ? EventSequenceNumber.ROOT : Eventlog.getClientHeadFromDb(dbEventlog)\n\n      const initialBackendHead = dbEventlogMissing\n        ? EventSequenceNumber.ROOT.global\n        : Eventlog.getBackendHeadFromDb(dbEventlog)\n\n      if (initialBackendHead > initialLocalHead.global) {\n        return shouldNeverHappen(\n          `During boot the backend head (${initialBackendHead}) should never be greater than the local head (${initialLocalHead.global})`,\n        )\n      }\n\n      const pendingEvents = dbEventlogMissing\n        ? []\n        : yield* Eventlog.getEventsSince({ global: initialBackendHead, client: EventSequenceNumber.clientDefault })\n\n      const initialSyncState = new SyncState.SyncState({\n        pending: pendingEvents,\n        upstreamHead: { global: initialBackendHead, client: EventSequenceNumber.clientDefault },\n        localHead: initialLocalHead,\n      })\n\n      /** State transitions need to happen atomically, so we use a Ref to track the state */\n      yield* SubscriptionRef.set(syncStateSref, initialSyncState)\n\n      // Rehydrate sync queue\n      if (pendingEvents.length > 0) {\n        const globalPendingEvents = pendingEvents\n          // Don't sync clientOnly events\n          .filter((eventEncoded) => {\n            const { eventDef } = getEventDef(schema, eventEncoded.name)\n            return eventDef.options.clientOnly === false\n          })\n\n        if (globalPendingEvents.length > 0) {\n          yield* BucketQueue.offerAll(syncBackendPushQueue, globalPendingEvents)\n        }\n      }\n\n      const shutdownOnError = (cause: unknown) =>\n        Effect.gen(function* () {\n          if (onError === 'shutdown') {\n            yield* shutdownChannel.send(UnexpectedError.make({ cause }))\n            yield* Effect.die(cause)\n          }\n        })\n\n      yield* backgroundApplyLocalPushes({\n        localPushesLatch,\n        localPushesQueue,\n        pullLatch,\n        syncStateSref,\n        syncBackendPushQueue,\n        schema,\n        isClientEvent,\n        otelSpan,\n        currentLocalPushGenerationRef,\n        connectedClientSessionPullQueues,\n        mergeCounterRef,\n        mergePayloads,\n        localPushBatchSize,\n        testing: {\n          delay: testing?.delays?.localPushProcessing,\n        },\n      }).pipe(Effect.tapCauseLogPretty, Effect.catchAllCause(shutdownOnError), Effect.forkScoped)\n\n      const backendPushingFiberHandle = yield* FiberHandle.make()\n      const backendPushingEffect = backgroundBackendPushing({\n        syncBackendPushQueue,\n        otelSpan,\n        devtoolsLatch: ctxRef.current?.devtoolsLatch,\n        backendPushBatchSize,\n      }).pipe(Effect.tapCauseLogPretty, Effect.catchAllCause(shutdownOnError))\n\n      yield* FiberHandle.run(backendPushingFiberHandle, backendPushingEffect)\n\n      yield* backgroundBackendPulling({\n        initialBackendHead,\n        isClientEvent,\n        restartBackendPushing: (filteredRebasedPending) =>\n          Effect.gen(function* () {\n            // Stop current pushing fiber\n            yield* FiberHandle.clear(backendPushingFiberHandle)\n\n            // Reset the sync backend push queue\n            yield* BucketQueue.clear(syncBackendPushQueue)\n            yield* BucketQueue.offerAll(syncBackendPushQueue, filteredRebasedPending)\n\n            // Restart pushing fiber\n            yield* FiberHandle.run(backendPushingFiberHandle, backendPushingEffect)\n          }),\n        syncStateSref,\n        localPushesLatch,\n        pullLatch,\n        dbState,\n        otelSpan,\n        initialBlockingSyncContext,\n        devtoolsLatch: ctxRef.current?.devtoolsLatch,\n        connectedClientSessionPullQueues,\n        mergeCounterRef,\n        mergePayloads,\n        advancePushHead,\n      }).pipe(Effect.tapCauseLogPretty, Effect.catchAllCause(shutdownOnError), Effect.forkScoped)\n\n      return { initialLeaderHead: initialLocalHead }\n    }).pipe(Effect.withSpanScoped('@livestore/common:LeaderSyncProcessor:boot'))\n\n    const pull: LeaderSyncProcessor['pull'] = ({ cursor }) =>\n      Effect.gen(function* () {\n        const queue = yield* pullQueue({ cursor })\n        return Stream.fromQueue(queue)\n      }).pipe(Stream.unwrapScoped)\n\n    const pullQueue: LeaderSyncProcessor['pullQueue'] = ({ cursor }) => {\n      const runtime = ctxRef.current?.runtime ?? shouldNeverHappen('Not initialized')\n      return Effect.gen(function* () {\n        const queue = yield* connectedClientSessionPullQueues.makeQueue\n        const payloadsSinceCursor = Array.from(mergePayloads.entries())\n          .map(([mergeCounter, payload]) => ({ payload, mergeCounter }))\n          .filter(({ mergeCounter }) => mergeCounter > cursor.mergeCounter)\n          .toSorted((a, b) => a.mergeCounter - b.mergeCounter)\n          .map(({ payload, mergeCounter }) => {\n            if (payload._tag === 'upstream-advance') {\n              return {\n                payload: {\n                  _tag: 'upstream-advance' as const,\n                  newEvents: ReadonlyArray.dropWhile(payload.newEvents, (eventEncoded) =>\n                    EventSequenceNumber.isGreaterThanOrEqual(cursor.eventNum, eventEncoded.seqNum),\n                  ),\n                },\n                mergeCounter,\n              }\n            } else {\n              return { payload, mergeCounter }\n            }\n          })\n\n        yield* queue.offerAll(payloadsSinceCursor)\n\n        return queue\n      }).pipe(Effect.provide(runtime))\n    }\n\n    const syncState = Subscribable.make({\n      get: Effect.gen(function* () {\n        const syncState = yield* syncStateSref\n        if (syncState === undefined) return shouldNeverHappen('Not initialized')\n        return syncState\n      }),\n      changes: syncStateSref.changes.pipe(Stream.filter(isNotUndefined)),\n    })\n\n    return {\n      pull,\n      pullQueue,\n      push,\n      pushPartial,\n      boot,\n      syncState,\n      getMergeCounter: () => mergeCounterRef.current,\n    } satisfies LeaderSyncProcessor\n  })\n\nconst backgroundApplyLocalPushes = ({\n  localPushesLatch,\n  localPushesQueue,\n  pullLatch,\n  syncStateSref,\n  syncBackendPushQueue,\n  schema,\n  isClientEvent,\n  otelSpan,\n  currentLocalPushGenerationRef,\n  connectedClientSessionPullQueues,\n  mergeCounterRef,\n  mergePayloads,\n  localPushBatchSize,\n  testing,\n}: {\n  pullLatch: Effect.Latch\n  localPushesLatch: Effect.Latch\n  localPushesQueue: BucketQueue.BucketQueue<LocalPushQueueItem>\n  syncStateSref: SubscriptionRef.SubscriptionRef<SyncState.SyncState | undefined>\n  syncBackendPushQueue: BucketQueue.BucketQueue<LiveStoreEvent.EncodedWithMeta>\n  schema: LiveStoreSchema\n  isClientEvent: (eventEncoded: LiveStoreEvent.EncodedWithMeta) => boolean\n  otelSpan: otel.Span | undefined\n  currentLocalPushGenerationRef: { current: number }\n  connectedClientSessionPullQueues: PullQueueSet\n  mergeCounterRef: { current: number }\n  mergePayloads: Map<number, typeof SyncState.PayloadUpstream.Type>\n  localPushBatchSize: number\n  testing: {\n    delay: Effect.Effect<void> | undefined\n  }\n}) =>\n  Effect.gen(function* () {\n    while (true) {\n      if (testing.delay !== undefined) {\n        yield* testing.delay.pipe(Effect.withSpan('localPushProcessingDelay'))\n      }\n\n      const batchItems = yield* BucketQueue.takeBetween(localPushesQueue, 1, localPushBatchSize)\n\n      // Wait for the backend pulling to finish\n      yield* localPushesLatch.await\n\n      // Prevent backend pull processing until this local push is finished\n      yield* pullLatch.close\n\n      // Since the generation might have changed since enqueuing, we need to filter out items with older generation\n      // It's important that we filter after we got localPushesLatch, otherwise we might filter with the old generation\n      const filteredBatchItems = batchItems\n        .filter(([_1, _2, generation]) => generation === currentLocalPushGenerationRef.current)\n        .map(([eventEncoded, deferred]) => [eventEncoded, deferred] as const)\n\n      if (filteredBatchItems.length === 0) {\n        // console.log('dropping old-gen batch', currentLocalPushGenerationRef.current)\n        // Allow the backend pulling to start\n        yield* pullLatch.open\n        continue\n      }\n\n      const [newEvents, deferreds] = ReadonlyArray.unzip(filteredBatchItems)\n\n      const syncState = yield* syncStateSref\n      if (syncState === undefined) return shouldNeverHappen('Not initialized')\n\n      const mergeResult = SyncState.merge({\n        syncState,\n        payload: { _tag: 'local-push', newEvents },\n        isClientEvent,\n        isEqualEvent: LiveStoreEvent.isEqualEncoded,\n      })\n\n      const mergeCounter = yield* incrementMergeCounter(mergeCounterRef)\n\n      switch (mergeResult._tag) {\n        case 'unexpected-error': {\n          otelSpan?.addEvent(`[${mergeCounter}]:push:unexpected-error`, {\n            batchSize: newEvents.length,\n            newEvents: TRACE_VERBOSE ? JSON.stringify(newEvents) : undefined,\n          })\n          return yield* Effect.fail(mergeResult.cause)\n        }\n        case 'rebase': {\n          return shouldNeverHappen('The leader thread should never have to rebase due to a local push')\n        }\n        case 'reject': {\n          otelSpan?.addEvent(`[${mergeCounter}]:push:reject`, {\n            batchSize: newEvents.length,\n            mergeResult: TRACE_VERBOSE ? JSON.stringify(mergeResult) : undefined,\n          })\n\n          // TODO: how to test this?\n          currentLocalPushGenerationRef.current++\n\n          const nextGeneration = currentLocalPushGenerationRef.current\n\n          const providedNum = newEvents.at(0)!.seqNum\n          // All subsequent pushes with same generation should be rejected as well\n          // We're also handling the case where the localPushQueue already contains events\n          // from the next generation which we preserve in the queue\n          const remainingEventsMatchingGeneration = yield* BucketQueue.takeSplitWhere(\n            localPushesQueue,\n            (item) => item[2] >= nextGeneration,\n          )\n\n          // TODO we still need to better understand and handle this scenario\n          if (LS_DEV && (yield* BucketQueue.size(localPushesQueue)) > 0) {\n            console.log('localPushesQueue is not empty', yield* BucketQueue.size(localPushesQueue))\n            // biome-ignore lint/suspicious/noDebugger: <explanation>\n            debugger\n          }\n\n          const allDeferredsToReject = [\n            ...deferreds,\n            ...remainingEventsMatchingGeneration.map(([_, deferred]) => deferred),\n          ].filter(isNotUndefined)\n\n          yield* Effect.forEach(allDeferredsToReject, (deferred) =>\n            Deferred.fail(\n              deferred,\n              LeaderAheadError.make({\n                minimumExpectedNum: mergeResult.expectedMinimumId,\n                providedNum,\n                // nextGeneration,\n              }),\n            ),\n          )\n\n          // Allow the backend pulling to start\n          yield* pullLatch.open\n\n          // In this case we're skipping state update and down/upstream processing\n          // We've cleared the local push queue and are now waiting for new local pushes / backend pulls\n          continue\n        }\n        case 'advance': {\n          break\n        }\n        default: {\n          casesHandled(mergeResult)\n        }\n      }\n\n      yield* SubscriptionRef.set(syncStateSref, mergeResult.newSyncState)\n\n      yield* connectedClientSessionPullQueues.offer({\n        payload: SyncState.PayloadUpstreamAdvance.make({ newEvents: mergeResult.newEvents }),\n        mergeCounter,\n      })\n      mergePayloads.set(mergeCounter, SyncState.PayloadUpstreamAdvance.make({ newEvents: mergeResult.newEvents }))\n\n      otelSpan?.addEvent(`[${mergeCounter}]:push:advance`, {\n        batchSize: newEvents.length,\n        mergeResult: TRACE_VERBOSE ? JSON.stringify(mergeResult) : undefined,\n      })\n\n      // Don't sync clientOnly events\n      const filteredBatch = mergeResult.newEvents.filter((eventEncoded) => {\n        const { eventDef } = getEventDef(schema, eventEncoded.name)\n        return eventDef.options.clientOnly === false\n      })\n\n      yield* BucketQueue.offerAll(syncBackendPushQueue, filteredBatch)\n\n      yield* materializeEventsBatch({ batchItems: mergeResult.newEvents, deferreds })\n\n      // Allow the backend pulling to start\n      yield* pullLatch.open\n    }\n  })\n\ntype MaterializeEventsBatch = (_: {\n  batchItems: ReadonlyArray<LiveStoreEvent.EncodedWithMeta>\n  /**\n   * The deferreds are used by the caller to know when the mutation has been processed.\n   * Indexes are aligned with `batchItems`\n   */\n  deferreds: ReadonlyArray<Deferred.Deferred<void, LeaderAheadError> | undefined> | undefined\n}) => Effect.Effect<void, UnexpectedError, LeaderThreadCtx>\n\n// TODO how to handle errors gracefully\nconst materializeEventsBatch: MaterializeEventsBatch = ({ batchItems, deferreds }) =>\n  Effect.gen(function* () {\n    const { dbState: db, dbEventlog, materializeEvent } = yield* LeaderThreadCtx\n\n    // NOTE We always start a transaction to ensure consistency between db and eventlog (even for single-item batches)\n    db.execute('BEGIN TRANSACTION', undefined) // Start the transaction\n    dbEventlog.execute('BEGIN TRANSACTION', undefined) // Start the transaction\n\n    yield* Effect.addFinalizer((exit) =>\n      Effect.gen(function* () {\n        if (Exit.isSuccess(exit)) return\n\n        // Rollback in case of an error\n        db.execute('ROLLBACK', undefined)\n        dbEventlog.execute('ROLLBACK', undefined)\n      }),\n    )\n\n    for (let i = 0; i < batchItems.length; i++) {\n      const { sessionChangeset, hash } = yield* materializeEvent(batchItems[i]!)\n      batchItems[i]!.meta.sessionChangeset = sessionChangeset\n      batchItems[i]!.meta.materializerHashLeader = hash\n\n      if (deferreds?.[i] !== undefined) {\n        yield* Deferred.succeed(deferreds[i]!, void 0)\n      }\n    }\n\n    db.execute('COMMIT', undefined) // Commit the transaction\n    dbEventlog.execute('COMMIT', undefined) // Commit the transaction\n  }).pipe(\n    Effect.uninterruptible,\n    Effect.scoped,\n    Effect.withSpan('@livestore/common:LeaderSyncProcessor:materializeEventItems', {\n      attributes: { batchSize: batchItems.length },\n    }),\n    Effect.tapCauseLogPretty,\n    UnexpectedError.mapToUnexpectedError,\n  )\n\nconst backgroundBackendPulling = ({\n  initialBackendHead,\n  isClientEvent,\n  restartBackendPushing,\n  otelSpan,\n  dbState,\n  syncStateSref,\n  localPushesLatch,\n  pullLatch,\n  devtoolsLatch,\n  initialBlockingSyncContext,\n  connectedClientSessionPullQueues,\n  mergeCounterRef,\n  mergePayloads,\n  advancePushHead,\n}: {\n  initialBackendHead: EventSequenceNumber.GlobalEventSequenceNumber\n  isClientEvent: (eventEncoded: LiveStoreEvent.EncodedWithMeta) => boolean\n  restartBackendPushing: (\n    filteredRebasedPending: ReadonlyArray<LiveStoreEvent.EncodedWithMeta>,\n  ) => Effect.Effect<void, UnexpectedError, LeaderThreadCtx | HttpClient.HttpClient>\n  otelSpan: otel.Span | undefined\n  syncStateSref: SubscriptionRef.SubscriptionRef<SyncState.SyncState | undefined>\n  dbState: SqliteDb\n  localPushesLatch: Effect.Latch\n  pullLatch: Effect.Latch\n  devtoolsLatch: Effect.Latch | undefined\n  initialBlockingSyncContext: InitialBlockingSyncContext\n  connectedClientSessionPullQueues: PullQueueSet\n  mergeCounterRef: { current: number }\n  mergePayloads: Map<number, typeof SyncState.PayloadUpstream.Type>\n  advancePushHead: (eventNum: EventSequenceNumber.EventSequenceNumber) => void\n}) =>\n  Effect.gen(function* () {\n    const { syncBackend, dbState: db, dbEventlog, schema } = yield* LeaderThreadCtx\n\n    if (syncBackend === undefined) return\n\n    const onNewPullChunk = (newEvents: LiveStoreEvent.EncodedWithMeta[], remaining: number) =>\n      Effect.gen(function* () {\n        if (newEvents.length === 0) return\n\n        if (devtoolsLatch !== undefined) {\n          yield* devtoolsLatch.await\n        }\n\n        // Prevent more local pushes from being processed until this pull is finished\n        yield* localPushesLatch.close\n\n        // Wait for pending local pushes to finish\n        yield* pullLatch.await\n\n        const syncState = yield* syncStateSref\n        if (syncState === undefined) return shouldNeverHappen('Not initialized')\n\n        const mergeResult = SyncState.merge({\n          syncState,\n          payload: SyncState.PayloadUpstreamAdvance.make({ newEvents }),\n          isClientEvent,\n          isEqualEvent: LiveStoreEvent.isEqualEncoded,\n          ignoreClientEvents: true,\n        })\n\n        const mergeCounter = yield* incrementMergeCounter(mergeCounterRef)\n\n        if (mergeResult._tag === 'reject') {\n          return shouldNeverHappen('The leader thread should never reject upstream advances')\n        } else if (mergeResult._tag === 'unexpected-error') {\n          otelSpan?.addEvent(`[${mergeCounter}]:pull:unexpected-error`, {\n            newEventsCount: newEvents.length,\n            newEvents: TRACE_VERBOSE ? JSON.stringify(newEvents) : undefined,\n          })\n          return yield* Effect.fail(mergeResult.cause)\n        }\n\n        const newBackendHead = newEvents.at(-1)!.seqNum\n\n        Eventlog.updateBackendHead(dbEventlog, newBackendHead)\n\n        if (mergeResult._tag === 'rebase') {\n          otelSpan?.addEvent(`[${mergeCounter}]:pull:rebase`, {\n            newEventsCount: newEvents.length,\n            newEvents: TRACE_VERBOSE ? JSON.stringify(newEvents) : undefined,\n            rollbackCount: mergeResult.rollbackEvents.length,\n            mergeResult: TRACE_VERBOSE ? JSON.stringify(mergeResult) : undefined,\n          })\n\n          const globalRebasedPendingEvents = mergeResult.newSyncState.pending.filter((event) => {\n            const { eventDef } = getEventDef(schema, event.name)\n            return eventDef.options.clientOnly === false\n          })\n          yield* restartBackendPushing(globalRebasedPendingEvents)\n\n          if (mergeResult.rollbackEvents.length > 0) {\n            yield* rollback({\n              dbState: db,\n              dbEventlog,\n              eventNumsToRollback: mergeResult.rollbackEvents.map((_) => _.seqNum),\n            })\n          }\n\n          yield* connectedClientSessionPullQueues.offer({\n            payload: SyncState.PayloadUpstreamRebase.make({\n              newEvents: mergeResult.newEvents,\n              rollbackEvents: mergeResult.rollbackEvents,\n            }),\n            mergeCounter,\n          })\n          mergePayloads.set(\n            mergeCounter,\n            SyncState.PayloadUpstreamRebase.make({\n              newEvents: mergeResult.newEvents,\n              rollbackEvents: mergeResult.rollbackEvents,\n            }),\n          )\n        } else {\n          otelSpan?.addEvent(`[${mergeCounter}]:pull:advance`, {\n            newEventsCount: newEvents.length,\n            mergeResult: TRACE_VERBOSE ? JSON.stringify(mergeResult) : undefined,\n          })\n\n          yield* connectedClientSessionPullQueues.offer({\n            payload: SyncState.PayloadUpstreamAdvance.make({ newEvents: mergeResult.newEvents }),\n            mergeCounter,\n          })\n          mergePayloads.set(mergeCounter, SyncState.PayloadUpstreamAdvance.make({ newEvents: mergeResult.newEvents }))\n\n          if (mergeResult.confirmedEvents.length > 0) {\n            // `mergeResult.confirmedEvents` don't contain the correct sync metadata, so we need to use\n            // `newEvents` instead which we filter via `mergeResult.confirmedEvents`\n            const confirmedNewEvents = newEvents.filter((event) =>\n              mergeResult.confirmedEvents.some((confirmedEvent) =>\n                EventSequenceNumber.isEqual(event.seqNum, confirmedEvent.seqNum),\n              ),\n            )\n            yield* Eventlog.updateSyncMetadata(confirmedNewEvents)\n          }\n        }\n\n        // Removes the changeset rows which are no longer needed as we'll never have to rollback beyond this point\n        trimChangesetRows(db, newBackendHead)\n\n        advancePushHead(mergeResult.newSyncState.localHead)\n\n        yield* materializeEventsBatch({ batchItems: mergeResult.newEvents, deferreds: undefined })\n\n        yield* SubscriptionRef.set(syncStateSref, mergeResult.newSyncState)\n\n        // Allow local pushes to be processed again\n        if (remaining === 0) {\n          yield* localPushesLatch.open\n        }\n      })\n\n    const cursorInfo = yield* Eventlog.getSyncBackendCursorInfo(initialBackendHead)\n\n    const hashMaterializerResult = makeMaterializerHash({ schema, dbState })\n\n    yield* syncBackend.pull(cursorInfo).pipe(\n      // TODO only take from queue while connected\n      Stream.tap(({ batch, remaining }) =>\n        Effect.gen(function* () {\n          // yield* Effect.spanEvent('batch', {\n          //   attributes: {\n          //     batchSize: batch.length,\n          //     batch: TRACE_VERBOSE ? batch : undefined,\n          //   },\n          // })\n\n          // NOTE we only want to take process events when the sync backend is connected\n          // (e.g. needed for simulating being offline)\n          // TODO remove when there's a better way to handle this in stream above\n          yield* SubscriptionRef.waitUntil(syncBackend.isConnected, (isConnected) => isConnected === true)\n\n          yield* onNewPullChunk(\n            batch.map((_) =>\n              LiveStoreEvent.EncodedWithMeta.fromGlobal(_.eventEncoded, {\n                syncMetadata: _.metadata,\n                materializerHashLeader: hashMaterializerResult(_.eventEncoded),\n                materializerHashSession: Option.none(),\n              }),\n            ),\n            remaining,\n          )\n\n          yield* initialBlockingSyncContext.update({ processed: batch.length, remaining })\n        }),\n      ),\n      Stream.runDrain,\n      Effect.interruptible,\n    )\n  }).pipe(Effect.withSpan('@livestore/common:LeaderSyncProcessor:backend-pulling'))\n\nconst backgroundBackendPushing = ({\n  syncBackendPushQueue,\n  otelSpan,\n  devtoolsLatch,\n  backendPushBatchSize,\n}: {\n  syncBackendPushQueue: BucketQueue.BucketQueue<LiveStoreEvent.EncodedWithMeta>\n  otelSpan: otel.Span | undefined\n  devtoolsLatch: Effect.Latch | undefined\n  backendPushBatchSize: number\n}) =>\n  Effect.gen(function* () {\n    const { syncBackend } = yield* LeaderThreadCtx\n    if (syncBackend === undefined) return\n\n    while (true) {\n      yield* SubscriptionRef.waitUntil(syncBackend.isConnected, (isConnected) => isConnected === true)\n\n      const queueItems = yield* BucketQueue.takeBetween(syncBackendPushQueue, 1, backendPushBatchSize)\n\n      yield* SubscriptionRef.waitUntil(syncBackend.isConnected, (isConnected) => isConnected === true)\n\n      if (devtoolsLatch !== undefined) {\n        yield* devtoolsLatch.await\n      }\n\n      otelSpan?.addEvent('backend-push', {\n        batchSize: queueItems.length,\n        batch: TRACE_VERBOSE ? JSON.stringify(queueItems) : undefined,\n      })\n\n      // TODO handle push errors (should only happen during concurrent pull+push)\n      const pushResult = yield* syncBackend.push(queueItems.map((_) => _.toGlobal())).pipe(Effect.either)\n\n      if (pushResult._tag === 'Left') {\n        if (LS_DEV) {\n          yield* Effect.logDebug('handled backend-push-error', { error: pushResult.left.toString() })\n        }\n        otelSpan?.addEvent('backend-push-error', { error: pushResult.left.toString() })\n        // wait for interrupt caused by background pulling which will then restart pushing\n        return yield* Effect.never\n      }\n    }\n  }).pipe(Effect.interruptible, Effect.withSpan('@livestore/common:LeaderSyncProcessor:backend-pushing'))\n\nconst trimChangesetRows = (db: SqliteDb, newHead: EventSequenceNumber.EventSequenceNumber) => {\n  // Since we're using the session changeset rows to query for the current head,\n  // we're keeping at least one row for the current head, and thus are using `<` instead of `<=`\n  db.execute(sql`DELETE FROM ${SystemTables.SESSION_CHANGESET_META_TABLE} WHERE seqNumGlobal < ${newHead.global}`)\n}\n\ninterface PullQueueSet {\n  makeQueue: Effect.Effect<\n    Queue.Queue<{ payload: typeof SyncState.PayloadUpstream.Type; mergeCounter: number }>,\n    UnexpectedError,\n    Scope.Scope | LeaderThreadCtx\n  >\n  offer: (item: {\n    payload: typeof SyncState.PayloadUpstream.Type\n    mergeCounter: number\n  }) => Effect.Effect<void, UnexpectedError>\n}\n\nconst makePullQueueSet = Effect.gen(function* () {\n  const set = new Set<Queue.Queue<{ payload: typeof SyncState.PayloadUpstream.Type; mergeCounter: number }>>()\n\n  yield* Effect.addFinalizer(() =>\n    Effect.gen(function* () {\n      for (const queue of set) {\n        yield* Queue.shutdown(queue)\n      }\n\n      set.clear()\n    }),\n  )\n\n  const makeQueue: PullQueueSet['makeQueue'] = Effect.gen(function* () {\n    const queue = yield* Queue.unbounded<{\n      payload: typeof SyncState.PayloadUpstream.Type\n      mergeCounter: number\n    }>().pipe(Effect.acquireRelease(Queue.shutdown))\n\n    yield* Effect.addFinalizer(() => Effect.sync(() => set.delete(queue)))\n\n    set.add(queue)\n\n    return queue\n  })\n\n  const offer: PullQueueSet['offer'] = (item) =>\n    Effect.gen(function* () {\n      // Short-circuit if the payload is an empty upstream advance\n      if (item.payload._tag === 'upstream-advance' && item.payload.newEvents.length === 0) {\n        return\n      }\n\n      for (const queue of set) {\n        yield* Queue.offer(queue, item)\n      }\n    })\n\n  return {\n    makeQueue,\n    offer,\n  }\n})\n\nconst incrementMergeCounter = (mergeCounterRef: { current: number }) =>\n  Effect.gen(function* () {\n    const { dbState } = yield* LeaderThreadCtx\n    mergeCounterRef.current++\n    dbState.execute(\n      sql`INSERT OR REPLACE INTO ${SystemTables.LEADER_MERGE_COUNTER_TABLE} (id, mergeCounter) VALUES (0, ${mergeCounterRef.current})`,\n    )\n    return mergeCounterRef.current\n  })\n\nconst getMergeCounterFromDb = (dbState: SqliteDb) =>\n  Effect.gen(function* () {\n    const result = dbState.select<{ mergeCounter: number }>(\n      sql`SELECT mergeCounter FROM ${SystemTables.LEADER_MERGE_COUNTER_TABLE} WHERE id = 0`,\n    )\n    return result[0]?.mergeCounter ?? 0\n  })\n\nconst validatePushBatch = (\n  batch: ReadonlyArray<LiveStoreEvent.EncodedWithMeta>,\n  pushHead: EventSequenceNumber.EventSequenceNumber,\n) =>\n  Effect.gen(function* () {\n    if (batch.length === 0) {\n      return\n    }\n\n    // Make sure batch is monotonically increasing\n    for (let i = 1; i < batch.length; i++) {\n      if (EventSequenceNumber.isGreaterThanOrEqual(batch[i - 1]!.seqNum, batch[i]!.seqNum)) {\n        shouldNeverHappen(\n          `Events must be ordered in monotonically ascending order by eventNum. Received: [${batch.map((e) => EventSequenceNumber.toString(e.seqNum)).join(', ')}]`,\n        )\n      }\n    }\n\n    // Make sure smallest sequence number is > pushHead\n    if (EventSequenceNumber.isGreaterThanOrEqual(pushHead, batch[0]!.seqNum)) {\n      return yield* LeaderAheadError.make({\n        minimumExpectedNum: pushHead,\n        providedNum: batch[0]!.seqNum,\n      })\n    }\n  })\n", "import { casesHandled } from '@livestore/utils'\nimport type { HttpClient } from '@livestore/utils/effect'\nimport { Effect, Queue } from '@livestore/utils/effect'\n\nimport type { InvalidPullError, IsOfflineError, MigrationHooks, MigrationsReport, SqliteError } from '../index.js'\nimport { migrateDb, rematerializeFromEventlog, UnexpectedError } from '../index.js'\nimport { configureConnection } from './connection.js'\nimport { LeaderThreadCtx } from './types.js'\n\nexport const recreateDb: Effect.Effect<\n  { migrationsReport: MigrationsReport },\n  UnexpectedError | SqliteError | IsOfflineError | InvalidPullError,\n  LeaderThreadCtx | HttpClient.HttpClient\n> = Effect.gen(function* () {\n  const { dbState, dbEventlog, schema, bootStatusQueue, materializeEvent } = yield* LeaderThreadCtx\n\n  const migrationOptions = schema.state.sqlite.migrations\n  let migrationsReport: MigrationsReport\n\n  yield* Effect.addFinalizer(\n    Effect.fn('recreateDb:finalizer')(function* (ex) {\n      if (ex._tag === 'Failure') dbState.destroy()\n    }),\n  )\n\n  // NOTE to speed up the operations below, we're creating a temporary in-memory database\n  // and later we'll overwrite the persisted database with the new data\n  // TODO bring back this optimization\n  // const tmpDb = yield* makeSqliteDb({ _tag: 'in-memory' })\n  const tmpDb = dbState\n  yield* configureConnection(tmpDb, { foreignKeys: true })\n\n  const initDb = (hooks: Partial<MigrationHooks> | undefined) =>\n    Effect.gen(function* () {\n      yield* Effect.tryAll(() => hooks?.init?.(tmpDb)).pipe(UnexpectedError.mapToUnexpectedError)\n\n      const migrationsReport = yield* migrateDb({\n        db: tmpDb,\n        schema,\n        onProgress: ({ done, total }) =>\n          Queue.offer(bootStatusQueue, { stage: 'migrating', progress: { done, total } }),\n      })\n\n      yield* Effect.tryAll(() => hooks?.pre?.(tmpDb)).pipe(UnexpectedError.mapToUnexpectedError)\n\n      return { migrationsReport, tmpDb }\n    })\n\n  switch (migrationOptions.strategy) {\n    case 'auto': {\n      const hooks = migrationOptions.hooks\n      const initResult = yield* initDb(hooks)\n\n      migrationsReport = initResult.migrationsReport\n\n      yield* rematerializeFromEventlog({\n        // db: initResult.tmpDb,\n        dbEventlog,\n        schema,\n        materializeEvent,\n        onProgress: ({ done, total }) =>\n          Queue.offer(bootStatusQueue, { stage: 'rehydrating', progress: { done, total } }),\n      })\n\n      yield* Effect.tryAll(() => hooks?.post?.(initResult.tmpDb)).pipe(UnexpectedError.mapToUnexpectedError)\n\n      break\n    }\n    case 'manual': {\n      const oldDbData = dbState.export()\n\n      migrationsReport = { migrations: [] }\n\n      const newDbData = yield* Effect.tryAll(() => migrationOptions.migrate(oldDbData)).pipe(\n        UnexpectedError.mapToUnexpectedError,\n      )\n\n      tmpDb.import(newDbData)\n\n      // TODO validate schema\n\n      break\n    }\n    default: {\n      casesHandled(migrationOptions)\n    }\n  }\n\n  // TODO bring back\n  // Import the temporary in-memory database into the persistent database\n  // yield* Effect.sync(() => db.import(tmpDb)).pipe(\n  //   Effect.withSpan('@livestore/common:leader-thread:recreateDb:import'),\n  // )\n\n  // TODO maybe bring back re-using this initial snapshot to avoid calling `.export()` again\n  // We've disabled this for now as it made the code too complex, as we often run syncing right after\n  // so the snapshot is no longer up to date\n  // const snapshotFromTmpDb = tmpDb.export()\n\n  // TODO bring back\n  // tmpDb.close()\n\n  return { migrationsReport }\n}).pipe(\n  Effect.scoped, // NOTE we're closing the scope here so finalizers are called when the effect is done\n  Effect.withSpan('@livestore/common:leader-thread:recreateDb'),\n  Effect.withPerformanceMeasure('@livestore/common:leader-thread:recreateDb'),\n)\n", "import type { HttpClient, Schema, Scope } from '@livestore/utils/effect'\nimport { Deferred, Effect, Layer, Queue, SubscriptionRef } from '@livestore/utils/effect'\n\nimport type { BootStatus, MakeSqliteDb, SqliteError } from '../adapter-types.js'\nimport { UnexpectedError } from '../adapter-types.js'\nimport type * as Devtools from '../devtools/mod.js'\nimport type { LiveStoreSchema } from '../schema/mod.js'\nimport { LiveStoreEvent } from '../schema/mod.js'\nimport type { InvalidPullError, IsOfflineError, SyncOptions } from '../sync/sync.js'\nimport { sql } from '../util.js'\nimport * as Eventlog from './eventlog.js'\nimport { bootDevtools } from './leader-worker-devtools.js'\nimport { makeLeaderSyncProcessor } from './LeaderSyncProcessor.js'\nimport { makeMaterializeEvent } from './materialize-event.js'\nimport { recreateDb } from './recreate-db.js'\nimport type { ShutdownChannel } from './shutdown-channel.js'\nimport type {\n  DevtoolsOptions,\n  InitialBlockingSyncContext,\n  InitialSyncOptions,\n  LeaderSqliteDb,\n  ShutdownState,\n} from './types.js'\nimport { LeaderThreadCtx } from './types.js'\n\nexport interface MakeLeaderThreadLayerParams {\n  storeId: string\n  syncPayload: Schema.JsonValue | undefined\n  clientId: string\n  schema: LiveStoreSchema\n  makeSqliteDb: MakeSqliteDb\n  syncOptions: SyncOptions | undefined\n  dbState: LeaderSqliteDb\n  dbEventlog: LeaderSqliteDb\n  devtoolsOptions: DevtoolsOptions\n  shutdownChannel: ShutdownChannel\n  params?: {\n    localPushBatchSize?: number\n    backendPushBatchSize?: number\n  }\n  testing?: {\n    syncProcessor?: {\n      delays?: {\n        localPushProcessing?: Effect.Effect<void>\n      }\n    }\n  }\n}\n\nexport const makeLeaderThreadLayer = ({\n  schema,\n  storeId,\n  clientId,\n  syncPayload,\n  makeSqliteDb,\n  syncOptions,\n  dbState,\n  dbEventlog,\n  devtoolsOptions,\n  shutdownChannel,\n  params,\n  testing,\n}: MakeLeaderThreadLayerParams): Layer.Layer<LeaderThreadCtx, UnexpectedError, Scope.Scope | HttpClient.HttpClient> =>\n  Effect.gen(function* () {\n    const bootStatusQueue = yield* Queue.unbounded<BootStatus>().pipe(Effect.acquireRelease(Queue.shutdown))\n\n    // TODO do more validation here than just checking the count of tables\n    // Either happens on initial boot or if schema changes\n    const dbEventlogMissing =\n      dbEventlog.select<{ count: number }>(sql`select count(*) as count from sqlite_master`)[0]!.count === 0\n\n    const dbStateMissing =\n      dbState.select<{ count: number }>(sql`select count(*) as count from sqlite_master`)[0]!.count === 0\n\n    const syncBackend =\n      syncOptions?.backend === undefined\n        ? undefined\n        : yield* syncOptions.backend({ storeId, clientId, payload: syncPayload })\n\n    if (syncBackend !== undefined) {\n      // We're already connecting to the sync backend concurrently\n      yield* syncBackend.connect.pipe(Effect.tapCauseLogPretty, Effect.forkScoped)\n    }\n\n    const initialBlockingSyncContext = yield* makeInitialBlockingSyncContext({\n      initialSyncOptions: syncOptions?.initialSyncOptions ?? { _tag: 'Skip' },\n      bootStatusQueue,\n    })\n\n    const syncProcessor = yield* makeLeaderSyncProcessor({\n      schema,\n      dbEventlogMissing,\n      dbEventlog,\n      dbState,\n      dbStateMissing,\n      initialBlockingSyncContext,\n      onError: syncOptions?.onSyncError ?? 'ignore',\n      params: {\n        localPushBatchSize: params?.localPushBatchSize,\n        backendPushBatchSize: params?.backendPushBatchSize,\n      },\n      testing: {\n        delays: testing?.syncProcessor?.delays,\n      },\n    })\n\n    const extraIncomingMessagesQueue = yield* Queue.unbounded<Devtools.Leader.MessageToApp>().pipe(\n      Effect.acquireRelease(Queue.shutdown),\n    )\n\n    const devtoolsContext = devtoolsOptions.enabled\n      ? {\n          enabled: true as const,\n          syncBackendLatch: yield* Effect.makeLatch(true),\n          syncBackendLatchState: yield* SubscriptionRef.make<{ latchClosed: boolean }>({ latchClosed: false }),\n        }\n      : { enabled: false as const }\n\n    const materializeEvent = yield* makeMaterializeEvent({ schema, dbState, dbEventlog })\n\n    const ctx = {\n      schema,\n      bootStatusQueue,\n      storeId,\n      clientId,\n      dbState,\n      dbEventlog,\n      makeSqliteDb,\n      eventSchema: LiveStoreEvent.makeEventDefSchema(schema),\n      shutdownStateSubRef: yield* SubscriptionRef.make<ShutdownState>('running'),\n      shutdownChannel,\n      syncBackend,\n      syncProcessor,\n      materializeEvent,\n      extraIncomingMessagesQueue,\n      devtools: devtoolsContext,\n      // State will be set during `bootLeaderThread`\n      initialState: {} as any as LeaderThreadCtx['Type']['initialState'],\n    } satisfies typeof LeaderThreadCtx.Service\n\n    // @ts-expect-error For debugging purposes\n    globalThis.__leaderThreadCtx = ctx\n\n    const layer = Layer.succeed(LeaderThreadCtx, ctx)\n\n    ctx.initialState = yield* bootLeaderThread({\n      dbStateMissing,\n      initialBlockingSyncContext,\n      devtoolsOptions,\n    }).pipe(Effect.provide(layer))\n\n    return layer\n  }).pipe(\n    Effect.withSpan('@livestore/common:leader-thread:boot'),\n    Effect.withSpanScoped('@livestore/common:leader-thread'),\n    UnexpectedError.mapToUnexpectedError,\n    Effect.tapCauseLogPretty,\n    Layer.unwrapScoped,\n  )\n\nconst makeInitialBlockingSyncContext = ({\n  initialSyncOptions,\n  bootStatusQueue,\n}: {\n  initialSyncOptions: InitialSyncOptions\n  bootStatusQueue: Queue.Queue<BootStatus>\n}) =>\n  Effect.gen(function* () {\n    const ctx = {\n      isDone: false,\n      processedEvents: 0,\n      total: -1,\n    }\n\n    const blockingDeferred = initialSyncOptions._tag === 'Blocking' ? yield* Deferred.make<void>() : undefined\n\n    if (blockingDeferred !== undefined && initialSyncOptions._tag === 'Blocking') {\n      yield* Deferred.succeed(blockingDeferred, void 0).pipe(\n        Effect.delay(initialSyncOptions.timeout),\n        Effect.forkScoped,\n      )\n    }\n\n    return {\n      blockingDeferred,\n      update: ({ processed, remaining }) =>\n        Effect.gen(function* () {\n          if (ctx.isDone === true) return\n\n          if (ctx.total === -1) {\n            ctx.total = remaining + processed\n          }\n\n          ctx.processedEvents += processed\n          yield* Queue.offer(bootStatusQueue, {\n            stage: 'syncing',\n            progress: { done: ctx.processedEvents, total: ctx.total },\n          })\n\n          if (remaining === 0 && blockingDeferred !== undefined) {\n            yield* Deferred.succeed(blockingDeferred, void 0)\n            ctx.isDone = true\n          }\n        }),\n    } satisfies InitialBlockingSyncContext\n  })\n\n/**\n * Blocks until the leader thread has finished its initial setup.\n * It also starts various background processes (e.g. syncing)\n */\nconst bootLeaderThread = ({\n  dbStateMissing,\n  initialBlockingSyncContext,\n  devtoolsOptions,\n}: {\n  dbStateMissing: boolean\n  initialBlockingSyncContext: InitialBlockingSyncContext\n  devtoolsOptions: DevtoolsOptions\n}): Effect.Effect<\n  LeaderThreadCtx['Type']['initialState'],\n  UnexpectedError | SqliteError | IsOfflineError | InvalidPullError,\n  LeaderThreadCtx | Scope.Scope | HttpClient.HttpClient\n> =>\n  Effect.gen(function* () {\n    const { dbEventlog, bootStatusQueue, syncProcessor } = yield* LeaderThreadCtx\n\n    yield* Eventlog.initEventlogDb(dbEventlog)\n\n    const { migrationsReport } = dbStateMissing ? yield* recreateDb : { migrationsReport: { migrations: [] } }\n\n    // NOTE the sync processor depends on the dbs being initialized properly\n    const { initialLeaderHead } = yield* syncProcessor.boot\n\n    if (initialBlockingSyncContext.blockingDeferred !== undefined) {\n      // Provides a syncing status right away before the first pull response comes in\n      yield* Queue.offer(bootStatusQueue, {\n        stage: 'syncing',\n        progress: { done: 0, total: -1 },\n      })\n\n      yield* initialBlockingSyncContext.blockingDeferred.pipe(\n        Effect.withSpan('@livestore/common:leader-thread:initial-sync-blocking'),\n      )\n    }\n\n    yield* Queue.offer(bootStatusQueue, { stage: 'done' })\n\n    yield* bootDevtools(devtoolsOptions).pipe(Effect.tapCauseLogPretty, Effect.forkScoped)\n\n    return { migrationsReport, leaderHead: initialLeaderHead }\n  })\n", "import type { WebChannel } from '@livestore/utils/effect'\nimport { Schema } from '@livestore/utils/effect'\n\nimport { IntentionalShutdownCause, UnexpectedError } from '../index.js'\n\nexport class All extends Schema.Union(IntentionalShutdownCause, UnexpectedError) {}\n\n/**\n * Used internally by an adapter to shutdown gracefully.\n */\nexport type ShutdownChannel = WebChannel.WebChannel<typeof All.Type, typeof All.Type>\n", "import { Schema, Transferable } from '@livestore/utils/effect'\n\nexport class CreateConnection extends Schema.TaggedRequest<CreateConnection>()('DevtoolsWebCommon.CreateConnection', {\n  payload: {\n    from: Schema.String,\n    port: Transferable.MessagePort,\n  },\n  success: Schema.Struct({}),\n  failure: Schema.Never,\n}) {}\n\nexport class Request extends Schema.Union(CreateConnection) {}\n", "import { LS_DEV } from '@livestore/utils'\nimport { Context, Effect, Layer, Stream, WebChannel } from '@livestore/utils/effect'\nimport type { MeshNode } from '@livestore/webmesh'\nimport { makeMeshNode, WebmeshSchema } from '@livestore/webmesh'\n\nimport type * as SharedWorkerSchema from './schema.js'\n\nexport * as Schema from './schema.js'\n\nexport class CacheService extends Context.Tag('@livestore/devtools-web-common:CacheService')<\n  CacheService,\n  { node: MeshNode }\n>() {\n  static layer = ({ nodeName }: { nodeName: string }) =>\n    Effect.gen(function* () {\n      const node = yield* makeMeshNode(nodeName)\n\n      globalThis.__debugWebmeshNode = node\n\n      return { node }\n    }).pipe(Layer.scoped(CacheService))\n}\n\nexport const CreateConnection = ({ from, port }: typeof SharedWorkerSchema.CreateConnection.Type) =>\n  Stream.asyncScoped<{}, never, CacheService>((emit) =>\n    Effect.gen(function* () {\n      const { node } = yield* CacheService\n\n      const messagePortChannel = yield* WebChannel.messagePortChannel({ port, schema: WebmeshSchema.Packet })\n\n      yield* node.addEdge({ target: from, edgeChannel: messagePortChannel, replaceIfExists: true })\n\n      if (LS_DEV) {\n        yield* Effect.logDebug(`@livestore/devtools-web-common: accepted edge: ${node.nodeName} ← ${from}`)\n      }\n\n      emit.single({})\n\n      yield* Effect.spanEvent({ connectedTo: [...node.edgeKeys] })\n\n      // Keep connection alive\n      // yield* Effect.never\n\n      // return {}\n    }).pipe(Effect.orDie),\n  ).pipe(Stream.withSpan(`@livestore/devtools-web-common:worker:create-connection:${from}`))\n", "import type * as WaSqlite from '@livestore/wa-sqlite'\nimport { MemoryVFS } from '@livestore/wa-sqlite/src/examples/MemoryVFS.js'\n\nlet cachedMemoryVfs: MemoryVFS | undefined\n\nexport const makeInMemoryDb = (sqlite3: WaSqlite.SQLiteAPI) => {\n  if (sqlite3.vfs_registered.has('memory-vfs') === false) {\n    // @ts-expect-error TODO fix types\n    const vfs = new MemoryVFS('memory-vfs', (sqlite3 as any).module)\n\n    // @ts-expect-error TODO fix types\n    sqlite3.vfs_register(vfs, false)\n    cachedMemoryVfs = vfs\n  }\n\n  const dbPointer = sqlite3.open_v2Sync(':memory:', undefined, 'memory-vfs')\n  const vfs = cachedMemoryVfs!\n\n  return { dbPointer, vfs }\n}\n", "import type {\n  PersistenceInfo,\n  PreparedBindValues,\n  PreparedStatement,\n  SqliteDb,\n  SqliteDbChangeset,\n} from '@livestore/common'\nimport { SqliteDbHelper, SqliteError } from '@livestore/common'\nimport * as SqliteConstants from '@livestore/wa-sqlite/src/sqlite-constants.js'\n\nimport { makeInMemoryDb } from './in-memory-vfs.js'\n\nexport const makeSqliteDb = <\n  TMetadata extends {\n    dbPointer: number\n    persistenceInfo: PersistenceInfo\n    deleteDb: () => void\n    configureDb: (db: SqliteDb<TMetadata>) => void\n  },\n>({\n  sqlite3,\n  metadata,\n}: {\n  sqlite3: SQLiteAPI\n  metadata: TMetadata\n}): SqliteDb<TMetadata> => {\n  const preparedStmts: PreparedStatement[] = []\n  const { dbPointer } = metadata\n\n  let isClosed = false\n\n  const sqliteDb: SqliteDb<TMetadata> = {\n    _tag: 'SqliteDb',\n    metadata,\n    prepare: (queryStr) => {\n      try {\n        const stmts = sqlite3.statements(dbPointer, queryStr.trim(), { unscoped: true })\n\n        let isFinalized = false\n\n        const preparedStmt = {\n          execute: (bindValues, options) => {\n            for (const stmt of stmts) {\n              if (bindValues !== undefined && Object.keys(bindValues).length > 0) {\n                sqlite3.bind_collection(stmt, bindValues as any)\n              }\n\n              try {\n                sqlite3.step(stmt)\n              } finally {\n                if (options?.onRowsChanged) {\n                  options.onRowsChanged(sqlite3.changes(dbPointer))\n                }\n\n                sqlite3.reset(stmt) // Reset is needed for next execution\n              }\n            }\n          },\n          select: <T>(bindValues: PreparedBindValues) => {\n            if (stmts.length !== 1) {\n              throw new SqliteError({\n                query: { bindValues, sql: queryStr },\n                code: -1,\n                cause: 'Expected only one statement when using `select`',\n              })\n            }\n\n            const stmt = stmts[0]!\n\n            if (bindValues !== undefined && Object.keys(bindValues).length > 0) {\n              sqlite3.bind_collection(stmt, bindValues as any)\n            }\n\n            const results: T[] = []\n\n            try {\n              // NOTE `column_names` only works for `SELECT` statements, ignoring other statements for now\n              let columns = undefined\n              try {\n                columns = sqlite3.column_names(stmt)\n                // eslint-disable-next-line @typescript-eslint/no-unused-vars\n              } catch (_e) {}\n\n              while (sqlite3.step(stmt) === SqliteConstants.SQLITE_ROW) {\n                if (columns !== undefined) {\n                  const obj: { [key: string]: any } = {}\n                  for (let i = 0; i < columns.length; i++) {\n                    obj[columns[i]!] = sqlite3.column(stmt, i)\n                  }\n                  results.push(obj as unknown as T)\n                }\n              }\n            } catch (e) {\n              throw new SqliteError({\n                query: { bindValues, sql: queryStr },\n                code: (e as any).code,\n                cause: e,\n              })\n            } finally {\n              // reset the cached statement so we can use it again in the future\n              sqlite3.reset(stmt)\n            }\n\n            return results\n          },\n          finalize: () => {\n            // Avoid double finalization which leads to a crash\n            if (isFinalized) {\n              return\n            }\n\n            isFinalized = true\n\n            for (const stmt of stmts) {\n              sqlite3.finalize(stmt)\n            }\n          },\n          sql: queryStr,\n        } satisfies PreparedStatement\n\n        preparedStmts.push(preparedStmt)\n\n        return preparedStmt\n      } catch (e) {\n        throw new SqliteError({\n          query: { sql: queryStr, bindValues: {} },\n          code: (e as any).code,\n          cause: e,\n        })\n      }\n    },\n    export: () => sqlite3.serialize(dbPointer, 'main'),\n    execute: SqliteDbHelper.makeExecute((queryStr, bindValues, options) => {\n      const stmt = sqliteDb.prepare(queryStr)\n      stmt.execute(bindValues, options)\n      stmt.finalize()\n    }),\n    select: SqliteDbHelper.makeSelect((queryStr, bindValues) => {\n      const stmt = sqliteDb.prepare(queryStr)\n      const results = stmt.select(bindValues)\n      stmt.finalize()\n      return results as ReadonlyArray<any>\n    }),\n    destroy: () => {\n      sqliteDb.close()\n\n      metadata.deleteDb()\n      // if (metadata._tag === 'opfs') {\n      //   metadata.vfs.resetAccessHandle(metadata.fileName)\n      // }\n    },\n    close: () => {\n      if (isClosed) {\n        return\n      }\n\n      for (const stmt of preparedStmts) {\n        stmt.finalize()\n      }\n      sqlite3.close(dbPointer)\n      isClosed = true\n    },\n    import: (source) => {\n      // https://www.sqlite.org/c3ref/c_deserialize_freeonclose.html\n      // #define SQLITE_DESERIALIZE_FREEONCLOSE 1 /* Call sqlite3_free() on close */\n      // #define SQLITE_DESERIALIZE_RESIZEABLE  2 /* Resize using sqlite3_realloc64() */\n      // #define SQLITE_DESERIALIZE_READONLY    4 /* Database is read-only */\n      const FREE_ON_CLOSE = 1\n      const RESIZEABLE = 2\n\n      // NOTE in case we'll have a future use-case where we need a read-only database, we can reuse this code below\n      // if (readOnly === true) {\n      //   sqlite3.deserialize(db, 'main', bytes, bytes.length, bytes.length, FREE_ON_CLOSE | RESIZEABLE)\n      // } else {\n      if (source instanceof Uint8Array) {\n        const tmpDb = makeInMemoryDb(sqlite3)\n        // TODO find a way to do this more efficiently with sqlite to avoid either of the deserialize + backup call\n        // Maybe this can be done via the VFS API\n        sqlite3.deserialize(tmpDb.dbPointer, 'main', source, source.length, source.length, FREE_ON_CLOSE | RESIZEABLE)\n        sqlite3.backup(dbPointer, 'main', tmpDb.dbPointer, 'main')\n        sqlite3.close(tmpDb.dbPointer)\n      } else {\n        sqlite3.backup(dbPointer, 'main', source.metadata.dbPointer, 'main')\n      }\n\n      metadata.configureDb(sqliteDb)\n    },\n    session: () => {\n      const sessionPointer = sqlite3.session_create(dbPointer, 'main')\n      sqlite3.session_attach(sessionPointer, null)\n\n      return {\n        changeset: () => {\n          const res = sqlite3.session_changeset(sessionPointer)\n          return res.changeset ?? undefined\n        },\n        finish: () => {\n          sqlite3.session_delete(sessionPointer)\n        },\n      }\n    },\n    makeChangeset: (data) => {\n      const changeset = {\n        invert: () => {\n          const inverted = sqlite3.changeset_invert(data)\n          return sqliteDb.makeChangeset(inverted)\n        },\n        apply: () => {\n          try {\n            sqlite3.changeset_apply(dbPointer, data)\n            // @ts-expect-error data should be garbage collected after use\n            // biome-ignore lint/style/noParameterAssign:\n            data = undefined\n          } catch (cause: any) {\n            throw new SqliteError({\n              code: cause.code ?? -1,\n              cause,\n              note: `Failed calling makeChangeset.apply`,\n            })\n          }\n        },\n      } satisfies SqliteDbChangeset\n\n      return changeset\n    },\n  } satisfies SqliteDb<TMetadata>\n\n  metadata.configureDb(sqliteDb)\n\n  return sqliteDb\n}\n", "/* eslint-disable prefer-arrow/prefer-arrow-functions */\n\n// Based on https://github.com/rhashimoto/wa-sqlite/blob/master/src/examples/AccessHandlePoolVFS.js\nimport * as VFS from '@livestore/wa-sqlite/src/VFS.js'\n\nimport { FacadeVFS } from '../../FacadeVFS.js'\n\nconst SECTOR_SIZE = 4096\n\n// Each OPFS file begins with a fixed-size header with metadata. The\n// contents of the file follow immediately after the header.\nconst HEADER_MAX_PATH_SIZE = 512\nconst HEADER_FLAGS_SIZE = 4\nconst HEADER_DIGEST_SIZE = 8\nconst HEADER_CORPUS_SIZE = HEADER_MAX_PATH_SIZE + HEADER_FLAGS_SIZE\nconst HEADER_OFFSET_FLAGS = HEADER_MAX_PATH_SIZE\nconst HEADER_OFFSET_DIGEST = HEADER_CORPUS_SIZE\nconst HEADER_OFFSET_DATA = SECTOR_SIZE\n\n// These file types are expected to persist in the file system outside\n// a session. Other files will be removed on VFS start.\nconst PERSISTENT_FILE_TYPES =\n  VFS.SQLITE_OPEN_MAIN_DB | VFS.SQLITE_OPEN_MAIN_JOURNAL | VFS.SQLITE_OPEN_SUPER_JOURNAL | VFS.SQLITE_OPEN_WAL\n\nconst DEFAULT_CAPACITY = 6\n\n/**\n * This VFS uses the updated Access Handle API with all synchronous methods\n * on FileSystemSyncAccessHandle (instead of just read and write). It will\n * work with the regular SQLite WebAssembly build, i.e. the one without\n * Asyncify.\n */\nexport class AccessHandlePoolVFS extends FacadeVFS {\n  log = null //function(...args) { console.log(`[${contextName}]`, ...args) };\n\n  // All the OPFS files the VFS uses are contained in one flat directory\n  // specified in the constructor. No other files should be written here.\n  #directoryPath\n  #directoryHandle: FileSystemDirectoryHandle | undefined\n\n  // The OPFS files all have randomly-generated names that do not match\n  // the SQLite files whose data they contain. This map links those names\n  // with their respective OPFS access handles.\n  #mapAccessHandleToName = new Map<FileSystemSyncAccessHandle, string>()\n\n  // When a SQLite file is associated with an OPFS file, that association\n  // is kept in #mapPathToAccessHandle. Each access handle is in exactly\n  // one of #mapPathToAccessHandle or #availableAccessHandles.\n  #mapPathToAccessHandle = new Map<string, FileSystemSyncAccessHandle>()\n  #availableAccessHandles = new Set<FileSystemSyncAccessHandle>()\n\n  #mapIdToFile = new Map<number, { path: string; flags: number; accessHandle: FileSystemSyncAccessHandle }>()\n\n  static async create(name: string, directoryPath: string, module: any) {\n    const vfs = new AccessHandlePoolVFS(name, directoryPath, module)\n    await vfs.isReady()\n    return vfs\n  }\n\n  constructor(name: string, directoryPath: string, module: any) {\n    super(name, module)\n    this.#directoryPath = directoryPath\n  }\n\n  getOpfsFileName(zName: string) {\n    const path = this.#getPath(zName)\n    const accessHandle = this.#mapPathToAccessHandle.get(path)!\n    return this.#mapAccessHandleToName.get(accessHandle)!\n  }\n\n  resetAccessHandle(zName: string) {\n    const path = this.#getPath(zName)\n    const accessHandle = this.#mapPathToAccessHandle.get(path)!\n    accessHandle.truncate(HEADER_OFFSET_DATA)\n    // accessHandle.write(new Uint8Array(), { at: HEADER_OFFSET_DATA })\n    // accessHandle.flush()\n  }\n\n  jOpen(zName: string, fileId: number, flags: number, pOutFlags: DataView): number {\n    try {\n      // First try to open a path that already exists in the file system.\n      const path = zName ? this.#getPath(zName) : Math.random().toString(36)\n      let accessHandle = this.#mapPathToAccessHandle.get(path)\n      if (!accessHandle && flags & VFS.SQLITE_OPEN_CREATE) {\n        // File not found so try to create it.\n        if (this.getSize() < this.getCapacity()) {\n          // Choose an unassociated OPFS file from the pool.\n          ;[accessHandle] = this.#availableAccessHandles.keys()\n          this.#setAssociatedPath(accessHandle!, path, flags)\n        } else {\n          // Out of unassociated files. This can be fixed by calling\n          // addCapacity() from the application.\n          throw new Error('cannot create file')\n        }\n      }\n      if (!accessHandle) {\n        throw new Error('file not found')\n      }\n      // Subsequent methods are only passed the fileId, so make sure we have\n      // a way to get the file resources.\n      const file = { path, flags, accessHandle }\n      this.#mapIdToFile.set(fileId, file)\n\n      pOutFlags.setInt32(0, flags, true)\n      return VFS.SQLITE_OK\n    } catch (e: any) {\n      console.error(e.message)\n      return VFS.SQLITE_CANTOPEN\n    }\n  }\n\n  jClose(fileId: number): number {\n    const file = this.#mapIdToFile.get(fileId)\n    if (file) {\n      file.accessHandle.flush()\n      this.#mapIdToFile.delete(fileId)\n      if (file.flags & VFS.SQLITE_OPEN_DELETEONCLOSE) {\n        this.#deletePath(file.path)\n      }\n    }\n    return VFS.SQLITE_OK\n  }\n\n  jRead(fileId: number, pData: Uint8Array, iOffset: number): number {\n    const file = this.#mapIdToFile.get(fileId)!\n    const nBytes = file.accessHandle.read(pData.subarray(), { at: HEADER_OFFSET_DATA + iOffset })\n    if (nBytes < pData.byteLength) {\n      pData.fill(0, nBytes, pData.byteLength)\n      return VFS.SQLITE_IOERR_SHORT_READ\n    }\n    return VFS.SQLITE_OK\n  }\n\n  jWrite(fileId: number, pData: Uint8Array, iOffset: number): number {\n    const file = this.#mapIdToFile.get(fileId)!\n    const nBytes = file.accessHandle.write(pData.subarray(), { at: HEADER_OFFSET_DATA + iOffset })\n    return nBytes === pData.byteLength ? VFS.SQLITE_OK : VFS.SQLITE_IOERR\n  }\n\n  jTruncate(fileId: number, iSize: number): number {\n    const file = this.#mapIdToFile.get(fileId)!\n    file.accessHandle.truncate(HEADER_OFFSET_DATA + iSize)\n    return VFS.SQLITE_OK\n  }\n\n  jSync(fileId: number, _flags: number): number {\n    const file = this.#mapIdToFile.get(fileId)!\n    file.accessHandle.flush()\n    return VFS.SQLITE_OK\n  }\n\n  jFileSize(fileId: number, pSize64: DataView): number {\n    const file = this.#mapIdToFile.get(fileId)!\n    const size = file.accessHandle.getSize() - HEADER_OFFSET_DATA\n    pSize64.setBigInt64(0, BigInt(size), true)\n    return VFS.SQLITE_OK\n  }\n\n  jSectorSize(_fileId: number): number {\n    return SECTOR_SIZE\n  }\n\n  jDeviceCharacteristics(_fileId: number): number {\n    return VFS.SQLITE_IOCAP_UNDELETABLE_WHEN_OPEN\n  }\n\n  jAccess(zName: string, flags: number, pResOut: DataView): number {\n    const path = this.#getPath(zName)\n    pResOut.setInt32(0, this.#mapPathToAccessHandle.has(path) ? 1 : 0, true)\n    return VFS.SQLITE_OK\n  }\n\n  jDelete(zName: string, _syncDir: number): number {\n    const path = this.#getPath(zName)\n    this.#deletePath(path)\n    return VFS.SQLITE_OK\n  }\n\n  async close() {\n    this.#releaseAccessHandles()\n  }\n\n  async isReady() {\n    if (!this.#directoryHandle) {\n      // All files are stored in a single directory.\n      let handle = await navigator.storage.getDirectory()\n      for (const d of this.#directoryPath.split('/')) {\n        if (d) {\n          handle = await handle.getDirectoryHandle(d, { create: true })\n        }\n      }\n      this.#directoryHandle = handle\n\n      await this.#acquireAccessHandles()\n      if (this.getCapacity() === 0) {\n        await this.addCapacity(DEFAULT_CAPACITY)\n      }\n    }\n    return true\n  }\n\n  /**\n   * Returns the number of SQLite files in the file system.\n   */\n  getSize(): number {\n    return this.#mapPathToAccessHandle.size\n  }\n\n  /**\n   * Returns the maximum number of SQLite files the file system can hold.\n   */\n  getCapacity(): number {\n    return this.#mapAccessHandleToName.size\n  }\n\n  /**\n   * Increase the capacity of the file system by n.\n   */\n  async addCapacity(n: number): Promise<number> {\n    for (let i = 0; i < n; ++i) {\n      const name = Math.random().toString(36).replace('0.', '')\n      const handle = await this.#directoryHandle!.getFileHandle(name, { create: true })\n      const accessHandle = await handle.createSyncAccessHandle()\n      this.#mapAccessHandleToName.set(accessHandle, name)\n\n      this.#setAssociatedPath(accessHandle, '', 0)\n    }\n    return n\n  }\n\n  /**\n   * Decrease the capacity of the file system by n. The capacity cannot be\n   * decreased to fewer than the current number of SQLite files in the\n   * file system.\n   */\n  async removeCapacity(n: number): Promise<number> {\n    let nRemoved = 0\n    for (const accessHandle of Array.from(this.#availableAccessHandles)) {\n      if (nRemoved == n || this.getSize() === this.getCapacity()) return nRemoved\n\n      const name = this.#mapAccessHandleToName.get(accessHandle)!\n      accessHandle.close()\n      await this.#directoryHandle!.removeEntry(name)\n      this.#mapAccessHandleToName.delete(accessHandle)\n      this.#availableAccessHandles.delete(accessHandle)\n      ++nRemoved\n    }\n    return nRemoved\n  }\n\n  async #acquireAccessHandles() {\n    // Enumerate all the files in the directory.\n    const files = [] as [string, FileSystemFileHandle][]\n    for await (const [name, handle] of this.#directoryHandle!) {\n      if (handle.kind === 'file') {\n        files.push([name, handle])\n      }\n    }\n\n    // Open access handles in parallel, separating associated and unassociated.\n    await Promise.all(\n      files.map(async ([name, handle]) => {\n        const accessHandle = await handle.createSyncAccessHandle()\n        this.#mapAccessHandleToName.set(accessHandle, name)\n        const path = this.#getAssociatedPath(accessHandle)\n        if (path) {\n          this.#mapPathToAccessHandle.set(path, accessHandle)\n        } else {\n          this.#availableAccessHandles.add(accessHandle)\n        }\n      }),\n    )\n  }\n\n  #releaseAccessHandles() {\n    for (const accessHandle of this.#mapAccessHandleToName.keys()) {\n      accessHandle.close()\n    }\n    this.#mapAccessHandleToName.clear()\n    this.#mapPathToAccessHandle.clear()\n    this.#availableAccessHandles.clear()\n  }\n\n  /**\n   * Read and return the associated path from an OPFS file header.\n   * Empty string is returned for an unassociated OPFS file.\n   * @returns {string} path or empty string\n   */\n  #getAssociatedPath(accessHandle: FileSystemSyncAccessHandle): string {\n    // Read the path and digest of the path from the file.\n    const corpus = new Uint8Array(HEADER_CORPUS_SIZE)\n    accessHandle.read(corpus, { at: 0 })\n\n    // Delete files not expected to be present.\n    const dataView = new DataView(corpus.buffer, corpus.byteOffset)\n    const flags = dataView.getUint32(HEADER_OFFSET_FLAGS)\n    if (corpus[0] && (flags & VFS.SQLITE_OPEN_DELETEONCLOSE || (flags & PERSISTENT_FILE_TYPES) === 0)) {\n      console.warn(`Remove file with unexpected flags ${flags.toString(16)}`)\n      this.#setAssociatedPath(accessHandle, '', 0)\n      return ''\n    }\n\n    const fileDigest = new Uint32Array(HEADER_DIGEST_SIZE / 4)\n    accessHandle.read(fileDigest, { at: HEADER_OFFSET_DIGEST })\n\n    // Verify the digest.\n    const computedDigest = this.#computeDigest(corpus)\n    if (fileDigest.every((value, i) => value === computedDigest[i])) {\n      // Good digest. Decode the null-terminated path string.\n      const pathBytes = corpus.indexOf(0)\n      if (pathBytes === 0) {\n        // Ensure that unassociated files are empty. Unassociated files are\n        // truncated in #setAssociatedPath after the header is written. If\n        // an interruption occurs right before the truncation then garbage\n        // may remain in the file.\n        accessHandle.truncate(HEADER_OFFSET_DATA)\n      }\n      return new TextDecoder().decode(corpus.subarray(0, pathBytes))\n    } else {\n      // Bad digest. Repair this header.\n      console.warn('Disassociating file with bad digest.')\n      this.#setAssociatedPath(accessHandle, '', 0)\n      return ''\n    }\n  }\n\n  /**\n   * Set the path on an OPFS file header.\n   */\n  #setAssociatedPath(accessHandle: FileSystemSyncAccessHandle, path: string, flags: number) {\n    // Convert the path string to UTF-8.\n    const corpus = new Uint8Array(HEADER_CORPUS_SIZE)\n    const encodedResult = new TextEncoder().encodeInto(path, corpus)\n    if (encodedResult.written >= HEADER_MAX_PATH_SIZE) {\n      throw new Error('path too long')\n    }\n\n    // Add the creation flags.\n    const dataView = new DataView(corpus.buffer, corpus.byteOffset)\n    dataView.setUint32(HEADER_OFFSET_FLAGS, flags)\n\n    // Write the OPFS file header, including the digest.\n    const digest = this.#computeDigest(corpus)\n    accessHandle.write(corpus, { at: 0 })\n    accessHandle.write(digest, { at: HEADER_OFFSET_DIGEST })\n    accessHandle.flush()\n\n    if (path) {\n      this.#mapPathToAccessHandle.set(path, accessHandle)\n      this.#availableAccessHandles.delete(accessHandle)\n    } else {\n      // This OPFS file doesn't represent any SQLite file so it doesn't\n      // need to keep any data.\n      accessHandle.truncate(HEADER_OFFSET_DATA)\n      this.#availableAccessHandles.add(accessHandle)\n    }\n  }\n\n  /**\n   * We need a synchronous digest function so can't use WebCrypto.\n   * Adapted from https://github.com/bryc/code/blob/master/jshash/experimental/cyrb53.js\n   * @returns {ArrayBuffer} 64-bit digest\n   */\n  #computeDigest(corpus: Uint8Array): Uint32Array {\n    if (!corpus[0]) {\n      // Optimization for deleted file.\n      return new Uint32Array([0xfe_cc_5f_80, 0xac_ce_c0_37])\n    }\n\n    let h1 = 0xde_ad_be_ef\n    let h2 = 0x41_c6_ce_57\n\n    for (const value of corpus) {\n      h1 = Math.imul(h1 ^ value, 2_654_435_761)\n      h2 = Math.imul(h2 ^ value, 1_597_334_677)\n    }\n\n    h1 = Math.imul(h1 ^ (h1 >>> 16), 2_246_822_507) ^ Math.imul(h2 ^ (h2 >>> 13), 3_266_489_909)\n    h2 = Math.imul(h2 ^ (h2 >>> 16), 2_246_822_507) ^ Math.imul(h1 ^ (h1 >>> 13), 3_266_489_909)\n\n    return new Uint32Array([h1 >>> 0, h2 >>> 0])\n  }\n\n  /**\n   * Convert a bare filename, path, or URL to a UNIX-style path.\n   */\n  #getPath(nameOrURL: string | URL): string {\n    const url = typeof nameOrURL === 'string' ? new URL(nameOrURL, 'file://localhost/') : nameOrURL\n    return url.pathname\n  }\n\n  /**\n   * Remove the association between a path and an OPFS file.\n   * @param {string} path\n   */\n  #deletePath(path: string) {\n    const accessHandle = this.#mapPathToAccessHandle.get(path)\n    if (accessHandle) {\n      // Un-associate the SQLite path from the OPFS file.\n      this.#mapPathToAccessHandle.delete(path)\n      this.#setAssociatedPath(accessHandle, '', 0)\n    }\n  }\n}\n", "// Based on https://github.com/rhashimoto/wa-sqlite/blob/master/src/FacadeVFS.js\n\n/* eslint-disable unicorn/prefer-code-point */\n/* eslint-disable @typescript-eslint/no-unused-vars */\n/* eslint-disable prefer-arrow/prefer-arrow-functions */\n// eslint-disable-next-line @typescript-eslint/ban-ts-comment\n// @ts-nocheck\nimport * as VFS from '@livestore/wa-sqlite/src/VFS.js'\n\nconst AsyncFunction = Object.getPrototypeOf(async () => {}).constructor\n\nexport class FacadeVFS extends VFS.Base {\n  /**\n   * @param {string} name\n   * @param {object} module\n   */\n  constructor(name, module) {\n    super(name, module)\n  }\n\n  /**\n   * Override to indicate which methods are asynchronous.\n   * @param {string} methodName\n   * @returns {boolean}\n   */\n  hasAsyncMethod(methodName) {\n    // The input argument is a string like \"xOpen\", so convert to \"jOpen\".\n    // Then check if the method exists and is async.\n    const jMethodName = `j${methodName.slice(1)}`\n    return this[jMethodName] instanceof AsyncFunction\n  }\n\n  /**\n   * Return the filename for a file id for use by mixins.\n   * @param {number} pFile\n   * @returns {string}\n   */\n  getFilename(pFile) {\n    throw new Error('unimplemented')\n  }\n\n  /**\n   * @param {string?} filename\n   * @param {number} pFile\n   * @param {number} flags\n   * @param {DataView} pOutFlags\n   * @returns {number|Promise<number>}\n   */\n  jOpen(filename, pFile, flags, pOutFlags): number {\n    return VFS.SQLITE_CANTOPEN\n  }\n\n  /**\n   * @param {string} filename\n   * @param {number} syncDir\n   * @returns {number|Promise<number>}\n   */\n  jDelete(filename, syncDir): number {\n    return VFS.SQLITE_OK\n  }\n\n  /**\n   * @param {string} filename\n   * @param {number} flags\n   * @param {DataView} pResOut\n   * @returns {number|Promise<number>}\n   */\n  jAccess(filename, flags, pResOut): number {\n    return VFS.SQLITE_OK\n  }\n\n  /**\n   * @param {string} filename\n   * @param {Uint8Array} zOut\n   * @returns {number|Promise<number>}\n   */\n  jFullPathname(filename, zOut): number {\n    // Copy the filename to the output buffer.\n    const { read, written } = new TextEncoder().encodeInto(filename, zOut)\n    if (read < filename.length) return VFS.SQLITE_IOERR\n    if (written >= zOut.length) return VFS.SQLITE_IOERR\n    zOut[written] = 0\n    return VFS.SQLITE_OK\n  }\n\n  /**\n   * @param {Uint8Array} zBuf\n   * @returns {number|Promise<number>}\n   */\n  jGetLastError(zBuf) {\n    return VFS.SQLITE_OK\n  }\n\n  /**\n   * @param {number} pFile\n   * @returns {number|Promise<number>}\n   */\n  jClose(pFile): number {\n    return VFS.SQLITE_OK\n  }\n\n  /**\n   * @param {number} pFile\n   * @param {Uint8Array} pData\n   * @param {number} iOffset\n   * @returns {number|Promise<number>}\n   */\n  jRead(pFile, pData, iOffset): number {\n    pData.fill(0)\n    return VFS.SQLITE_IOERR_SHORT_READ\n  }\n\n  /**\n   * @param {number} pFile\n   * @param {Uint8Array} pData\n   * @param {number} iOffset\n   * @returns {number|Promise<number>}\n   */\n  jWrite(pFile, pData, iOffset): number {\n    return VFS.SQLITE_IOERR_WRITE\n  }\n\n  /**\n   * @param {number} pFile\n   * @param {number} size\n   * @returns {number|Promise<number>}\n   */\n  jTruncate(pFile, size): number {\n    return VFS.SQLITE_OK\n  }\n\n  /**\n   * @param {number} pFile\n   * @param {number} flags\n   * @returns {number|Promise<number>}\n   */\n  jSync(pFile, flags): number {\n    return VFS.SQLITE_OK\n  }\n\n  /**\n   * @param {number} pFile\n   * @param {DataView} pSize\n   * @returns {number|Promise<number>}\n   */\n  jFileSize(pFile, pSize): number {\n    return VFS.SQLITE_OK\n  }\n\n  /**\n   * @param {number} pFile\n   * @param {number} lockType\n   * @returns {number|Promise<number>}\n   */\n  jLock(pFile, lockType): number {\n    return VFS.SQLITE_OK\n  }\n\n  /**\n   * @param {number} pFile\n   * @param {number} lockType\n   * @returns {number|Promise<number>}\n   */\n  jUnlock(pFile, lockType): number {\n    return VFS.SQLITE_OK\n  }\n\n  /**\n   * @param {number} pFile\n   * @param {DataView} pResOut\n   * @returns {number|Promise<number>}\n   */\n  jCheckReservedLock(pFile, pResOut): number {\n    pResOut.setInt32(0, 0, true)\n    return VFS.SQLITE_OK\n  }\n\n  /**\n   * @param {number} pFile\n   * @param {number} op\n   * @param {DataView} pArg\n   * @returns {number|Promise<number>}\n   */\n  jFileControl(pFile, op, pArg): number {\n    return VFS.SQLITE_NOTFOUND\n  }\n\n  /**\n   * @param {number} pFile\n   * @returns {number|Promise<number>}\n   */\n  jSectorSize(pFile): number {\n    return super.xSectorSize(pFile)\n  }\n\n  /**\n   * @param {number} pFile\n   * @returns {number|Promise<number>}\n   */\n  jDeviceCharacteristics(pFile): number {\n    return 0\n  }\n\n  /**\n   * @param {number} pVfs\n   * @param {number} zName\n   * @param {number} pFile\n   * @param {number} flags\n   * @param {number} pOutFlags\n   * @returns {number|Promise<number>}\n   */\n  xOpen(pVfs, zName, pFile, flags, pOutFlags): number {\n    const filename = this.#decodeFilename(zName, flags)\n    const pOutFlagsView = this.#makeTypedDataView('Int32', pOutFlags)\n    this['log']?.('jOpen', filename, pFile, '0x' + flags.toString(16))\n    return this.jOpen(filename, pFile, flags, pOutFlagsView)\n  }\n\n  /**\n   * @param {number} pVfs\n   * @param {number} zName\n   * @param {number} syncDir\n   * @returns {number|Promise<number>}\n   */\n  xDelete(pVfs, zName, syncDir) {\n    const filename = this._module.UTF8ToString(zName)\n    this['log']?.('jDelete', filename, syncDir)\n    return this.jDelete(filename, syncDir)\n  }\n\n  /**\n   * @param {number} pVfs\n   * @param {number} zName\n   * @param {number} flags\n   * @param {number} pResOut\n   * @returns {number|Promise<number>}\n   */\n  xAccess(pVfs, zName, flags, pResOut) {\n    const filename = this._module.UTF8ToString(zName)\n    const pResOutView = this.#makeTypedDataView('Int32', pResOut)\n    this['log']?.('jAccess', filename, flags)\n    return this.jAccess(filename, flags, pResOutView)\n  }\n\n  /**\n   * @param {number} pVfs\n   * @param {number} zName\n   * @param {number} nOut\n   * @param {number} zOut\n   * @returns {number|Promise<number>}\n   */\n  xFullPathname(pVfs, zName, nOut, zOut) {\n    const filename = this._module.UTF8ToString(zName)\n    const zOutArray = this._module.HEAPU8.subarray(zOut, zOut + nOut)\n    this['log']?.('jFullPathname', filename, nOut)\n    return this.jFullPathname(filename, zOutArray)\n  }\n\n  /**\n   * @param {number} pVfs\n   * @param {number} nBuf\n   * @param {number} zBuf\n   * @returns {number|Promise<number>}\n   */\n  xGetLastError(pVfs, nBuf, zBuf) {\n    const zBufArray = this._module.HEAPU8.subarray(zBuf, zBuf + nBuf)\n    this['log']?.('jGetLastError', nBuf)\n    return this.jGetLastError(zBufArray)\n  }\n\n  /**\n   * @param {number} pFile\n   * @returns {number|Promise<number>}\n   */\n  xClose(pFile) {\n    this['log']?.('jClose', pFile)\n    return this.jClose(pFile)\n  }\n\n  /**\n   * @param {number} pFile\n   * @param {number} pData\n   * @param {number} iAmt\n   * @param {number} iOffsetLo\n   * @param {number} iOffsetHi\n   * @returns {number|Promise<number>}\n   */\n  xRead(pFile, pData, iAmt, iOffsetLo, iOffsetHi) {\n    const pDataArray = this.#makeDataArray(pData, iAmt)\n    const iOffset = delegalize(iOffsetLo, iOffsetHi)\n    this['log']?.('jRead', pFile, iAmt, iOffset)\n    return this.jRead(pFile, pDataArray, iOffset)\n  }\n\n  /**\n   * @param {number} pFile\n   * @param {number} pData\n   * @param {number} iAmt\n   * @param {number} iOffsetLo\n   * @param {number} iOffsetHi\n   * @returns {number|Promise<number>}\n   */\n  xWrite(pFile, pData, iAmt, iOffsetLo, iOffsetHi) {\n    const pDataArray = this.#makeDataArray(pData, iAmt)\n    const iOffset = delegalize(iOffsetLo, iOffsetHi)\n    this['log']?.('jWrite', pFile, pDataArray, iOffset)\n    return this.jWrite(pFile, pDataArray, iOffset)\n  }\n\n  /**\n   * @param {number} pFile\n   * @param {number} sizeLo\n   * @param {number} sizeHi\n   * @returns {number|Promise<number>}\n   */\n  xTruncate(pFile, sizeLo, sizeHi) {\n    const size = delegalize(sizeLo, sizeHi)\n    this['log']?.('jTruncate', pFile, size)\n    return this.jTruncate(pFile, size)\n  }\n\n  /**\n   * @param {number} pFile\n   * @param {number} flags\n   * @returns {number|Promise<number>}\n   */\n  xSync(pFile, flags) {\n    this['log']?.('jSync', pFile, flags)\n    return this.jSync(pFile, flags)\n  }\n\n  /**\n   *\n   * @param {number} pFile\n   * @param {number} pSize\n   * @returns {number|Promise<number>}\n   */\n  xFileSize(pFile, pSize) {\n    const pSizeView = this.#makeTypedDataView('BigInt64', pSize)\n    this['log']?.('jFileSize', pFile)\n    return this.jFileSize(pFile, pSizeView)\n  }\n\n  /**\n   * @param {number} pFile\n   * @param {number} lockType\n   * @returns {number|Promise<number>}\n   */\n  xLock(pFile, lockType) {\n    this['log']?.('jLock', pFile, lockType)\n    return this.jLock(pFile, lockType)\n  }\n\n  /**\n   * @param {number} pFile\n   * @param {number} lockType\n   * @returns {number|Promise<number>}\n   */\n  xUnlock(pFile, lockType) {\n    this['log']?.('jUnlock', pFile, lockType)\n    return this.jUnlock(pFile, lockType)\n  }\n\n  /**\n   * @param {number} pFile\n   * @param {number} pResOut\n   * @returns {number|Promise<number>}\n   */\n  xCheckReservedLock(pFile, pResOut) {\n    const pResOutView = this.#makeTypedDataView('Int32', pResOut)\n    this['log']?.('jCheckReservedLock', pFile)\n    return this.jCheckReservedLock(pFile, pResOutView)\n  }\n\n  /**\n   * @param {number} pFile\n   * @param {number} op\n   * @param {number} pArg\n   * @returns {number|Promise<number>}\n   */\n  xFileControl(pFile, op, pArg) {\n    const pArgView = new DataView(this._module.HEAPU8.buffer, this._module.HEAPU8.byteOffset + pArg)\n    this['log']?.('jFileControl', pFile, op, pArgView)\n    return this.jFileControl(pFile, op, pArgView)\n  }\n\n  /**\n   * @param {number} pFile\n   * @returns {number|Promise<number>}\n   */\n  xSectorSize(pFile) {\n    this['log']?.('jSectorSize', pFile)\n    return this.jSectorSize(pFile)\n  }\n\n  /**\n   * @param {number} pFile\n   * @returns {number|Promise<number>}\n   */\n  xDeviceCharacteristics(pFile) {\n    this['log']?.('jDeviceCharacteristics', pFile)\n    return this.jDeviceCharacteristics(pFile)\n  }\n\n  /**\n   * Wrapped DataView for pointer arguments.\n   * Pointers to a single value are passed using DataView. A Proxy\n   * wrapper prevents use of incorrect type or endianness.\n   * @param {'Int32'|'BigInt64'} type\n   * @param {number} byteOffset\n   * @returns {DataView}\n   */\n  #makeTypedDataView(type, byteOffset) {\n    const byteLength = type === 'Int32' ? 4 : 8\n    const getter = `get${type}`\n    const setter = `set${type}`\n    const makeDataView = () =>\n      new DataView(this._module.HEAPU8.buffer, this._module.HEAPU8.byteOffset + byteOffset, byteLength)\n    let dataView = makeDataView()\n    return new Proxy(dataView, {\n      get(_, prop) {\n        if (dataView.buffer.byteLength === 0) {\n          // WebAssembly memory resize detached the buffer.\n          dataView = makeDataView()\n        }\n        if (prop === getter) {\n          return function (byteOffset, littleEndian) {\n            if (!littleEndian) throw new Error('must be little endian')\n            return dataView[prop](byteOffset, littleEndian)\n          }\n        }\n        if (prop === setter) {\n          return function (byteOffset, value, littleEndian) {\n            if (!littleEndian) throw new Error('must be little endian')\n            return dataView[prop](byteOffset, value, littleEndian)\n          }\n        }\n        if (typeof prop === 'string' && /^(get)|(set)/.test(prop)) {\n          throw new Error('invalid type')\n        }\n        const result = dataView[prop]\n        return typeof result === 'function' ? result.bind(dataView) : result\n      },\n    })\n  }\n\n  /**\n   * @param {number} byteOffset\n   * @param {number} byteLength\n   */\n  #makeDataArray(byteOffset, byteLength) {\n    let target = this._module.HEAPU8.subarray(byteOffset, byteOffset + byteLength)\n    return new Proxy(target, {\n      get: (_, prop, receiver) => {\n        if (target.buffer.byteLength === 0) {\n          // WebAssembly memory resize detached the buffer.\n          target = this._module.HEAPU8.subarray(byteOffset, byteOffset + byteLength)\n        }\n        const result = target[prop]\n        return typeof result === 'function' ? result.bind(target) : result\n      },\n    })\n  }\n\n  #decodeFilename(zName, flags) {\n    if (flags & VFS.SQLITE_OPEN_URI) {\n      // The first null-terminated string is the URI path. Subsequent\n      // strings are query parameter keys and values.\n      // https://www.sqlite.org/c3ref/open.html#urifilenamesinsqlite3open\n      let pName = zName\n      let state = 1\n      const charCodes = []\n      while (state) {\n        const charCode = this._module.HEAPU8[pName++]\n        if (charCode) {\n          charCodes.push(charCode)\n        } else {\n          if (!this._module.HEAPU8[pName]) state = null\n          switch (state) {\n            case 1: {\n              // path\n              charCodes.push('?'.charCodeAt(0))\n              state = 2\n              break\n            }\n            case 2: {\n              // key\n              charCodes.push('='.charCodeAt(0))\n              state = 3\n              break\n            }\n            case 3: {\n              // value\n              charCodes.push('&'.charCodeAt(0))\n              state = 2\n              break\n            }\n          }\n        }\n      }\n      return new TextDecoder().decode(new Uint8Array(charCodes))\n    }\n    return zName ? this._module.UTF8ToString(zName) : null\n  }\n}\n// Emscripten \"legalizes\" 64-bit integer arguments by passing them as\n// two 32-bit signed integers.\nfunction delegalize(lo32, hi32) {\n  return hi32 * 0x1_00_00_00_00 + lo32 + (lo32 < 0 ? 2 ** 32 : 0)\n}\n", "import { Effect } from '@livestore/utils/effect'\nimport type * as WaSqlite from '@livestore/wa-sqlite'\n\nimport { AccessHandlePoolVFS } from './AccessHandlePoolVFS.js'\n\nconst semaphore = Effect.makeSemaphore(1).pipe(Effect.runSync)\nconst opfsVfsMap = new Map<string, AccessHandlePoolVFS>()\n\nexport const makeOpfsDb = ({\n  sqlite3,\n  directory,\n  fileName,\n}: {\n  sqlite3: WaSqlite.SQLiteAPI\n  directory: string\n  fileName: string\n}) =>\n  Effect.gen(function* () {\n    // Replace all special characters with underscores\n    const safePath = directory.replaceAll(/[\"*/:<>?\\\\|]/g, '_')\n    const pathSegment = safePath.length === 0 ? '' : `-${safePath}`\n    const vfsName = `opfs${pathSegment}`\n\n    if (sqlite3.vfs_registered.has(vfsName) === false) {\n      const vfs = yield* Effect.promise(() => AccessHandlePoolVFS.create(vfsName, directory, (sqlite3 as any).module))\n\n      sqlite3.vfs_register(vfs, false)\n      opfsVfsMap.set(vfsName, vfs)\n    }\n\n    const dbPointer = sqlite3.open_v2Sync(fileName, undefined, vfsName)\n    const vfs = opfsVfsMap.get(vfsName)!\n\n    return { dbPointer, vfs }\n  }).pipe(semaphore.withPermits(1))\n", "import * as VFS from '@livestore/wa-sqlite/src/VFS.js'\n\nconst SECTOR_SIZE = 4096\nconst HEADER_MAX_PATH_SIZE = 512\nconst HEADER_FLAGS_SIZE = 4\nconst HEADER_DIGEST_SIZE = 8\nconst HEADER_CORPUS_SIZE = HEADER_MAX_PATH_SIZE + HEADER_FLAGS_SIZE\nconst HEADER_OFFSET_FLAGS = HEADER_MAX_PATH_SIZE\nconst HEADER_OFFSET_DIGEST = HEADER_CORPUS_SIZE\nexport const HEADER_OFFSET_DATA = SECTOR_SIZE\n\nconst PERSISTENT_FILE_TYPES =\n  VFS.SQLITE_OPEN_MAIN_DB | VFS.SQLITE_OPEN_MAIN_JOURNAL | VFS.SQLITE_OPEN_SUPER_JOURNAL | VFS.SQLITE_OPEN_WAL\n\nconst textDecoder = new TextDecoder()\n\nexport const decodeSAHPoolFilename = async (file: File): Promise<string> => {\n  // Read the path and digest of the path from the file.\n  const corpus = new Uint8Array(await file.slice(0, HEADER_CORPUS_SIZE).arrayBuffer())\n\n  // Delete files not expected to be present.\n  const dataView = new DataView(corpus.buffer, corpus.byteOffset)\n  const flags = dataView.getUint32(HEADER_OFFSET_FLAGS)\n  if (corpus[0] && (flags & VFS.SQLITE_OPEN_DELETEONCLOSE || (flags & PERSISTENT_FILE_TYPES) === 0)) {\n    console.warn(`Remove file with unexpected flags ${flags.toString(16)}`)\n    return ''\n  }\n\n  const fileDigest = new Uint32Array(\n    await file.slice(HEADER_OFFSET_DIGEST, HEADER_OFFSET_DIGEST + HEADER_DIGEST_SIZE).arrayBuffer(),\n  )\n\n  // Verify the digest.\n  const computedDigest = computeDigest(corpus)\n  if (fileDigest.every((value, i) => value === computedDigest[i])) {\n    // Good digest. Decode the null-terminated path string.\n    const pathBytes = corpus.indexOf(0)\n    if (pathBytes === 0) {\n      // Note: We can't truncate the file here as File objects are read-only\n      // console.warn('Unassociated file detected')\n    }\n    return textDecoder.decode(corpus.subarray(0, pathBytes))\n  } else {\n    // Bad digest. Repair this header.\n    console.warn('Disassociating file with bad digest.')\n    return ''\n  }\n}\n\nconst computeDigest = (corpus: Uint8Array): Uint32Array => {\n  if (!corpus[0]) {\n    // Optimization for deleted file.\n    return new Uint32Array([0xfe_cc_5f_80, 0xac_ce_c0_37])\n  }\n\n  let h1 = 0xde_ad_be_ef\n  let h2 = 0x41_c6_ce_57\n\n  for (const value of corpus) {\n    h1 = Math.imul(h1 ^ value, 2_654_435_761)\n    h2 = Math.imul(h2 ^ value, 1_597_334_677)\n  }\n\n  h1 = Math.imul(h1 ^ (h1 >>> 16), 2_246_822_507) ^ Math.imul(h2 ^ (h2 >>> 13), 3_266_489_909)\n  h2 = Math.imul(h2 ^ (h2 >>> 16), 2_246_822_507) ^ Math.imul(h1 ^ (h1 >>> 13), 3_266_489_909)\n\n  return new Uint32Array([h1 >>> 0, h2 >>> 0])\n}\n", "import type { MakeSqliteDb, PersistenceInfo, SqliteDb } from '@livestore/common'\nimport { Effect, Hash } from '@livestore/utils/effect'\nimport type { MemoryVFS } from '@livestore/wa-sqlite/src/examples/MemoryVFS.js'\n\nimport { makeInMemoryDb } from '../in-memory-vfs.js'\nimport { makeSqliteDb } from '../make-sqlite-db.js'\nimport type { AccessHandlePoolVFS } from './opfs/AccessHandlePoolVFS.js'\nimport { makeOpfsDb } from './opfs/index.js'\n\nexport * from './opfs/opfs-sah-pool.js'\n\nexport type WebDatabaseMetadataInMemory = {\n  _tag: 'in-memory'\n  vfs: MemoryVFS\n  dbPointer: number\n  persistenceInfo: PersistenceInfo\n  deleteDb: () => void\n  configureDb: (db: SqliteDb) => void\n}\n\nexport type WebDatabaseMetadataOpfs = {\n  _tag: 'opfs'\n  vfs: AccessHandlePoolVFS\n  dbPointer: number\n  persistenceInfo: PersistenceInfo<{\n    opfsDirectory: string\n    /** Actual filename used by OPFS */\n    opfsFileName: string\n  }>\n  deleteDb: () => void\n  configureDb: (db: SqliteDb) => void\n}\n\nexport type WebDatabaseMetadata = WebDatabaseMetadataInMemory | WebDatabaseMetadataOpfs\n\nexport type WebDatabaseInputInMemory = {\n  _tag: 'in-memory'\n  configureDb?: (db: SqliteDb) => void\n}\n\nexport type WebDatabaseInputOpfs = {\n  _tag: 'opfs'\n  /** Filename of the database file (only used when exporting/downloading the database) */\n  fileName: string\n  opfsDirectory: string\n  configureDb?: (db: SqliteDb) => void\n}\n\nexport type WebDatabaseInput = WebDatabaseInputInMemory | WebDatabaseInputOpfs\n\nexport type MakeWebSqliteDb = MakeSqliteDb<\n  { dbPointer: number; persistenceInfo: PersistenceInfo },\n  WebDatabaseInput,\n  WebDatabaseMetadata\n>\n\nexport const sqliteDbFactory =\n  ({ sqlite3 }: { sqlite3: SQLiteAPI }): MakeWebSqliteDb =>\n  (input: WebDatabaseInput) =>\n    Effect.gen(function* () {\n      if (input._tag === 'in-memory') {\n        const { dbPointer, vfs } = makeInMemoryDb(sqlite3)\n        return makeSqliteDb<WebDatabaseMetadataInMemory>({\n          sqlite3,\n          metadata: {\n            _tag: 'in-memory',\n            vfs,\n            dbPointer,\n            deleteDb: () => {},\n            configureDb: input.configureDb ?? (() => {}),\n            persistenceInfo: {\n              fileName: ':memory:',\n            },\n          },\n        }) as any\n      }\n\n      // TODO figure out the actual max length\n      const MAX_DB_FILENAME_LENGTH = 60\n\n      let dbFilename = input.fileName\n\n      if (input.fileName.length > MAX_DB_FILENAME_LENGTH) {\n        yield* Effect.logWarning(\n          `dbFilename too long: '${input.fileName}'. Max ${MAX_DB_FILENAME_LENGTH} chars, got ${input.fileName.length}. Hashing...`,\n        )\n        dbFilename = `hash-${Hash.string(input.fileName)}.db`\n      }\n\n      const { dbPointer, vfs } = yield* makeOpfsDb({\n        sqlite3,\n        directory: input.opfsDirectory,\n        fileName: dbFilename,\n      })\n\n      return makeSqliteDb<WebDatabaseMetadataOpfs>({\n        sqlite3,\n        metadata: {\n          _tag: 'opfs',\n          vfs,\n          dbPointer,\n          deleteDb: () => vfs.resetAccessHandle(input.fileName),\n          configureDb: input.configureDb ?? (() => {}),\n          persistenceInfo: {\n            fileName: dbFilename,\n            opfsDirectory: input.opfsDirectory,\n            opfsFileName: vfs.getOpfsFileName(dbFilename),\n          },\n        },\n      })\n    })\n", "import * as WaSqlite from '@livestore/wa-sqlite'\nimport WaSqliteFactory from '@livestore/wa-sqlite/dist/wa-sqlite.mjs'\n\nexport const loadSqlite3Wasm = async () => {\n  const module = await WaSqliteFactory()\n  // https://github.com/rhashimoto/wa-sqlite/issues/143#issuecomment-1899060056\n  // module._free(module._malloc(10_000 * 4096 + 65_536))\n  const sqlite3 = WaSqlite.Factory(module)\n  // @ts-expect-error TODO fix types\n  sqlite3.module = module\n  return sqlite3\n}\n", "// NOTE we're already firing off this promise call here since we'll need it anyway and need it cached\n\nimport { prettyBytes } from '@livestore/utils'\n\n// To improve LiveStore compatibility with e.g. Node.js we're guarding for `navigator` / `navigator.storage` to be defined.\nexport const rootHandlePromise =\n  typeof navigator === 'undefined' || navigator.storage === undefined\n    ? // We're using a proxy here to make the promise reject lazy\n      (new Proxy(\n        {},\n        {\n          get: () =>\n            Promise.reject(\n              new Error(`Can't get OPFS root handle in this environment as navigator.storage is undefined`),\n            ),\n        },\n      ) as never)\n    : navigator.storage.getDirectory()\n\nexport const getDirHandle = async (absDirPath: string | undefined) => {\n  const rootHandle = await rootHandlePromise\n  if (absDirPath === undefined) return rootHandle\n\n  let dirHandle = rootHandle\n  const directoryStack = absDirPath?.split('/').filter(Boolean)\n  while (directoryStack.length > 0) {\n    dirHandle = await dirHandle.getDirectoryHandle(directoryStack.shift()!)\n  }\n\n  return dirHandle\n}\n\nexport const printTree = async (\n  directoryHandle_: FileSystemDirectoryHandle | Promise<FileSystemDirectoryHandle> = rootHandlePromise,\n  depth: number = Number.POSITIVE_INFINITY,\n  prefix: string = '',\n): Promise<void> => {\n  if (depth < 0) return\n\n  const directoryHandle = await directoryHandle_\n  const entries = directoryHandle.values()\n\n  for await (const entry of entries) {\n    const isDirectory = entry.kind === 'directory'\n    const size = entry.kind === 'file' ? await entry.getFile().then((file) => prettyBytes(file.size)) : undefined\n    console.log(`${prefix}${isDirectory ? '📁' : '📄'} ${entry.name} ${size ? `(${size})` : ''}`)\n\n    if (isDirectory) {\n      const nestedDirectoryHandle = await directoryHandle.getDirectoryHandle(entry.name)\n      await printTree(nestedDirectoryHandle, depth - 1, `${prefix}  `)\n    }\n  }\n}\n\nexport const deleteAll = async (directoryHandle: FileSystemDirectoryHandle) => {\n  if (directoryHandle.kind !== 'directory') return\n\n  for await (const entryName of directoryHandle.keys()) {\n    await directoryHandle.removeEntry(entryName, { recursive: true })\n  }\n}\n", "import { liveStoreStorageFormatVersion, UnexpectedError } from '@livestore/common'\nimport type { LiveStoreSchema } from '@livestore/common/schema'\nimport { decodeSAHPoolFilename, HEADER_OFFSET_DATA } from '@livestore/sqlite-wasm/browser'\nimport { Effect, Schedule, Schema } from '@livestore/utils/effect'\n\nimport * as OpfsUtils from '../../opfs-utils.js'\nimport type * as WorkerSchema from './worker-schema.js'\n\nexport class PersistedSqliteError extends Schema.TaggedError<PersistedSqliteError>()('PersistedSqliteError', {\n  cause: Schema.Defect,\n}) {}\n\nexport const readPersistedAppDbFromClientSession = ({\n  storageOptions,\n  storeId,\n  schema,\n}: {\n  storageOptions: WorkerSchema.StorageType\n  storeId: string\n  schema: LiveStoreSchema\n}) =>\n  Effect.promise(async () => {\n    const directory = sanitizeOpfsDir(storageOptions.directory, storeId)\n    const sahPoolOpaqueDir = await OpfsUtils.getDirHandle(directory).catch(() => undefined)\n\n    if (sahPoolOpaqueDir === undefined) {\n      return undefined\n    }\n\n    const tryGetDbFile = async (fileHandle: FileSystemFileHandle) => {\n      const file = await fileHandle.getFile()\n      const fileName = await decodeSAHPoolFilename(file)\n      return fileName ? { fileName, file } : undefined\n    }\n\n    const getAllFiles = async (asyncIterator: AsyncIterable<FileSystemHandle>): Promise<FileSystemFileHandle[]> => {\n      const results: FileSystemFileHandle[] = []\n      for await (const value of asyncIterator) {\n        if (value.kind === 'file') {\n          results.push(value as FileSystemFileHandle)\n        }\n      }\n      return results\n    }\n\n    const files = await getAllFiles(sahPoolOpaqueDir.values())\n\n    const fileResults = await Promise.all(files.map(tryGetDbFile))\n\n    const appDbFileName = '/' + getStateDbFileName(schema)\n\n    const dbFileRes = fileResults.find((_) => _?.fileName === appDbFileName)\n    // console.debug('fileResults', fileResults, 'dbFileRes', dbFileRes)\n\n    if (dbFileRes !== undefined) {\n      const data = await dbFileRes.file.slice(HEADER_OFFSET_DATA).arrayBuffer()\n      // console.debug('readPersistedAppDbFromClientSession', data.byteLength, data)\n\n      // Given the SAH pool always eagerly creates files with empty non-header data,\n      // we want to return undefined if the file exists but is empty\n      if (data.byteLength === 0) {\n        return undefined\n      }\n\n      return new Uint8Array(data)\n    }\n\n    return undefined\n  }).pipe(\n    Effect.logWarnIfTakesLongerThan({\n      duration: 1000,\n      label: '@livestore/adapter-web:readPersistedAppDbFromClientSession',\n    }),\n    Effect.withPerformanceMeasure('@livestore/adapter-web:readPersistedAppDbFromClientSession'),\n    Effect.withSpan('@livestore/adapter-web:readPersistedAppDbFromClientSession'),\n  )\n\nexport const resetPersistedDataFromClientSession = ({\n  storageOptions,\n  storeId,\n}: {\n  storageOptions: WorkerSchema.StorageType\n  storeId: string\n}) =>\n  Effect.gen(function* () {\n    const directory = sanitizeOpfsDir(storageOptions.directory, storeId)\n    yield* opfsDeleteAbs(directory)\n  }).pipe(\n    Effect.retry({\n      schedule: Schedule.exponentialBackoff10Sec,\n    }),\n    Effect.withSpan('@livestore/adapter-web:resetPersistedDataFromClientSession'),\n  )\n\nconst opfsDeleteAbs = (absPath: string) =>\n  Effect.promise(async () => {\n    // Get the root directory handle\n    const root = await OpfsUtils.rootHandlePromise\n\n    // Split the absolute path to traverse directories\n    const pathParts = absPath.split('/').filter((part) => part.length)\n\n    try {\n      // Traverse to the target file handle\n      let currentDir = root\n      for (let i = 0; i < pathParts.length - 1; i++) {\n        currentDir = await currentDir.getDirectoryHandle(pathParts[i]!)\n      }\n\n      // Delete the file\n      await currentDir.removeEntry(pathParts.at(-1)!, { recursive: true })\n    } catch (error) {\n      if (error instanceof DOMException && error.name === 'NotFoundError') {\n        // Can ignore as it's already been deleted or not there in the first place\n        return\n      } else {\n        throw error\n      }\n    }\n  }).pipe(\n    UnexpectedError.mapToUnexpectedError,\n    Effect.withSpan('@livestore/adapter-web:worker:opfsDeleteFile', { attributes: { absFilePath: absPath } }),\n  )\n\nexport const sanitizeOpfsDir = (directory: string | undefined, storeId: string) => {\n  // Root dir should be `''` not `/`\n  if (directory === undefined || directory === '' || directory === '/')\n    return `livestore-${storeId}@${liveStoreStorageFormatVersion}`\n\n  if (directory.includes('/')) {\n    throw new Error(\n      `@livestore/adapter-web:worker:sanitizeOpfsDir: Nested directories are not yet supported ('${directory}')`,\n    )\n  }\n\n  return `${directory}@${liveStoreStorageFormatVersion}`\n}\n\nexport const getStateDbFileName = (schema: LiveStoreSchema) => {\n  const schemaHashSuffix =\n    schema.state.sqlite.migrations.strategy === 'manual' ? 'fixed' : schema.state.sqlite.hash.toString()\n  return `state${schemaHashSuffix}.db`\n}\n", "import { ShutdownChannel } from '@livestore/common/leader-thread'\nimport { WebChannel } from '@livestore/utils/effect'\n\nexport const makeShutdownChannel = (storeId: string) =>\n  WebChannel.broadcastChannel({\n    channelName: `livestore.shutdown.${storeId}`,\n    schema: ShutdownChannel.All,\n  })\n", "import {\n  BootStatus,\n  Devtools,\n  LeaderAheadError,\n  LeaderPullCursor,\n  liveStoreVersion,\n  MigrationsReport,\n  SyncState,\n  UnexpectedError,\n} from '@livestore/common'\nimport { EventSequenceNumber, LiveStoreEvent } from '@livestore/common/schema'\nimport * as WebmeshWorker from '@livestore/devtools-web-common/worker'\nimport { Schema, Transferable } from '@livestore/utils/effect'\n\nexport const StorageTypeOpfs = Schema.Struct({\n  type: Schema.Literal('opfs'),\n  /**\n   * Default is `livestore-${storeId}`\n   *\n   * When providing this option, make sure to include the `storeId` in the path to avoid\n   * conflicts with other LiveStore apps.\n   */\n  directory: Schema.optional(Schema.String),\n})\n\nexport type StorageTypeOpfs = typeof StorageTypeOpfs.Type\n\n// export const StorageTypeIndexeddb = Schema.Struct({\n//   type: Schema.Literal('indexeddb'),\n//   /** @default \"livestore\" */\n//   databaseName: Schema.optionalWith(Schema.String, { default: () => 'livestore' }),\n//   /** @default \"livestore-\" */\n//   storeNamePrefix: Schema.optionalWith(Schema.String, { default: () => 'livestore-' }),\n// })\n\nexport const StorageType = Schema.Union(\n  StorageTypeOpfs,\n  // StorageTypeIndexeddb\n)\nexport type StorageType = typeof StorageType.Type\nexport type StorageTypeEncoded = typeof StorageType.Encoded\n\n// export const SyncBackendOptions = Schema.Union(SyncBackendOptionsWebsocket)\nexport const SyncBackendOptions = Schema.Record({ key: Schema.String, value: Schema.JsonValue })\nexport type SyncBackendOptions = Record<string, Schema.JsonValue>\n\nexport namespace LeaderWorkerOuter {\n  export class InitialMessage extends Schema.TaggedRequest<InitialMessage>()('InitialMessage', {\n    payload: { port: Transferable.MessagePort, storeId: Schema.String, clientId: Schema.String },\n    success: Schema.Void,\n    failure: UnexpectedError,\n  }) {}\n\n  export class Request extends Schema.Union(InitialMessage) {}\n}\n\n// TODO unify this code with schema from node adapter\nexport namespace LeaderWorkerInner {\n  export class InitialMessage extends Schema.TaggedRequest<InitialMessage>()('InitialMessage', {\n    payload: {\n      storageOptions: StorageType,\n      devtoolsEnabled: Schema.Boolean,\n      storeId: Schema.String,\n      clientId: Schema.String,\n      debugInstanceId: Schema.String,\n      syncPayload: Schema.UndefinedOr(Schema.JsonValue),\n    },\n    success: Schema.Void,\n    failure: UnexpectedError,\n  }) {}\n\n  export class BootStatusStream extends Schema.TaggedRequest<BootStatusStream>()('BootStatusStream', {\n    payload: {},\n    success: BootStatus,\n    failure: UnexpectedError,\n  }) {}\n\n  export class PushToLeader extends Schema.TaggedRequest<PushToLeader>()('PushToLeader', {\n    payload: {\n      batch: Schema.Array(LiveStoreEvent.AnyEncoded),\n    },\n    success: Schema.Void,\n    failure: Schema.Union(UnexpectedError, LeaderAheadError),\n  }) {}\n\n  export class PullStream extends Schema.TaggedRequest<PullStream>()('PullStream', {\n    payload: {\n      cursor: LeaderPullCursor,\n    },\n    success: Schema.Struct({\n      payload: SyncState.PayloadUpstream,\n      mergeCounter: Schema.Number,\n    }),\n    failure: UnexpectedError,\n  }) {}\n\n  export class Export extends Schema.TaggedRequest<Export>()('Export', {\n    payload: {},\n    success: Transferable.Uint8Array,\n    failure: UnexpectedError,\n  }) {}\n\n  export class ExportEventlog extends Schema.TaggedRequest<ExportEventlog>()('ExportEventlog', {\n    payload: {},\n    success: Transferable.Uint8Array,\n    failure: UnexpectedError,\n  }) {}\n\n  export class GetRecreateSnapshot extends Schema.TaggedRequest<GetRecreateSnapshot>()('GetRecreateSnapshot', {\n    payload: {},\n    success: Schema.Struct({\n      snapshot: Transferable.Uint8Array,\n      migrationsReport: MigrationsReport,\n    }),\n    failure: UnexpectedError,\n  }) {}\n\n  export class GetLeaderHead extends Schema.TaggedRequest<GetLeaderHead>()('GetLeaderHead', {\n    payload: {},\n    success: EventSequenceNumber.EventSequenceNumber,\n    failure: UnexpectedError,\n  }) {}\n\n  export class GetLeaderSyncState extends Schema.TaggedRequest<GetLeaderSyncState>()('GetLeaderSyncState', {\n    payload: {},\n    success: SyncState.SyncState,\n    failure: UnexpectedError,\n  }) {}\n\n  export class Shutdown extends Schema.TaggedRequest<Shutdown>()('Shutdown', {\n    payload: {},\n    success: Schema.Void,\n    failure: UnexpectedError,\n  }) {}\n\n  export class ExtraDevtoolsMessage extends Schema.TaggedRequest<ExtraDevtoolsMessage>()('ExtraDevtoolsMessage', {\n    payload: {\n      message: Devtools.Leader.MessageToApp,\n    },\n    success: Schema.Void,\n    failure: UnexpectedError,\n  }) {}\n\n  export const Request = Schema.Union(\n    InitialMessage,\n    BootStatusStream,\n    PushToLeader,\n    PullStream,\n    Export,\n    ExportEventlog,\n    GetRecreateSnapshot,\n    GetLeaderHead,\n    GetLeaderSyncState,\n    Shutdown,\n    ExtraDevtoolsMessage,\n    WebmeshWorker.Schema.CreateConnection,\n  )\n  export type Request = typeof Request.Type\n}\n\nexport namespace SharedWorker {\n  export class InitialMessagePayloadFromClientSession extends Schema.TaggedStruct('FromClientSession', {\n    initialMessage: LeaderWorkerInner.InitialMessage,\n  }) {}\n\n  export class InitialMessage extends Schema.TaggedRequest<InitialMessage>()('InitialMessage', {\n    payload: {\n      payload: Schema.Union(InitialMessagePayloadFromClientSession, Schema.TaggedStruct('FromWebBridge', {})),\n      // To guard against scenarios where a client session is already running a newer version of LiveStore\n      // We should probably find a better way to handle those cases once they become more common.\n      liveStoreVersion: Schema.Literal(liveStoreVersion),\n    },\n    success: Schema.Void,\n    failure: UnexpectedError,\n  }) {}\n\n  export class UpdateMessagePort extends Schema.TaggedRequest<UpdateMessagePort>()('UpdateMessagePort', {\n    payload: {\n      port: Transferable.MessagePort,\n    },\n    success: Schema.Void,\n    failure: UnexpectedError,\n  }) {}\n\n  export class Request extends Schema.Union(\n    InitialMessage,\n    UpdateMessagePort,\n\n    // Proxied requests\n    LeaderWorkerInner.BootStatusStream,\n    LeaderWorkerInner.PushToLeader,\n    LeaderWorkerInner.PullStream,\n    LeaderWorkerInner.Export,\n    LeaderWorkerInner.GetRecreateSnapshot,\n    LeaderWorkerInner.ExportEventlog,\n    LeaderWorkerInner.GetLeaderHead,\n    LeaderWorkerInner.GetLeaderSyncState,\n    LeaderWorkerInner.Shutdown,\n    LeaderWorkerInner.ExtraDevtoolsMessage,\n\n    WebmeshWorker.Schema.CreateConnection,\n  ) {}\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6CO,IAAM,sBAAsB,CAAC,UAAoB,EAAE,aAAa,YAAW,MAChF;EACE;;;;;;;;;;;;;EAaA;;;;0BAIsB,cAAc,OAAO,KAAK;MAC9C,gBAAgB,SAAY,KAAK,0BAA0B,WAAW,GAAG;;EAE3E,CAAA;AAAE;AAGC,IAAM,UAAU,CAAC,UAAoBA,MAAa,SAAoB;AAC3E,QAAM,aAAa,kBAAkB,MAAMA,IAAG;AAC9C,SAAO,eAAO,IAAI;IAChB,KAAK,MAAM,SAAS,QAAQA,MAAK,UAAU;IAC3C,OAAO,CAAC,UACN,IAAI,YAAY,EAAE,OAAO,OAAO,EAAE,YAAY,KAAAA,KAAG,GAAI,MAAO,MAA+B,KAAI,CAAE;GACpG,EAAE;IACD,eAAO;;IAEP,eAAO,SAAS,6BAA6B;MAC3C,YAAY,EAAE,cAAcA,MAAK,KAAAA,MAAK,eAAe,OAAO,KAAK,UAAU,EAAC;KAC7E;EAAC;AAEN;AAYO,IAAM,kBAAkB,CAAC,UAAoBA,MAAa,eAAkC;AACjG,SAAO,eAAO,IAAI;IAChB,KAAK,MAAM,SAAS,QAAQA,MAAK,UAAU;IAC3C,OAAO,CAAC,UACN,IAAI,YAAY,EAAE,OAAO,OAAO,EAAE,YAAY,KAAAA,KAAG,GAAI,MAAO,MAA+B,KAAI,CAAE;GACpG,EAAE;IACD,eAAO;;IAEP,eAAO,SAAS,qCAAqC;MACnD,YAAY;QACV,cAAcA;QACd,KAAAA;QACA,eAAe,OAAO,KAAK,UAAU;;KAExC;EAAC;AAEN;;;AC/EO,IAAM,yBAAyB,eAAO,aAAa,QAAQ,CAAA,CAAE;AAG7D,IAAM,6BAA6B,eAAO,aAAa,YAAY;EACxE,SAAS,eAAO,MAAM,eAAO,oBAAoB,eAAO,MAAM;CAC/D;AAIM,IAAM,qBAAqB,eAAO,MAAM,wBAAwB,0BAA0B;AA4C3F,IAAO,kBAAP,cAA+B,gBAAQ,IAAI,iBAAiB,EAAC,EA6BhE;;;;AClHH;;;;;;;;;;;;;ACAO,IAAM,gBAAgB,CAAgC,QAC3D,OAAO,QAAQ,GAAG;;;ACmCb,IAAM,iBAAiB,CAAC,OAA6B;AAC1D,QAAM,gBAAgB,CAAC,KAAK,KAAK,GAAG;AACpC,SAAO,cAAc,SAAS,EAAE;AAClC;;;ACUO,IAAM,YAAY,CAAqC,EAC5D,WACA,SACA,QACA,UAAU,EAAE,WAAW,MAAK,EAAE,MAML;AACzB,QAAM,OAAO,kBAAkB;IAC7B;IACA;IACA,SAAS,EAAE,WAAW,mCAAS,WAAW,MAAM,OAAO,KAAK,MAAM,EAAC;GACpE;AAED,SAAO,CAAC,MAAM,eAAe,EAAE,SAAS,OAAM,CAAE,CAAC;AACnD;AAEO,IAAM,oBAAoB,CAAqC,EACpE,WACA,SACA,UAAU,EAAE,WAAW,MAAK,EAAE,MAKnB;AACX,QAAM,QAAO,mCAAS,SAAQ,OAAO,KAAK,OAAO;AACjD,QAAM,UAAU,KAAK,KAAK,IAAI;AAC9B,QAAM,YAAY,KAAK,IAAI,CAAC,QAAQ,IAAI,GAAG,EAAE,EAAE,KAAK,IAAI;AAExD,SAAO,aAAa,QAAQ,YAAY,gBAAgB,EAAE,QAAQ,SAAS,KAAK,OAAO,aAAa,SAAS;AAC/G;AAyDO,IAAM,aAAa,CAAqC,EAC7D,SACA,WACA,cAAc,eACd,MAAK,MAMoB;AACzB,QAAM,eAAe,sBAAsB,aAAa;AAGxD,MAAI,OAAO,KAAK,YAAY,EAAE,WAAW,GAAG;AAC1C,WAAO,CAAC,eAAe,CAAA,CAAE;EAC3B;AAEA,QAAM,iBAAiB,OAAO,KAAK,YAAY,EAC5C,IAAI,CAAC,eAAe,GAAG,UAAU,cAAc,UAAU,EAAE,EAC3D,KAAK,IAAI;AAEZ,QAAM,aAAa;IACjB,GAAG,eAAe,EAAE,SAAS,QAAQ,cAAc,gBAAgB,UAAS,CAAE;IAC9E,GAAG,eAAe,EAAE,SAAS,QAAQ,OAAO,gBAAgB,UAAU,SAAS,KAAI,CAAE;;AAGvF,QAAM,WAAW,cAAc,EAAE,MAAK,CAAE;AACxC,QAAM,gBAAgB,aAAa,KAAK,KAAK,SAAS,QAAQ;AAE9D,SAAO,CAAC,aAAa,SAAS,QAAQ,cAAc,IAAI,aAAa,IAAI,UAAU;AACrF;AAwFO,IAAM,iBAAiB,CAAmE,EAC/F,SACA,QACA,iBAAiB,IACjB,QAAO,MAOiB;AACxB,QAAM,WAAW,KACf,SACA,eACA,cAAc,IAAI,CAAC,CAAC,YAAY,SAAS,MAAM;IAC7C;IACA,CAAC,UAAc;AACb,UAAI,UAAU,aAAa,SAAS,UAAU,QAAQ,UAAU;AAAY,eAAO;AACnF,YAAM,MAAM,eAAO,aAAa,UAAU,MAAM,EAAE,KAAK;AACvD,UAAI,IAAI,SAAS,QAAQ;AACvB,cAAM,gBAAgB,cAAc,gBAAgB,IAAI,IAAI;AAC5D,cAAM,oBAAoB,OAAO,UAAU,OAAO,GAAG;AAErD,gBAAQ,MACN,sDACyC,UAAU;;mBAE5C,iBAAiB;;SAE3B,aAAa;;SAGV,KAAK;AAEP;AACA,cAAM,IAAI;MACZ,OAAO;AACL,eAAO,IAAI;MACb;IACF;GACD,GACD,OAAO,WAAW;AAGpB,SAAO,KACL,OAAO,QAAQ,MAAM,EAElB,OAAO,CAAC,CAAC,EAAE,KAAK,MAAM,YAAY,QAAS,UAAU,QAAQ,UAAU,MAAU,EACjF,QAAQ,CAAC,CAAC,YAAY,KAAK,MAAoB;AAC9C,UAAM,QAAQ,SAAS,UAAU,KAAK,kBAAkB,8BAA8B,UAAU,GAAG;AAEnG,QAAI,OAAO,UAAU,YAAY,UAAU,QAAQ,QAAQ,OAAO;AAChE,cAAQ,MAAM,IAAI;QAChB,KAAK,MAAM;AACT,iBAAO,MAAM,IAAI,IAAI,CAACC,QAAY,MAAc,CAAC,GAAG,cAAc,GAAG,UAAU,IAAI,CAAC,IAAI,MAAMA,MAAK,CAAC,CAAC;QACvG;QACA,KAAK;QACL,KAAK;QACL,KAAK,KAAK;AACR,iBAAO,CAAC,CAAC,GAAG,cAAc,GAAG,UAAU,IAAI,MAAM,MAAM,GAAG,CAAC,CAAC;QAC9D;QACA,SAAS;AACP,gBAAM,IAAI,MAAM,eAAe,MAAM,EAAE,EAAE;QAC3C;MACF;IACF,OAAO;AACL,aAAO,CAAC,CAAC,GAAG,cAAc,GAAG,UAAU,IAAI,MAAM,KAAK,CAAC,CAAC;IAC1D;EACF,CAAC,GACH,OAAO,WAAW;AAEtB;AAEA,IAAM,gBAAgB,CAAqC,EACzD,MAAK,MAGF;AACH,QAAM,aAAa,CAAC,YAAoB,UAAgD;AACtF,QAAI,UAAU,MAAM;AAClB,aAAO;IACT,WAAW,OAAO,UAAU,YAAY,OAAO,MAAM,OAAO,YAAwB,eAAe,MAAM,EAAE,GAAG;AAC5G,aAAO,GAAG,MAAM,EAAE,WAAW,UAAU;IACzC,WAAW,OAAO,UAAU,YAAY,OAAO,MAAM,OAAO,YAAY,MAAM,OAAO,MAAM;AACzF,aAAO,OAAO,MAAM,IAAI,IAAI,CAAC,GAAQ,MAAc,UAAU,UAAU,IAAI,CAAC,EAAE,EAAE,KAAK,IAAI,CAAC;IAC5F,OAAO;AACL,aAAO,YAAY,UAAU;IAC/B;EACF;AAEA,SAAO,KACL,OACA,eACA,cAAc,IAAI,CAAC,CAAC,YAAY,KAAK,MAAM,GAAG,UAAU,IAAI,WAAW,YAAY,KAAK,CAAC,EAAE,GAC3F,cAAc,KAAK,OAAO,CAAC;AAE/B;AAGA,IAAM,wBAAwB,CAAgC,QAAa;AACzE,SAAO,OAAO,YAAY,OAAO,QAAQ,GAAG,EAAE,OAAO,CAAC,CAAC,EAAE,KAAK,MAAM,UAAU,MAAS,CAAC;AAC1F;;;AHpVO,IAAM,iBAAiB,CAAC,eAC7B,eAAO,IAAI,aAAS;AAClB,aAAW,YAAY,sBAAsB;AAC3C,WAAO,aAAa;MAClB,IAAI;MACJ,WAAW;MACX,UAAU,SAAS,UAAU;MAC7B,eAAe;KAChB;EACH;AAGA,SAAO,QACL,YACA,kBAAkB,iBAAiB;mBACF,KAAK,MAAM;4CACN,iBAAiB,KACvD,CAAA,CAAE;AAEN,CAAC;AAGI,IAAM,iBAAiB,CAC5B,UAEA,eAAO,IAAI,aAAS;AAClB,QAAM,EAAE,YAAY,QAAO,IAAK,OAAO;AAEvC,QAAM,QAAQ,kBAAkB,MAAM,gBAAgB,MAAM,MAAM,MAAM,EAAE,MAAK;AAC/E,QAAM,mBAAmB,WAAW,OAAO,MAAM,OAAO,kBAAkB,MAAM,YAAY,MAAM,KAAK,CAAC;AACxG,QAAM,gBAAgB,eAAO,kBAAkB,kBAAkB,UAAU,KAAK,eAAO,KAAK,CAAC,EAAE,gBAAgB;AAE/G,QAAM,uBAAuB,0BAA0B,MAAM,gBAAgB,MAAM,MAAM,MAAM,EAAE,MAAK;AACtG,QAAM,0BAA0B,QAAQ,OACtC,qBAAqB,OACrB,kBAAkB,qBAAqB,YAAY,qBAAqB,KAAK,CAAC;AAEhF,QAAM,8BAA8B,eAAO,kBACzC,0BAA0B,UAAU,KAAK,eAAO,KAAK,CAAC,EACtD,uBAAuB;AAEzB,SAAO,cACJ,IAAI,CAAC,kBAAiB;AACrB,UAAM,mBAAmB,4BAA4B,KACnD,CAAC,mBACC,eAAe,iBAAiB,cAAc,gBAC9C,eAAe,iBAAiB,cAAc,YAAY;AAE9D,WAAsB,gBAAgB,KAAK;MACzC,MAAM,cAAc;MACpB,MAAM,cAAc;MACpB,QAAQ,EAAE,QAAQ,cAAc,cAAc,QAAQ,cAAc,aAAY;MAChF,cAAc,EAAE,QAAQ,cAAc,oBAAoB,QAAQ,cAAc,mBAAkB;MAClG,UAAU,cAAc;MACxB,WAAW,cAAc;MACzB,MAAM;QACJ,kBACE,oBAAoB,iBAAiB,cAAc,OAC/C;UACE,MAAM;UACN,MAAM,iBAAiB;UACvB,OAAO,iBAAiB;YAE1B,EAAE,MAAM,QAAgB;QAC9B,cAAc,cAAc;QAC5B,wBAAwB,eAAO,KAAI;QACnC,yBAAyB,eAAO,KAAI;;KAEvC;EACH,CAAC,EACA,OAAO,CAAC,MAA0B,QAAQ,EAAE,QAAQ,KAAK,IAAI,CAAC,EAC9D,KAAK,CAAC,GAAG,MAA0B,QAAQ,EAAE,QAAQ,EAAE,MAAM,CAAC;AACnE,CAAC;AAEI,IAAM,sBAAsB,CAAC,eAAiE;AACnG,QAAM,MAAM,WAAW,OAIrB,6CAA6C,mBAAmB,wDAAwD,EACxH,CAAC;AAEH,SAAO,MAAM,EAAE,QAAQ,IAAI,cAAc,QAAQ,IAAI,aAAY,IAAyB;AAC5F;AAEO,IAAM,uBAAuB,CAAC,eAAqE;AA1G1G;AA2GE,2BAAW,OACT,uBAAuB,iBAAiB,EAAE,EAC1C,CAAC,MAFH,mBAEM,SAA4B,KAAK;;AAGlC,IAAM,oBAAoB,CAAC,YAAsB,SACtD,WAAW,QAAQ,aAAa,iBAAiB,eAAe,KAAK,MAAM,EAAE;AAExE,IAAM,qBAAqB,CAChC,cACA,YACA,oBACA,UACA,cAEA,eAAO,IAAI,aAAS;AAElB,MAAI,UAAU,aAAa,aAAa,WAA+B,KAAK,QAAQ;AAClF,UAAM,oBACJ,WAAW,OACT,iCAAiC,mBAAmB,gDACpD,CAAC,aAAa,aAAa,QAAQ,aAAa,aAAa,MAAM,CAA8B,EACjG,CAAC,EAAG,UAAU;AAElB,QAAI,sBAAsB,OAAO;AAC/B,wBACE,mBAAmB,aAAa,aAAa,MAAM,IAAI,aAAa,aAAa,MAAM,iBAAiB;IAE5G;EACF;AAGA,SAAO,QACL,YACA,GAAG,UAAU;IACX,WAAW;IACX,SAAS,kBAAkB,UAAU;IACrC,QAAQ;MACN,cAAc,aAAa,OAAO;MAClC,cAAc,aAAa,OAAO;MAClC,oBAAoB,aAAa,aAAa;MAC9C,oBAAoB,aAAa,aAAa;MAC9C,MAAM,aAAa;MACnB,UAAU,aAAa,QAAQ,CAAA;MAC/B;MACA;MACA,YAAY;MACZ,kBAAkB,aAAa,KAAK;;GAEvC,CAAC;AAEN,CAAC;AAEI,IAAM,qBAAqB,CAAC,UACjC,eAAO,IAAI,aAAS;AAClB,QAAM,EAAE,WAAU,IAAK,OAAO;AAG9B,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,UAAM,QAAQ,MAAM,CAAC;AAErB,WAAO,QACL,YACA,GAAG,WAAW;MACZ,WAAW;MACX,SAAS,kBAAkB,UAAU;MACrC,OAAO,EAAE,cAAc,MAAM,OAAO,QAAQ,cAAc,MAAM,OAAO,OAAM;MAC7E,cAAc,EAAE,kBAAkB,MAAM,KAAK,aAAY;KAC1D,CAAC;EAEN;AACF,CAAC;AAEI,IAAM,2BAA2B,CAAC,eACvC,eAAO,IAAI,aAAS;AAClB,QAAM,EAAE,WAAU,IAAK,OAAO;AAE9B,MAAI,eAAmC,KAAK;AAAQ,WAAO,eAAO,KAAI;AAEtE,QAAM,sBAAsB,eAAO,OAAO;IACxC,kBAAkB,eAAO,UAAU,eAAO,OAAO,eAAO,SAAS,CAAC;GACnE,EAAE,KAAK,eAAO,MAAM,kBAAkB,GAAG,eAAO,OAAO,eAAO,IAAI;AAEnE,QAAM,qBAAqB,OAAO,eAAO,KAAK,MAC5C,WAAW,OACT,mCAAmC,mBAAmB,yBAAyB,UAAU,oCAAoC,CAC9H,EACD,KAAK,eAAO,QAAQ,eAAO,OAAO,mBAAmB,CAAC,GAAG,eAAO,IAAI,eAAO,OAAO,GAAG,eAAO,KAAK;AAEnG,SAAO,eAAO,KAAK;IACjB,QAAQ,EAAE,QAAQ,YAAY,QAA4B,cAAa;IACvE,UAAU;GACX;AACH,CAAC,EAAE,KAAK,eAAO,SAAS,uDAAuD,EAAE,YAAY,EAAE,WAAU,EAAE,CAAE,CAAC;;;AI7LzG,IAAM,eAAe,CAAC,YAC3B,eAAO,IAAI,aAAS;AAClB,MAAI,QAAQ,YAAY,OAAO;AAC7B;EACF;AAEA,QAAM,EAAE,eAAe,4BAA4B,UAAU,QAAO,IAAK,OAAO;AAEhF,SAAO,iBAAiB;IACtB,kBAAkB,eAAO,UAAU,0BAA0B;IAC7D,aAAa,MAAM,eAAO;GAC3B,EAAE,KAAK,eAAO,mBAAmB,eAAO,UAAU;AAEnD,QAAM,EAAE,MAAM,iBAAiB,KAAI,IAAK,OAAO,QAAQ;AAEvD,SAAO,KAAK,iBAAiB,KAC3B,eAAO,OACL,CAAC,QACCC,aAAS,cAAc,qBAAqB,IAAI,aAAa,EAAE,SAAS,SAAQ,CAAE,KAAK,IAAI,SAAS,IAAI,GAE5G,eAAO,IAAI,CAAC,EAAE,aAAa,OAAM,MAC/B,eAAO,IAAI,aAAS;AAClB,UAAM,UAAU,OAAO,KAAK,YAAY;MACtC,QAAQ;MACR;MACA,QAAQ,EAAE,QAAQA,aAAS,OAAO,cAAc,MAAMA,aAAS,OAAO,eAAc;MACpF;KACD;AAED,UAAM,cAAqC,CAAC,YAC1C,QACG,KAAK,OAAO,EACZ,KACC,eAAO,SAAS,yDAAyD,GACzE,eAAO,eACP,eAAO,YAAY;AAGzB,UAAM,YAAY,OAAO,cAAc;AACvC,UAAM,eAAe,cAAc,gBAAe;AAElD,WAAO,cAAc,KAAK,EAAE,QAAQ,EAAE,cAAc,UAAU,UAAU,UAAS,EAAE,CAAE,EAAE,KACrF,eAAO,IAAI,CAAC,EAAE,QAAO,MAAO,YAAYA,aAAS,OAAO,SAAS,KAAK,EAAE,SAAS,iBAAgB,CAAE,CAAC,CAAC,GACrG,eAAO,UACP,eAAO,UAAU;AAGnB,WAAO,iBAAiB;MACtB,kBAAkB,QAAQ,OAAO,KAAK,eAAO,QAAO,GAAI,eAAO,KAAK;MACpE;MACA;KACD;EACH,CAAC,EAAE,KAAK,eAAO,mBAAmB,eAAO,UAAU,CAAC,GAEtD,eAAO,QAAQ;AAEnB,CAAC,EAAE,KAAK,eAAO,SAAS,+CAA+C,CAAC;AAE1E,IAAM,mBAAmB,CAAC,EACxB,kBACA,aACA,gBAAe,MAMf,eAAO,IAAI,aAAS;AAClB,QAAM,EACJ,aACA,cAAAC,eACA,SACA,YACA,qBACA,iBACA,eACA,UACA,SAAQ,IACN,OAAO;AAGX,QAAM,uBAAuB,OAAO,iBAAS,KAAI;AAGjD,QAAM,oBAAoB,oBAAI,IAAG;AAEjC,SAAO,iBAAiB,KACtB,eAAO,IAAI,CAAC,iBACV,eAAO,IAAI,aAAS;AAClB,UAAM,EAAE,UAAS,IAAK;AACtB,UAAM,aAAa,EAAE,WAAW,kBAAkB,SAAQ;AAO1D,QAAI,aAAa,SAAS,yBAAyB;AACjD;IACF;AAMA,QAAI,kBAAkB,IAAI,SAAS,GAAG;AAEpC;IACF;AAEA,sBAAkB,IAAI,SAAS;AAE/B,YAAQ,aAAa,MAAM;MACzB,KAAK,mBAAmB;AACtB,eAAO,YAAYD,aAAS,OAAO,KAAK,KAAK,EAAE,GAAG,WAAU,CAAE,CAAC;AAC/D;MACF;MACA,KAAK,0BAA0B;AAC7B,cAAM,WAAW,QAAQ,OAAM;AAE/B,eAAO,YAAYA,aAAS,OAAO,YAAY,KAAK,EAAE,UAAU,GAAG,WAAU,CAAE,CAAC;AAEhF;MACF;MACA,KAAK,uCAAuC;AAC1C,cAAM,EAAE,KAAI,IAAK;AAEjB,YAAI;AAEJ,YAAI;AACF,gBAAM,QAAQ,OAAOC,cAAa,EAAE,MAAM,YAAW,CAAE;AACvD,gBAAM,OAAO,IAAI;AACjB,gBAAM,mBAAmB,MAAM,OAC7B,qDAAqD;AAGvD,uBAAa,IAAI,IAAI,iBAAiB,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC;AAExD,gBAAM,MAAK;QACb,SAAS,OAAO;AACd,iBAAO,eAAO,SAAS,iCAAiC,KAAK;AAC7D,iBAAO,YACLD,aAAS,OAAO,iBAAiB,MAAM,KAAK;YAC1C,GAAG;YACH,OAAO,EAAE,MAAM,oBAAoB,MAAK;WACzC,CAAC;AAGJ;QACF;AAEA,YAAI;AACF,cAAI,WAAW,IAAI,sBAAa,mBAAmB,GAAG;AAEpD,mBAAO,wBAAgB,IAAI,qBAAqB,eAAe;AAE/D,uBAAW,OAAO,IAAI;AAEtB,oBAAQ,QAAO;UACjB,WACE,WAAW,IAAI,sBAAa,iBAAiB,KAC7C,WAAW,IAAI,sBAAa,4BAA4B,GACxD;AAEA,mBAAO,wBAAgB,IAAI,qBAAqB,eAAe;AAE/D,oBAAQ,OAAO,IAAI;AAEnB,uBAAW,QAAO;UACpB,OAAO;AACL,mBAAO,YACLA,aAAS,OAAO,iBAAiB,MAAM,KAAK;cAC1C,GAAG;cACH,OAAO,EAAE,MAAM,uBAAsB;aACtC,CAAC;AAEJ;UACF;AAEA,iBAAO,YAAYA,aAAS,OAAO,iBAAiB,QAAQ,KAAK,EAAE,GAAG,WAAU,CAAE,CAAC;AACnF,iBAAO,gBAAgB,KAAK,yBAAyB,KAAK,EAAE,QAAQ,kBAAiB,CAAE,CAAC,KAAK,eAAO;AAEpG;QACF,SAAS,OAAO;AACd,iBAAO,eAAO,SAAS,iCAAiC,KAAK;AAC7D,iBAAO,YACLA,aAAS,OAAO,iBAAiB,MAAM,KAAK;YAC1C,GAAG;YACH,OAAO,EAAE,MAAM,oBAAoB,MAAK;WACzC,CAAC;AAEJ;QACF;MACF;MACA,KAAK,mCAAmC;AACtC,cAAM,EAAE,KAAI,IAAK;AAEjB,eAAO,wBAAgB,IAAI,qBAAqB,eAAe;AAE/D,gBAAQ,QAAO;AAEf,YAAI,SAAS,YAAY;AACvB,qBAAW,QAAO;QACpB;AAEA,eAAO,YAAYA,aAAS,OAAO,aAAa,QAAQ,KAAK,EAAE,GAAG,WAAU,CAAE,CAAC;AAE/E,eAAO,gBAAgB,KAAK,yBAAyB,KAAK,EAAE,QAAQ,iBAAgB,CAAE,CAAC,KAAK,eAAO;AAEnG;MACF;MACA,KAAK,kCAAkC;AACrC,YAAI,oBAAoB,QAAW;AACjC,kBAAQ,IAAI,yFAAyF;AACrG;QACF;AAEA,cAAM,cAAc;AACpB,cAAM,aAAa,QAAQ,OAAyB,aAAa,MAAS,EAAE,CAAC,EAAG;AAChF,cAAM,mBAAmB,WAAW,OAAyB,aAAa,MAAS,EAAE,CAAC,EAAG;AAEzF,eAAO,YACLA,aAAS,OAAO,oBAAoB,KAAK;UACvC,OAAO,EAAE,UAAU,YAAY,iBAAiB,gBAAgB,MAAK;UACrE,UAAU,EAAE,UAAU,kBAAkB,iBAAiB,gBAAgB,SAAQ;UACjF,GAAG;SACJ,CAAC;AAGJ;MACF;MACA,KAAK,0BAA0B;AAC7B,cAAM,WAAW,WAAW,OAAM;AAElC,eAAO,YAAYA,aAAS,OAAO,YAAY,KAAK,EAAE,UAAU,GAAG,WAAU,CAAE,CAAC;AAEhF;MACF;MACA,KAAK,6BAA6B;AAChC,eAAO,cAAc,YAAY;UAC/B,OAAO,aAAa;UACpB,UAAU,YAAY,QAAQ;UAC9B,WAAW,YAAY,QAAQ;SAChC;AAED,eAAO,YAAYA,aAAS,OAAO,eAAe,KAAK,EAAE,GAAG,WAAU,CAAE,CAAC;AAEzE;MACF;MACA,KAAK,mCAAmC;AACtC,cAAM,EAAE,eAAc,IAAK;AAE3B,YAAI,gBAAgB,QAAW;AAE7B,iBAAO,YAAY,KAAK,eAAO,KAAI,CAAE,EAAE,KACrC,eAAO,IAAI,CAAC,MAAM,EAAE,KAAK,GACzB,eAAO,kBACP,eAAO,IAAI,CAAC,EAAE,cAAc,SAAQ,MAClC,YACEA,aAAS,OAAO,eAAe,KAAK;YAClC;YACA;YACA;YACA,GAAG;YACH,WAAW,OAAO,EAAE;WACrB,CAAC,CACH,GAEH,eAAO,UACP,eAAO,eACP,eAAO,mBACP,iBAAS,IAAI,sBAAsB,cAAc,CAAC;QAEtD;AAEA;MACF;MACA,KAAK,qCAAqC;AACxC,cAAM,EAAE,WAAAE,WAAS,IAAK;AACtB,gBAAQ,IAAI,8BAA8BA,UAAS;AAEnD,eAAO,iBAAS,OAAO,sBAAsBA,UAAS;AAEtD;MACF;MACA,KAAK,6BAA6B;AAChC,cAAM,cAAcF,aAAS,OAAO,YAAY,KAAK;UACnD,SAAS,gBAAgB;UACzB,WAAU,2CAAa,aAAY,CAAA;SACpC;AAED,eAAO,YAAYA,aAAS,OAAO,eAAe,KAAK,EAAE,aAAa,GAAG,WAAU,CAAE,CAAC;AAEtF;MACF;MACA,KAAK,qCAAqC;AACxC,YAAI,gBAAgB,QAAW;AAC7B,gBAAM,EAAE,eAAc,IAAK;AAK3B,iBAAO,eAAO,MAAM,GAAI;AAExB,iBAAO,eAAO,UACZ,YAAY,YAAY,SACxB,SAAS,UAAU,SAAS,sBAAsB,UAAU,eAAO,KAAK,EAAE,aAAa,MAAK,CAAE,CAAC,EAC/F,KACA,eAAO,IAAI,CAAC,CAAC,aAAa,EAAE,YAAW,CAAE,MACvC,YACEA,aAAS,OAAO,iBAAiB,KAAK;YACpC,eAAe,EAAE,aAAa,aAAa,KAAK,IAAG,GAAI,YAAW;YAClE;YACA,GAAG;YACH,WAAW,OAAO,EAAE;WACrB,CAAC,CACH,GAEH,eAAO,UACP,eAAO,eACP,eAAO,mBACP,iBAAS,IAAI,sBAAsB,cAAc,CAAC;QAEtD;AAEA;MACF;MACA,KAAK,uCAAuC;AAC1C,cAAM,EAAE,WAAAE,WAAS,IAAK;AAEtB,eAAO,iBAAS,OAAO,sBAAsBA,UAAS;AAEtD;MACF;MACA,KAAK,gCAAgC;AACnC,cAAM,EAAE,eAAc,IAAK;AAE3B,eAAO,cAAc,UAAU,QAAQ,KACrC,eAAO,IAAI,CAAC,cACV,YACEF,aAAS,OAAO,YAAY,KAAK;UAC/B,OAAO,UAAU;UACjB,UAAU,UAAU;UACpB;UACA,GAAG;UACH,WAAW,OAAO,EAAE;SACrB,CAAC,CACH,GAEH,eAAO,UACP,eAAO,eACP,eAAO,mBACP,iBAAS,IAAI,sBAAsB,cAAc,CAAC;AAGpD;MACF;MACA,KAAK,kCAAkC;AACrC,cAAM,EAAE,eAAc,IAAK;AAE3B,eAAO,iBAAS,OAAO,sBAAsB,cAAc;AAE3D;MACF;MACA,KAAK,mCAAmC;AACtC,cAAM,EAAE,WAAU,IAAK;AAEvB,YAAI,SAAS,YAAY;AAAO;AAEhC,YAAI,eAAe,MAAM;AACvB,iBAAO,SAAS,iBAAiB;QACnC,OAAO;AACL,iBAAO,SAAS,iBAAiB;QACnC;AAEA,eAAO,wBAAgB,IAAI,SAAS,uBAAuB,EAAE,aAAa,WAAU,CAAE;AAEtF,eAAO,YAAYA,aAAS,OAAO,aAAa,QAAQ,KAAK,EAAE,GAAG,WAAU,CAAE,CAAC;AAE/E;MACF;MACA,SAAS;AACP,eAAO,eAAO,WAAW,mCAAmC,YAAY;MAC1E;IACF;EACF,CAAC,EAAE,KAAK,eAAO,SAAS,qDAAqD,aAAa,IAAI,EAAE,CAAC,CAAC,GAEpG,gBAAgB,4BAChB,eAAO,QAAQ;AAEnB,CAAC;;;ACpYI,IAAM,uBAAuB,CAAC,EACnC,QACA,SACA,WAAU,MAMV,eAAO,IAAI,aAAS;AAClB,QAAM,wBAAwB,IAAI;;;;IAIhC,CAAC,GAAG,OAAO,cAAc,QAAO,CAAE,EAAE,IAAI,CAAC,CAAC,GAAG,CAAC,MAAM,CAAC,GAAG,eAAO,KAAK,EAAE,MAAM,CAAC,CAAU;EAAC;AAG1F,SAAO,CAAC,cAAc,YACpB,eAAO,IAAI,aAAS;AAClB,UAAM,gBAAe,mCAAS,iBAAgB;AAE9C,UAAM,YAAY,aAAa;AAC/B,UAAM,EAAE,UAAU,aAAY,IAAK,YAAY,QAAQ,SAAS;AAEhE,UAAM,cAAc,kCAAkC;MACpD;MACA;MACA;MACA,OAAO,EAAE,SAAS,QAAW,SAAS,aAAY;KACnD;AAED,UAAM,mBAAmB,SAAQ,IAAK,eAAO,KAAK,wBAAwB,WAAW,CAAC,IAAI,eAAO,KAAI;AAErG,QACE,iBAAiB,SAAS,UAC1B,aAAa,KAAK,wBAAwB,SAAS,UACnD,aAAa,KAAK,wBAAwB,UAAU,iBAAiB,OACrE;AACA,aAAO,gBAAgB,KAAK;QAC1B,OAAO,kDAAkD,aAAa,IAAI;QAC1E,MAAM;OACP;IACH;AAaA,UAAM,UAAU,QAAQ,QAAO;AAE/B,eAAW,EAAE,cAAc,WAAU,KAAM,aAAa;AAGtD,aAAO,gBAAgB,SAAS,cAAc,UAAU;IAC1D;AAEA,UAAM,YAAY,QAAQ,UAAS;AACnC,YAAQ,OAAM;AAGd,WAAO,QACL,SACA,GAAG,UAAU;MACX,WAAW,sBAAa;MACxB,SAAS,sBAAa,0BAA0B,UAAU;MAC1D,QAAQ;QACN,cAAc,aAAa,OAAO;QAClC,cAAc,aAAa,OAAO;;QAElC,WAAW,aAAa;QACxB,OAAO,SAAS,cAAc;;KAEjC,CAAC;AAMJ,QAAI,iBAAiB,OAAO;AAC1B,YAAMG,aAAY,aAAa;AAC/B,YAAM,qBACJ,sBAAsB,IAAIA,UAAS,KAAK,kBAAkB,6BAA6BA,UAAS,EAAE;AAEpG,aAAgB,mBACd,cACA,YACA,oBACA,aAAa,UACb,aAAa,SAAS;IAE1B,OAAO;IAEP;AAEA,WAAO;MACL,kBAAkB,YACd;QACE,MAAM;QACN,MAAM;QACN,OAAO,SAAS,cAAc;UAEhC,EAAE,MAAM,QAAgB;MAC5B,MAAM;;EAEV,CAAC,EAAE,KACD,eAAO,SAAS,oDAAoD;IAClE,YAAY;MACV,WAAW,aAAa;MACxB,UAAU,aAAa;MACvB,cAAc,GAAG,4BAAoB,SAAS,aAAa,MAAM,CAAC,IAAI,aAAa,IAAI;;GAE1F,CAAC;AAGR,CAAC;AAEI,IAAM,WAAW,CAAC,EACvB,SACA,YACA,oBAAmB,MAMnB,eAAO,IAAI,aAAS;AAClB,QAAM,iBAAiB,QACpB,OACC,oBAAoB,sBAAa,4BAA4B,2CAA2C,oBAAoB,IAAI,CAAC,OAAO,IAAI,GAAG,MAAM,KAAK,GAAG,MAAM,GAAG,EAAE,KAAK,IAAI,CAAC,GAAG,EAEtL,IAAI,CAAC,OAAO;IACX,QAAQ,EAAE,QAAQ,EAAE,cAAc,QAAQ,EAAE,aAAY;IACxD,WAAW,EAAE;IACb,OAAO,EAAE;IACT,EACD,SAAS,CAAC,GAAG,MAAM,4BAAoB,QAAQ,EAAE,QAAQ,EAAE,MAAM,CAAC;AAGrE,WAAS,IAAI,eAAe,SAAS,GAAG,KAAK,GAAG,KAAK;AACnD,UAAM,EAAE,UAAS,IAAK,eAAe,CAAC;AACtC,QAAI,cAAc,MAAM;AACtB,cAAQ,cAAc,SAAS,EAAE,OAAM,EAAG,MAAK;IACjD;EACF;AAEA,QAAM,qBAAqB,cAAc,SAAS,GAAG,EACnD,oBAAoB,IAAI,CAAC,WAAW,IAAI,OAAO,MAAM,KAAK,OAAO,MAAM,GAAG,CAAC;AAI7E,aAAW,qBAAqB,oBAAoB;AAClD,YAAQ,QACN,kBAAkB,sBAAa,4BAA4B,2CAA2C,kBAAkB,KAAK,IAAI,CAAC,GAAG;EAEzI;AAGA,aAAW,qBAAqB,oBAAoB;AAClD,eAAW,QACT,kBAAkB,sBAAa,mBAAmB,2CAA2C,kBAAkB,KAAK,IAAI,CAAC,GAAG;EAEhI;AACF,CAAC,EAAE,KACD,eAAO,SAAS,kDAAkD;EAChE,YAAY,EAAE,OAAO,oBAAoB,OAAM;CAChD,CAAC;;;ACtHC,IAAM,0BAA0B,CAAC,EACtC,QACA,mBACA,YACA,SACA,gBACA,4BACA,SACA,QACA,QAAO,MA2BP,eAAO,IAAI,aAAS;AAClB,QAAM,uBAAuB,OAAO,oBAAY,KAAI;AACpD,QAAM,qBAAqB,OAAO,sBAAsB;AACxD,QAAM,uBAAuB,OAAO,wBAAwB;AAE5D,QAAM,gBAAgB,OAAO,wBAAgB,KAAsC,MAAS;AAE5F,QAAM,gBAAgB,CAAC,iBAAgD;AACrE,UAAM,EAAE,SAAQ,IAAK,YAAY,QAAQ,aAAa,IAAI;AAC1D,WAAO,SAAS,QAAQ;EAC1B;AAEA,QAAM,mCAAmC,OAAO;AAQhD,QAAM,gCAAgC,EAAE,SAAS,EAAC;AAGlD,QAAM,kBAAkB,EAAE,SAAS,iBAAiB,IAAI,OAAO,sBAAsB,OAAO,EAAC;AAC7F,QAAM,gBAAgB,oBAAI,IAAG;AAG7B,QAAM,SAAS;IACb,SAAS;;AAUX,QAAM,mBAAmB,OAAO,oBAAY,KAAI;AAChD,QAAM,mBAAmB,OAAO,eAAO,UAAU,IAAI;AACrD,QAAM,YAAY,OAAO,eAAO,UAAU,IAAI;AAW9C,QAAM,cAAc,EAAE,SAAS,4BAAoB,KAAI;AACvD,QAAM,kBAAkB,CAAC,aAAqD;AAC5E,gBAAY,UAAU,4BAAoB,IAAI,YAAY,SAAS,QAAQ;EAC7E;AAGA,QAAM,OAAoC,CAAC,WAAW,YAAS;AAhKnE;AAiKM,0BAAO,IAAI,aAAS;AAClB,UAAI,UAAU,WAAW;AAAG;AAE5B,aAAO,kBAAkB,WAAW,YAAY,OAAO;AAEvD,sBAAgB,UAAU,GAAG,EAAE,EAAG,MAAM;AAExC,YAAM,qBAAoB,mCAAS,sBAAqB;AACxD,YAAM,aAAa,8BAA8B;AAEjD,UAAI,mBAAmB;AACrB,cAAM,YAAY,OAAO,eAAO,QAAQ,WAAW,MAAM,iBAAS,KAAI,CAA0B;AAEhG,cAAM,QAAQ,UAAU,IACtB,CAAC,cAAc,MAAM,CAAC,cAAc,UAAU,CAAC,GAAG,UAAU,CAAuB;AAGrF,eAAO,oBAAY,SAAS,kBAAkB,KAAK;AAEnD,eAAO,eAAO,IAAI,SAAS;MAC7B,OAAO;AACL,cAAM,QAAQ,UAAU,IAAI,CAAC,iBAAiB,CAAC,cAAc,QAAW,UAAU,CAAuB;AACzG,eAAO,oBAAY,SAAS,kBAAkB,KAAK;MACrD;IACF,CAAC,EAAE,KACD,eAAO,SAAS,8CAA8C;MAC5D,YAAY;QACV,WAAW,UAAU;QACrB,OAAO,gBAAgB,YAAY;;MAErC,SAAO,YAAO,YAAP,mBAAgB,QAAO,CAAC,EAAE,MAAM,YAAY,MAAM,OAAO,QAAQ,MAAM,YAAY,CAAA,EAAE,CAAE,IAAI;KACnG,CAAC;;AAGN,QAAM,cAAkD,CAAC,EAAE,OAAO,EAAE,MAAM,KAAI,GAAI,UAAU,UAAS,MACnG,eAAO,IAAI,aAAS;AAClB,UAAMC,aAAY,OAAO;AACzB,QAAIA,eAAc;AAAW,aAAO,kBAAkB,iBAAiB;AAEvE,UAAM,EAAE,SAAQ,IAAK,YAAY,QAAQ,IAAI;AAE7C,UAAM,eAAe,IAAI,uBAAe,gBAAgB;MACtD;MACA;MACA;MACA;MACA,GAAG,4BAAoB,SAASA,WAAU,WAAW,SAAS,QAAQ,UAAU;KACjF;AAED,WAAO,KAAK,CAAC,YAAY,CAAC;EAC5B,CAAC,EAAE,KAAK,eAAO,SAAS,oBAAoB,eAAO,KAAK,CAAC;AAG3D,QAAM,OAAoC,eAAO,IAAI,aAAS;AAtNlE;AAuNM,UAAM,OAAO,OAAO,eAAO,YAAY,KAAK,eAAO,KAAK;AACxD,UAAM,WAAW,OAAO,eAAW,gBAAgB,KAAK,eAAO,SAAS,MAAM,eAAO,QAAQ,MAAS,CAAC,CAAC;AACxG,UAAM,EAAE,UAAU,gBAAe,IAAK,OAAO;AAC7C,UAAM,UAAU,OAAO,eAAO,QAAO;AAErC,WAAO,UAAU;MACf;MACA;MACA,eAAe,SAAS,UAAU,SAAS,mBAAmB;MAC9D;;AAGF,UAAM,mBAAmB,oBAAoB,4BAAoB,OAAgB,oBAAoB,UAAU;AAE/G,UAAM,qBAAqB,oBACvB,4BAAoB,KAAK,SAChB,qBAAqB,UAAU;AAE5C,QAAI,qBAAqB,iBAAiB,QAAQ;AAChD,aAAO,kBACL,iCAAiC,kBAAkB,kDAAkD,iBAAiB,MAAM,GAAG;IAEnI;AAEA,UAAM,gBAAgB,oBAClB,CAAA,IACA,OAAgB,eAAe,EAAE,QAAQ,oBAAoB,QAAQ,4BAAoB,cAAa,CAAE;AAE5G,UAAM,mBAAmB,IAAc,UAAU;MAC/C,SAAS;MACT,cAAc,EAAE,QAAQ,oBAAoB,QAAQ,4BAAoB,cAAa;MACrF,WAAW;KACZ;AAGD,WAAO,wBAAgB,IAAI,eAAe,gBAAgB;AAG1D,QAAI,cAAc,SAAS,GAAG;AAC5B,YAAM,sBAAsB,cAEzB,OAAO,CAAC,iBAAgB;AACvB,cAAM,EAAE,SAAQ,IAAK,YAAY,QAAQ,aAAa,IAAI;AAC1D,eAAO,SAAS,QAAQ,eAAe;MACzC,CAAC;AAEH,UAAI,oBAAoB,SAAS,GAAG;AAClC,eAAO,oBAAY,SAAS,sBAAsB,mBAAmB;MACvE;IACF;AAEA,UAAM,kBAAkB,CAAC,UACvB,eAAO,IAAI,aAAS;AAClB,UAAI,YAAY,YAAY;AAC1B,eAAO,gBAAgB,KAAK,gBAAgB,KAAK,EAAE,MAAK,CAAE,CAAC;AAC3D,eAAO,eAAO,IAAI,KAAK;MACzB;IACF,CAAC;AAEH,WAAO,2BAA2B;MAChC;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA,SAAS;QACP,QAAO,wCAAS,WAAT,mBAAiB;;KAE3B,EAAE,KAAK,eAAO,mBAAmB,eAAO,cAAc,eAAe,GAAG,eAAO,UAAU;AAE1F,UAAM,4BAA4B,OAAO,oBAAY,KAAI;AACzD,UAAM,uBAAuB,yBAAyB;MACpD;MACA;MACA,gBAAe,YAAO,YAAP,mBAAgB;MAC/B;KACD,EAAE,KAAK,eAAO,mBAAmB,eAAO,cAAc,eAAe,CAAC;AAEvE,WAAO,oBAAY,IAAI,2BAA2B,oBAAoB;AAEtE,WAAO,yBAAyB;MAC9B;MACA;MACA,uBAAuB,CAAC,2BACtB,eAAO,IAAI,aAAS;AAElB,eAAO,oBAAY,MAAM,yBAAyB;AAGlD,eAAO,oBAAY,MAAM,oBAAoB;AAC7C,eAAO,oBAAY,SAAS,sBAAsB,sBAAsB;AAGxE,eAAO,oBAAY,IAAI,2BAA2B,oBAAoB;MACxE,CAAC;MACH;MACA;MACA;MACA;MACA;MACA;MACA,gBAAe,YAAO,YAAP,mBAAgB;MAC/B;MACA;MACA;MACA;KACD,EAAE,KAAK,eAAO,mBAAmB,eAAO,cAAc,eAAe,GAAG,eAAO,UAAU;AAE1F,WAAO,EAAE,mBAAmB,iBAAgB;EAC9C,CAAC,EAAE,KAAK,eAAO,eAAe,4CAA4C,CAAC;AAE3E,QAAM,OAAoC,CAAC,EAAE,OAAM,MACjD,eAAO,IAAI,aAAS;AAClB,UAAM,QAAQ,OAAO,UAAU,EAAE,OAAM,CAAE;AACzC,WAAO,eAAO,UAAU,KAAK;EAC/B,CAAC,EAAE,KAAK,eAAO,YAAY;AAE7B,QAAM,YAA8C,CAAC,EAAE,OAAM,MAAM;AApVvE;AAqVM,UAAM,YAAU,YAAO,YAAP,mBAAgB,YAAW,kBAAkB,iBAAiB;AAC9E,WAAO,eAAO,IAAI,aAAS;AACzB,YAAM,QAAQ,OAAO,iCAAiC;AACtD,YAAM,sBAAsB,MAAM,KAAK,cAAc,QAAO,CAAE,EAC3D,IAAI,CAAC,CAAC,cAAc,OAAO,OAAO,EAAE,SAAS,aAAY,EAAG,EAC5D,OAAO,CAAC,EAAE,aAAY,MAAO,eAAe,OAAO,YAAY,EAC/D,SAAS,CAAC,GAAG,MAAM,EAAE,eAAe,EAAE,YAAY,EAClD,IAAI,CAAC,EAAE,SAAS,aAAY,MAAM;AACjC,YAAI,QAAQ,SAAS,oBAAoB;AACvC,iBAAO;YACL,SAAS;cACP,MAAM;cACN,WAAW,cAAc,UAAU,QAAQ,WAAW,CAAC,iBACrD,4BAAoB,qBAAqB,OAAO,UAAU,aAAa,MAAM,CAAC;;YAGlF;;QAEJ,OAAO;AACL,iBAAO,EAAE,SAAS,aAAY;QAChC;MACF,CAAC;AAEH,aAAO,MAAM,SAAS,mBAAmB;AAEzC,aAAO;IACT,CAAC,EAAE,KAAK,eAAO,QAAQ,OAAO,CAAC;EACjC;AAEA,QAAM,YAAY,qBAAa,KAAK;IAClC,KAAK,eAAO,IAAI,aAAS;AACvB,YAAMA,aAAY,OAAO;AACzB,UAAIA,eAAc;AAAW,eAAO,kBAAkB,iBAAiB;AACvE,aAAOA;IACT,CAAC;IACD,SAAS,cAAc,QAAQ,KAAK,eAAO,OAAO,cAAc,CAAC;GAClE;AAED,SAAO;IACL;IACA;IACA;IACA;IACA;IACA;IACA,iBAAiB,MAAM,gBAAgB;;AAE3C,CAAC;AAEH,IAAM,6BAA6B,CAAC,EAClC,kBACA,kBACA,WACA,eACA,sBACA,QACA,eACA,UACA,+BACA,kCACA,iBACA,eACA,oBACA,QAAO,MAmBP,eAAO,IAAI,aAAS;AAClB,SAAO,MAAM;AACX,QAAI,QAAQ,UAAU,QAAW;AAC/B,aAAO,QAAQ,MAAM,KAAK,eAAO,SAAS,0BAA0B,CAAC;IACvE;AAEA,UAAM,aAAa,OAAO,oBAAY,YAAY,kBAAkB,GAAG,kBAAkB;AAGzF,WAAO,iBAAiB;AAGxB,WAAO,UAAU;AAIjB,UAAM,qBAAqB,WACxB,OAAO,CAAC,CAAC,IAAI,IAAI,UAAU,MAAM,eAAe,8BAA8B,OAAO,EACrF,IAAI,CAAC,CAAC,cAAc,QAAQ,MAAM,CAAC,cAAc,QAAQ,CAAU;AAEtE,QAAI,mBAAmB,WAAW,GAAG;AAGnC,aAAO,UAAU;AACjB;IACF;AAEA,UAAM,CAAC,WAAW,SAAS,IAAI,cAAc,MAAM,kBAAkB;AAErE,UAAM,YAAY,OAAO;AACzB,QAAI,cAAc;AAAW,aAAO,kBAAkB,iBAAiB;AAEvE,UAAM,cAAwB,MAAM;MAClC;MACA,SAAS,EAAE,MAAM,cAAc,UAAS;MACxC;MACA,cAAc,uBAAe;KAC9B;AAED,UAAM,eAAe,OAAO,sBAAsB,eAAe;AAEjE,YAAQ,YAAY,MAAM;MACxB,KAAK,oBAAoB;AACvB,6CAAU,SAAS,IAAI,YAAY,2BAA2B;UAC5D,WAAW,UAAU;UACrB,WAAW,gBAAgB,KAAK,UAAU,SAAS,IAAI;;AAEzD,eAAO,OAAO,eAAO,KAAK,YAAY,KAAK;MAC7C;MACA,KAAK,UAAU;AACb,eAAO,kBAAkB,mEAAmE;MAC9F;MACA,KAAK,UAAU;AACb,6CAAU,SAAS,IAAI,YAAY,iBAAiB;UAClD,WAAW,UAAU;UACrB,aAAa,gBAAgB,KAAK,UAAU,WAAW,IAAI;;AAI7D,sCAA8B;AAE9B,cAAM,iBAAiB,8BAA8B;AAErD,cAAM,cAAc,UAAU,GAAG,CAAC,EAAG;AAIrC,cAAM,oCAAoC,OAAO,oBAAY,eAC3D,kBACA,CAAC,SAAS,KAAK,CAAC,KAAK,cAAc;AAIrC,YAAI,WAAW,OAAO,oBAAY,KAAK,gBAAgB,KAAK,GAAG;AAC7D,kBAAQ,IAAI,iCAAiC,OAAO,oBAAY,KAAK,gBAAgB,CAAC;AAEtF;QACF;AAEA,cAAM,uBAAuB;UAC3B,GAAG;UACH,GAAG,kCAAkC,IAAI,CAAC,CAAC,GAAG,QAAQ,MAAM,QAAQ;UACpE,OAAO,cAAc;AAEvB,eAAO,eAAO,QAAQ,sBAAsB,CAAC,aAC3C,iBAAS,KACP,UACA,iBAAiB,KAAK;UACpB,oBAAoB,YAAY;UAChC;;SAED,CAAC,CACH;AAIH,eAAO,UAAU;AAIjB;MACF;MACA,KAAK,WAAW;AACd;MACF;MACA,SAAS;AACP,qBAAa,WAAW;MAC1B;IACF;AAEA,WAAO,wBAAgB,IAAI,eAAe,YAAY,YAAY;AAElE,WAAO,iCAAiC,MAAM;MAC5C,SAAmB,uBAAuB,KAAK,EAAE,WAAW,YAAY,UAAS,CAAE;MACnF;KACD;AACD,kBAAc,IAAI,cAAwB,uBAAuB,KAAK,EAAE,WAAW,YAAY,UAAS,CAAE,CAAC;AAE3G,yCAAU,SAAS,IAAI,YAAY,kBAAkB;MACnD,WAAW,UAAU;MACrB,aAAa,gBAAgB,KAAK,UAAU,WAAW,IAAI;;AAI7D,UAAM,gBAAgB,YAAY,UAAU,OAAO,CAAC,iBAAgB;AAClE,YAAM,EAAE,SAAQ,IAAK,YAAY,QAAQ,aAAa,IAAI;AAC1D,aAAO,SAAS,QAAQ,eAAe;IACzC,CAAC;AAED,WAAO,oBAAY,SAAS,sBAAsB,aAAa;AAE/D,WAAO,uBAAuB,EAAE,YAAY,YAAY,WAAW,UAAS,CAAE;AAG9E,WAAO,UAAU;EACnB;AACF,CAAC;AAYH,IAAM,yBAAiD,CAAC,EAAE,YAAY,UAAS,MAC7E,eAAO,IAAI,aAAS;AAClB,QAAM,EAAE,SAAS,IAAI,YAAY,iBAAgB,IAAK,OAAO;AAG7D,KAAG,QAAQ,qBAAqB,MAAS;AACzC,aAAW,QAAQ,qBAAqB,MAAS;AAEjD,SAAO,eAAO,aAAa,CAAC,SAC1B,eAAO,IAAI,aAAS;AAClB,QAAI,aAAK,UAAU,IAAI;AAAG;AAG1B,OAAG,QAAQ,YAAY,MAAS;AAChC,eAAW,QAAQ,YAAY,MAAS;EAC1C,CAAC,CAAC;AAGJ,WAAS,IAAI,GAAG,IAAI,WAAW,QAAQ,KAAK;AAC1C,UAAM,EAAE,kBAAkB,KAAI,IAAK,OAAO,iBAAiB,WAAW,CAAC,CAAE;AACzE,eAAW,CAAC,EAAG,KAAK,mBAAmB;AACvC,eAAW,CAAC,EAAG,KAAK,yBAAyB;AAE7C,SAAI,uCAAY,QAAO,QAAW;AAChC,aAAO,iBAAS,QAAQ,UAAU,CAAC,GAAI,MAAM;IAC/C;EACF;AAEA,KAAG,QAAQ,UAAU,MAAS;AAC9B,aAAW,QAAQ,UAAU,MAAS;AACxC,CAAC,EAAE,KACD,eAAO,iBACP,eAAO,QACP,eAAO,SAAS,+DAA+D;EAC7E,YAAY,EAAE,WAAW,WAAW,OAAM;CAC3C,GACD,eAAO,mBACP,gBAAgB,oBAAoB;AAGxC,IAAM,2BAA2B,CAAC,EAChC,oBACA,eACA,uBACA,UACA,SACA,eACA,kBACA,WACA,eACA,4BACA,kCACA,iBACA,eACA,gBAAe,MAmBf,eAAO,IAAI,aAAS;AAClB,QAAM,EAAE,aAAa,SAAS,IAAI,YAAY,OAAM,IAAK,OAAO;AAEhE,MAAI,gBAAgB;AAAW;AAE/B,QAAM,iBAAiB,CAAC,WAA6C,cACnE,eAAO,IAAI,aAAS;AAClB,QAAI,UAAU,WAAW;AAAG;AAE5B,QAAI,kBAAkB,QAAW;AAC/B,aAAO,cAAc;IACvB;AAGA,WAAO,iBAAiB;AAGxB,WAAO,UAAU;AAEjB,UAAM,YAAY,OAAO;AACzB,QAAI,cAAc;AAAW,aAAO,kBAAkB,iBAAiB;AAEvE,UAAM,cAAwB,MAAM;MAClC;MACA,SAAmB,uBAAuB,KAAK,EAAE,UAAS,CAAE;MAC5D;MACA,cAAc,uBAAe;MAC7B,oBAAoB;KACrB;AAED,UAAM,eAAe,OAAO,sBAAsB,eAAe;AAEjE,QAAI,YAAY,SAAS,UAAU;AACjC,aAAO,kBAAkB,yDAAyD;IACpF,WAAW,YAAY,SAAS,oBAAoB;AAClD,2CAAU,SAAS,IAAI,YAAY,2BAA2B;QAC5D,gBAAgB,UAAU;QAC1B,WAAW,gBAAgB,KAAK,UAAU,SAAS,IAAI;;AAEzD,aAAO,OAAO,eAAO,KAAK,YAAY,KAAK;IAC7C;AAEA,UAAM,iBAAiB,UAAU,GAAG,EAAE,EAAG;AAEzC,IAAS,kBAAkB,YAAY,cAAc;AAErD,QAAI,YAAY,SAAS,UAAU;AACjC,2CAAU,SAAS,IAAI,YAAY,iBAAiB;QAClD,gBAAgB,UAAU;QAC1B,WAAW,gBAAgB,KAAK,UAAU,SAAS,IAAI;QACvD,eAAe,YAAY,eAAe;QAC1C,aAAa,gBAAgB,KAAK,UAAU,WAAW,IAAI;;AAG7D,YAAM,6BAA6B,YAAY,aAAa,QAAQ,OAAO,CAAC,UAAS;AACnF,cAAM,EAAE,SAAQ,IAAK,YAAY,QAAQ,MAAM,IAAI;AACnD,eAAO,SAAS,QAAQ,eAAe;MACzC,CAAC;AACD,aAAO,sBAAsB,0BAA0B;AAEvD,UAAI,YAAY,eAAe,SAAS,GAAG;AACzC,eAAO,SAAS;UACd,SAAS;UACT;UACA,qBAAqB,YAAY,eAAe,IAAI,CAAC,MAAM,EAAE,MAAM;SACpE;MACH;AAEA,aAAO,iCAAiC,MAAM;QAC5C,SAAmB,sBAAsB,KAAK;UAC5C,WAAW,YAAY;UACvB,gBAAgB,YAAY;SAC7B;QACD;OACD;AACD,oBAAc,IACZ,cACU,sBAAsB,KAAK;QACnC,WAAW,YAAY;QACvB,gBAAgB,YAAY;OAC7B,CAAC;IAEN,OAAO;AACL,2CAAU,SAAS,IAAI,YAAY,kBAAkB;QACnD,gBAAgB,UAAU;QAC1B,aAAa,gBAAgB,KAAK,UAAU,WAAW,IAAI;;AAG7D,aAAO,iCAAiC,MAAM;QAC5C,SAAmB,uBAAuB,KAAK,EAAE,WAAW,YAAY,UAAS,CAAE;QACnF;OACD;AACD,oBAAc,IAAI,cAAwB,uBAAuB,KAAK,EAAE,WAAW,YAAY,UAAS,CAAE,CAAC;AAE3G,UAAI,YAAY,gBAAgB,SAAS,GAAG;AAG1C,cAAM,qBAAqB,UAAU,OAAO,CAAC,UAC3C,YAAY,gBAAgB,KAAK,CAAC,mBAChC,4BAAoB,QAAQ,MAAM,QAAQ,eAAe,MAAM,CAAC,CACjE;AAEH,eAAgB,mBAAmB,kBAAkB;MACvD;IACF;AAGA,sBAAkB,IAAI,cAAc;AAEpC,oBAAgB,YAAY,aAAa,SAAS;AAElD,WAAO,uBAAuB,EAAE,YAAY,YAAY,WAAW,WAAW,OAAS,CAAE;AAEzF,WAAO,wBAAgB,IAAI,eAAe,YAAY,YAAY;AAGlE,QAAI,cAAc,GAAG;AACnB,aAAO,iBAAiB;IAC1B;EACF,CAAC;AAEH,QAAM,aAAa,OAAgB,yBAAyB,kBAAkB;AAE9E,QAAM,yBAAyB,qBAAqB,EAAE,QAAQ,QAAO,CAAE;AAEvE,SAAO,YAAY,KAAK,UAAU,EAAE;;IAElC,eAAO,IAAI,CAAC,EAAE,OAAO,UAAS,MAC5B,eAAO,IAAI,aAAS;AAWlB,aAAO,wBAAgB,UAAU,YAAY,aAAa,CAAC,gBAAgB,gBAAgB,IAAI;AAE/F,aAAO,eACL,MAAM,IAAI,CAAC,MACT,uBAAe,gBAAgB,WAAW,EAAE,cAAc;QACxD,cAAc,EAAE;QAChB,wBAAwB,uBAAuB,EAAE,YAAY;QAC7D,yBAAyB,eAAO,KAAI;OACrC,CAAC,GAEJ,SAAS;AAGX,aAAO,2BAA2B,OAAO,EAAE,WAAW,MAAM,QAAQ,UAAS,CAAE;IACjF,CAAC,CAAC;IAEJ,eAAO;IACP,eAAO;EAAa;AAExB,CAAC,EAAE,KAAK,eAAO,SAAS,uDAAuD,CAAC;AAElF,IAAM,2BAA2B,CAAC,EAChC,sBACA,UACA,eACA,qBAAoB,MAOpB,eAAO,IAAI,aAAS;AAClB,QAAM,EAAE,YAAW,IAAK,OAAO;AAC/B,MAAI,gBAAgB;AAAW;AAE/B,SAAO,MAAM;AACX,WAAO,wBAAgB,UAAU,YAAY,aAAa,CAAC,gBAAgB,gBAAgB,IAAI;AAE/F,UAAM,aAAa,OAAO,oBAAY,YAAY,sBAAsB,GAAG,oBAAoB;AAE/F,WAAO,wBAAgB,UAAU,YAAY,aAAa,CAAC,gBAAgB,gBAAgB,IAAI;AAE/F,QAAI,kBAAkB,QAAW;AAC/B,aAAO,cAAc;IACvB;AAEA,yCAAU,SAAS,gBAAgB;MACjC,WAAW,WAAW;MACtB,OAAO,gBAAgB,KAAK,UAAU,UAAU,IAAI;;AAItD,UAAM,aAAa,OAAO,YAAY,KAAK,WAAW,IAAI,CAAC,MAAM,EAAE,SAAQ,CAAE,CAAC,EAAE,KAAK,eAAO,MAAM;AAElG,QAAI,WAAW,SAAS,QAAQ;AAC9B,UAAI,QAAQ;AACV,eAAO,eAAO,SAAS,8BAA8B,EAAE,OAAO,WAAW,KAAK,SAAQ,EAAE,CAAE;MAC5F;AACA,2CAAU,SAAS,sBAAsB,EAAE,OAAO,WAAW,KAAK,SAAQ,EAAE;AAE5E,aAAO,OAAO,eAAO;IACvB;EACF;AACF,CAAC,EAAE,KAAK,eAAO,eAAe,eAAO,SAAS,uDAAuD,CAAC;AAExG,IAAM,oBAAoB,CAAC,IAAc,YAAoD;AAG3F,KAAG,QAAQ,kBAAkB,sBAAa,4BAA4B,yBAAyB,QAAQ,MAAM,EAAE;AACjH;AAcA,IAAM,mBAAmB,eAAO,IAAI,aAAS;AAC3C,QAAM,MAAM,oBAAI,IAAG;AAEnB,SAAO,eAAO,aAAa,MACzB,eAAO,IAAI,aAAS;AAClB,eAAW,SAAS,KAAK;AACvB,aAAO,cAAM,SAAS,KAAK;IAC7B;AAEA,QAAI,MAAK;EACX,CAAC,CAAC;AAGJ,QAAM,YAAuC,eAAO,IAAI,aAAS;AAC/D,UAAM,QAAQ,OAAO,cAAM,UAAS,EAG/B,KAAK,eAAO,eAAe,cAAM,QAAQ,CAAC;AAE/C,WAAO,eAAO,aAAa,MAAM,eAAO,KAAK,MAAM,IAAI,OAAO,KAAK,CAAC,CAAC;AAErE,QAAI,IAAI,KAAK;AAEb,WAAO;EACT,CAAC;AAED,QAAM,QAA+B,CAAC,SACpC,eAAO,IAAI,aAAS;AAElB,QAAI,KAAK,QAAQ,SAAS,sBAAsB,KAAK,QAAQ,UAAU,WAAW,GAAG;AACnF;IACF;AAEA,eAAW,SAAS,KAAK;AACvB,aAAO,cAAM,MAAM,OAAO,IAAI;IAChC;EACF,CAAC;AAEH,SAAO;IACL;IACA;;AAEJ,CAAC;AAED,IAAM,wBAAwB,CAAC,oBAC7B,eAAO,IAAI,aAAS;AAClB,QAAM,EAAE,QAAO,IAAK,OAAO;AAC3B,kBAAgB;AAChB,UAAQ,QACN,6BAA6B,sBAAa,0BAA0B,kCAAkC,gBAAgB,OAAO,GAAG;AAElI,SAAO,gBAAgB;AACzB,CAAC;AAEH,IAAM,wBAAwB,CAAC,YAC7B,eAAO,IAAI,aAAS;AA15BtB;AA25BI,QAAM,SAAS,QAAQ,OACrB,+BAA+B,sBAAa,0BAA0B,eAAe;AAEvF,WAAO,YAAO,CAAC,MAAR,mBAAW,iBAAgB;AACpC,CAAC;AAEH,IAAM,oBAAoB,CACxB,OACA,aAEA,eAAO,IAAI,aAAS;AAClB,MAAI,MAAM,WAAW,GAAG;AACtB;EACF;AAGA,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,QAAI,4BAAoB,qBAAqB,MAAM,IAAI,CAAC,EAAG,QAAQ,MAAM,CAAC,EAAG,MAAM,GAAG;AACpF,wBACE,mFAAmF,MAAM,IAAI,CAAC,MAAM,4BAAoB,SAAS,EAAE,MAAM,CAAC,EAAE,KAAK,IAAI,CAAC,GAAG;IAE7J;EACF;AAGA,MAAI,4BAAoB,qBAAqB,UAAU,MAAM,CAAC,EAAG,MAAM,GAAG;AACxE,WAAO,OAAO,iBAAiB,KAAK;MAClC,oBAAoB;MACpB,aAAa,MAAM,CAAC,EAAG;KACxB;EACH;AACF,CAAC;;;ACj7BI,IAAM,aAIT,eAAO,IAAI,aAAS;AACtB,QAAM,EAAE,SAAS,YAAY,QAAQ,iBAAiB,iBAAgB,IAAK,OAAO;AAElF,QAAM,mBAAmB,OAAO,MAAM,OAAO;AAC7C,MAAI;AAEJ,SAAO,eAAO,aACZ,eAAO,GAAG,sBAAsB,EAAE,WAAW,IAAE;AAC7C,QAAI,GAAG,SAAS;AAAW,cAAQ,QAAO;EAC5C,CAAC,CAAC;AAOJ,QAAM,QAAQ;AACd,SAAO,oBAAoB,OAAO,EAAE,aAAa,KAAI,CAAE;AAEvD,QAAM,SAAS,CAAC,UACd,eAAO,IAAI,aAAS;AAClB,WAAO,eAAO,OAAO,MAAG;AAlC9B;AAkCiC,kDAAO,SAAP,+BAAc;KAAM,EAAE,KAAK,gBAAgB,oBAAoB;AAE1F,UAAMC,oBAAmB,OAAO,UAAU;MACxC,IAAI;MACJ;MACA,YAAY,CAAC,EAAE,MAAM,MAAK,MACxB,cAAM,MAAM,iBAAiB,EAAE,OAAO,aAAa,UAAU,EAAE,MAAM,MAAK,EAAE,CAAE;KACjF;AAED,WAAO,eAAO,OAAO,MAAG;AA3C9B;AA2CiC,kDAAO,QAAP,+BAAa;KAAM,EAAE,KAAK,gBAAgB,oBAAoB;AAEzF,WAAO,EAAE,kBAAAA,mBAAkB,MAAK;EAClC,CAAC;AAEH,UAAQ,iBAAiB,UAAU;IACjC,KAAK,QAAQ;AACX,YAAM,QAAQ,iBAAiB;AAC/B,YAAM,aAAa,OAAO,OAAO,KAAK;AAEtC,yBAAmB,WAAW;AAE9B,aAAO,0BAA0B;;QAE/B;QACA;QACA;QACA,YAAY,CAAC,EAAE,MAAM,MAAK,MACxB,cAAM,MAAM,iBAAiB,EAAE,OAAO,eAAe,UAAU,EAAE,MAAM,MAAK,EAAE,CAAE;OACnF;AAED,aAAO,eAAO,OAAO,MAAG;AAhE9B;AAgEiC,oDAAO,SAAP,+BAAc,WAAW;OAAM,EAAE,KAAK,gBAAgB,oBAAoB;AAErG;IACF;IACA,KAAK,UAAU;AACb,YAAM,YAAY,QAAQ,OAAM;AAEhC,yBAAmB,EAAE,YAAY,CAAA,EAAE;AAEnC,YAAM,YAAY,OAAO,eAAO,OAAO,MAAM,iBAAiB,QAAQ,SAAS,CAAC,EAAE,KAChF,gBAAgB,oBAAoB;AAGtC,YAAM,OAAO,SAAS;AAItB;IACF;IACA,SAAS;AACP,mBAAa,gBAAgB;IAC/B;EACF;AAgBA,SAAO,EAAE,iBAAgB;AAC3B,CAAC,EAAE;EACD,eAAO;;EACP,eAAO,SAAS,4CAA4C;EAC5D,eAAO,uBAAuB,4CAA4C;AAAC;;;ACzDtE,IAAM,wBAAwB,CAAC,EACpC,QACA,SACA,UACA,aACA,cAAAC,eACA,aACA,SACA,YACA,iBACA,iBACA,QACA,QAAO,MAEP,eAAO,IAAI,aAAS;AA9DtB;AA+DI,QAAM,kBAAkB,OAAO,cAAM,UAAS,EAAe,KAAK,eAAO,eAAe,cAAM,QAAQ,CAAC;AAIvG,QAAM,oBACJ,WAAW,OAA0B,gDAAgD,EAAE,CAAC,EAAG,UAAU;AAEvG,QAAM,iBACJ,QAAQ,OAA0B,gDAAgD,EAAE,CAAC,EAAG,UAAU;AAEpG,QAAM,eACJ,2CAAa,aAAY,SACrB,SACA,OAAO,YAAY,QAAQ,EAAE,SAAS,UAAU,SAAS,YAAW,CAAE;AAE5E,MAAI,gBAAgB,QAAW;AAE7B,WAAO,YAAY,QAAQ,KAAK,eAAO,mBAAmB,eAAO,UAAU;EAC7E;AAEA,QAAM,6BAA6B,OAAO,+BAA+B;IACvE,qBAAoB,2CAAa,uBAAsB,EAAE,MAAM,OAAM;IACrE;GACD;AAED,QAAM,gBAAgB,OAAO,wBAAwB;IACnD;IACA;IACA;IACA;IACA;IACA;IACA,UAAS,2CAAa,gBAAe;IACrC,QAAQ;MACN,oBAAoB,iCAAQ;MAC5B,sBAAsB,iCAAQ;;IAEhC,SAAS;MACP,SAAQ,wCAAS,kBAAT,mBAAwB;;GAEnC;AAED,QAAM,6BAA6B,OAAO,cAAM,UAAS,EAAiC,KACxF,eAAO,eAAe,cAAM,QAAQ,CAAC;AAGvC,QAAM,kBAAkB,gBAAgB,UACpC;IACE,SAAS;IACT,kBAAkB,OAAO,eAAO,UAAU,IAAI;IAC9C,uBAAuB,OAAO,wBAAgB,KAA+B,EAAE,aAAa,MAAK,CAAE;MAErG,EAAE,SAAS,MAAc;AAE7B,QAAM,mBAAmB,OAAO,qBAAqB,EAAE,QAAQ,SAAS,WAAU,CAAE;AAEpF,QAAM,MAAM;IACV;IACA;IACA;IACA;IACA;IACA;IACA,cAAAA;IACA,aAAa,uBAAe,mBAAmB,MAAM;IACrD,qBAAqB,OAAO,wBAAgB,KAAoB,SAAS;IACzE;IACA;IACA;IACA;IACA;IACA,UAAU;;IAEV,cAAc,CAAA;;AAIhB,aAAW,oBAAoB;AAE/B,QAAM,QAAQ,cAAM,QAAQ,iBAAiB,GAAG;AAEhD,MAAI,eAAe,OAAO,iBAAiB;IACzC;IACA;IACA;GACD,EAAE,KAAK,eAAO,QAAQ,KAAK,CAAC;AAE7B,SAAO;AACT,CAAC,EAAE,KACD,eAAO,SAAS,sCAAsC,GACtD,eAAO,eAAe,iCAAiC,GACvD,gBAAgB,sBAChB,eAAO,mBACP,cAAM,YAAY;AAGtB,IAAM,iCAAiC,CAAC,EACtC,oBACA,gBAAe,MAKf,eAAO,IAAI,aAAS;AAClB,QAAM,MAAM;IACV,QAAQ;IACR,iBAAiB;IACjB,OAAO;;AAGT,QAAM,mBAAmB,mBAAmB,SAAS,aAAa,OAAO,iBAAS,KAAI,IAAW;AAEjG,MAAI,qBAAqB,UAAa,mBAAmB,SAAS,YAAY;AAC5E,WAAO,iBAAS,QAAQ,kBAAkB,MAAM,EAAE,KAChD,eAAO,MAAM,mBAAmB,OAAO,GACvC,eAAO,UAAU;EAErB;AAEA,SAAO;IACL;IACA,QAAQ,CAAC,EAAE,WAAW,UAAS,MAC7B,eAAO,IAAI,aAAS;AAClB,UAAI,IAAI,WAAW;AAAM;AAEzB,UAAI,IAAI,UAAU,IAAI;AACpB,YAAI,QAAQ,YAAY;MAC1B;AAEA,UAAI,mBAAmB;AACvB,aAAO,cAAM,MAAM,iBAAiB;QAClC,OAAO;QACP,UAAU,EAAE,MAAM,IAAI,iBAAiB,OAAO,IAAI,MAAK;OACxD;AAED,UAAI,cAAc,KAAK,qBAAqB,QAAW;AACrD,eAAO,iBAAS,QAAQ,kBAAkB,MAAM;AAChD,YAAI,SAAS;MACf;IACF,CAAC;;AAEP,CAAC;AAMH,IAAM,mBAAmB,CAAC,EACxB,gBACA,4BACA,gBAAe,MAUf,eAAO,IAAI,aAAS;AAClB,QAAM,EAAE,YAAY,iBAAiB,cAAa,IAAK,OAAO;AAE9D,SAAgB,eAAe,UAAU;AAEzC,QAAM,EAAE,iBAAgB,IAAK,iBAAiB,OAAO,aAAa,EAAE,kBAAkB,EAAE,YAAY,CAAA,EAAE,EAAE;AAGxG,QAAM,EAAE,kBAAiB,IAAK,OAAO,cAAc;AAEnD,MAAI,2BAA2B,qBAAqB,QAAW;AAE7D,WAAO,cAAM,MAAM,iBAAiB;MAClC,OAAO;MACP,UAAU,EAAE,MAAM,GAAG,OAAO,GAAE;KAC/B;AAED,WAAO,2BAA2B,iBAAiB,KACjD,eAAO,SAAS,uDAAuD,CAAC;EAE5E;AAEA,SAAO,cAAM,MAAM,iBAAiB,EAAE,OAAO,OAAM,CAAE;AAErD,SAAO,aAAa,eAAe,EAAE,KAAK,eAAO,mBAAmB,eAAO,UAAU;AAErF,SAAO,EAAE,kBAAkB,YAAY,kBAAiB;AAC1D,CAAC;;;AC1PH;;;;AAIM,IAAO,MAAP,cAAmB,eAAO,MAAM,0BAA0B,eAAe,EAAC;;;;ACLhF;;;;;AAEM,IAAO,mBAAP,cAAgC,eAAO,cAAa,EAAqB,sCAAsC;EACnH,SAAS;IACP,MAAM,eAAO;IACb,MAAM,qBAAa;;EAErB,SAAS,eAAO,OAAO,CAAA,CAAE;EACzB,SAAS,eAAO;CACjB,EAAC;;AAEI,IAAO,UAAP,cAAuB,eAAO,MAAM,gBAAgB,EAAC;;;;ACFrD,IAAO,gBAAP,MAAO,sBAAqB,gBAAQ,IAAI,6CAA6C,EAAC,EAGzF;;AACD,cAJW,eAIJ,SAAQ,CAAC,EAAE,SAAQ,MACxB,eAAO,IAAI,aAAS;AAClB,QAAM,OAAO,OAAO,aAAa,QAAQ;AAEzC,aAAW,qBAAqB;AAEhC,SAAO,EAAE,KAAI;AACf,CAAC,EAAE,KAAK,cAAM,OAAO,aAAY,CAAC;AAXhC,IAAO,eAAP;AAcC,IAAMC,oBAAmB,CAAC,EAAE,MAAM,KAAI,MAC3C,eAAO,YAAqC,CAAC,SAC3C,eAAO,IAAI,aAAS;AAClB,QAAM,EAAE,KAAI,IAAK,OAAO;AAExB,QAAM,qBAAqB,OAAO,YAAW,mBAAmB,EAAE,MAAM,QAAQ,oBAAc,OAAM,CAAE;AAEtG,SAAO,KAAK,QAAQ,EAAE,QAAQ,MAAM,aAAa,oBAAoB,iBAAiB,KAAI,CAAE;AAE5F,MAAI,QAAQ;AACV,WAAO,eAAO,SAAS,kDAAkD,KAAK,QAAQ,MAAM,IAAI,EAAE;EACpG;AAEA,OAAK,OAAO,CAAA,CAAE;AAEd,SAAO,eAAO,UAAU,EAAE,aAAa,CAAC,GAAG,KAAK,QAAQ,EAAC,CAAE;AAM7D,CAAC,EAAE,KAAK,eAAO,KAAK,CAAC,EACrB,KAAK,eAAO,SAAS,2DAA2D,IAAI,EAAE,CAAC;;;AC5C3F,SAAS,iBAAiB;AAE1B,IAAI;AAEG,IAAM,iBAAiB,CAAC,YAA+B;AAC5D,MAAI,QAAQ,eAAe,IAAI,YAAY,MAAM,OAAO;AAEtD,UAAMC,OAAM,IAAI,UAAU,cAAe,QAAgB,MAAM;AAG/D,YAAQ,aAAaA,MAAK,KAAK;AAC/B,sBAAkBA;EACpB;AAEA,QAAM,YAAY,QAAQ,YAAY,YAAY,QAAW,YAAY;AACzE,QAAM,MAAM;AAEZ,SAAO,EAAE,WAAW,IAAG;AACzB;;;ACXA,YAAY,qBAAqB;AAI1B,IAAM,eAAe,CAO1B,EACA,SACA,SAAQ,MAIgB;AACxB,QAAM,gBAAqC,CAAA;AAC3C,QAAM,EAAE,UAAS,IAAK;AAEtB,MAAI,WAAW;AAEf,QAAM,WAAgC;IACpC,MAAM;IACN;IACA,SAAS,CAAC,aAAY;AACpB,UAAI;AACF,cAAM,QAAQ,QAAQ,WAAW,WAAW,SAAS,KAAI,GAAI,EAAE,UAAU,KAAI,CAAE;AAE/E,YAAI,cAAc;AAElB,cAAM,eAAe;UACnB,SAAS,CAAC,YAAY,YAAW;AAC/B,uBAAW,QAAQ,OAAO;AACxB,kBAAI,eAAe,UAAa,OAAO,KAAK,UAAU,EAAE,SAAS,GAAG;AAClE,wBAAQ,gBAAgB,MAAM,UAAiB;cACjD;AAEA,kBAAI;AACF,wBAAQ,KAAK,IAAI;cACnB;AACE,oBAAI,mCAAS,eAAe;AAC1B,0BAAQ,cAAc,QAAQ,QAAQ,SAAS,CAAC;gBAClD;AAEA,wBAAQ,MAAM,IAAI;cACpB;YACF;UACF;UACA,QAAQ,CAAI,eAAkC;AAC5C,gBAAI,MAAM,WAAW,GAAG;AACtB,oBAAM,IAAI,YAAY;gBACpB,OAAO,EAAE,YAAY,KAAK,SAAQ;gBAClC,MAAM;gBACN,OAAO;eACR;YACH;AAEA,kBAAM,OAAO,MAAM,CAAC;AAEpB,gBAAI,eAAe,UAAa,OAAO,KAAK,UAAU,EAAE,SAAS,GAAG;AAClE,sBAAQ,gBAAgB,MAAM,UAAiB;YACjD;AAEA,kBAAM,UAAe,CAAA;AAErB,gBAAI;AAEF,kBAAI,UAAU;AACd,kBAAI;AACF,0BAAU,QAAQ,aAAa,IAAI;cAErC,SAAS,IAAI;cAAC;AAEd,qBAAO,QAAQ,KAAK,IAAI,MAAsB,4BAAY;AACxD,oBAAI,YAAY,QAAW;AACzB,wBAAM,MAA8B,CAAA;AACpC,2BAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,KAAK;AACvC,wBAAI,QAAQ,CAAC,CAAE,IAAI,QAAQ,OAAO,MAAM,CAAC;kBAC3C;AACA,0BAAQ,KAAK,GAAmB;gBAClC;cACF;YACF,SAAS,GAAG;AACV,oBAAM,IAAI,YAAY;gBACpB,OAAO,EAAE,YAAY,KAAK,SAAQ;gBAClC,MAAO,EAAU;gBACjB,OAAO;eACR;YACH;AAEE,sBAAQ,MAAM,IAAI;YACpB;AAEA,mBAAO;UACT;UACA,UAAU,MAAK;AAEb,gBAAI,aAAa;AACf;YACF;AAEA,0BAAc;AAEd,uBAAW,QAAQ,OAAO;AACxB,sBAAQ,SAAS,IAAI;YACvB;UACF;UACA,KAAK;;AAGP,sBAAc,KAAK,YAAY;AAE/B,eAAO;MACT,SAAS,GAAG;AACV,cAAM,IAAI,YAAY;UACpB,OAAO,EAAE,KAAK,UAAU,YAAY,CAAA,EAAE;UACtC,MAAO,EAAU;UACjB,OAAO;SACR;MACH;IACF;IACA,QAAQ,MAAM,QAAQ,UAAU,WAAW,MAAM;IACjD,SAAS,yBAAe,YAAY,CAAC,UAAU,YAAY,YAAW;AACpE,YAAM,OAAO,SAAS,QAAQ,QAAQ;AACtC,WAAK,QAAQ,YAAY,OAAO;AAChC,WAAK,SAAQ;IACf,CAAC;IACD,QAAQ,yBAAe,WAAW,CAAC,UAAU,eAAc;AACzD,YAAM,OAAO,SAAS,QAAQ,QAAQ;AACtC,YAAM,UAAU,KAAK,OAAO,UAAU;AACtC,WAAK,SAAQ;AACb,aAAO;IACT,CAAC;IACD,SAAS,MAAK;AACZ,eAAS,MAAK;AAEd,eAAS,SAAQ;IAInB;IACA,OAAO,MAAK;AACV,UAAI,UAAU;AACZ;MACF;AAEA,iBAAW,QAAQ,eAAe;AAChC,aAAK,SAAQ;MACf;AACA,cAAQ,MAAM,SAAS;AACvB,iBAAW;IACb;IACA,QAAQ,CAAC,WAAU;AAKjB,YAAM,gBAAgB;AACtB,YAAM,aAAa;AAMnB,UAAI,kBAAkB,YAAY;AAChC,cAAM,QAAQ,eAAe,OAAO;AAGpC,gBAAQ,YAAY,MAAM,WAAW,QAAQ,QAAQ,OAAO,QAAQ,OAAO,QAAQ,gBAAgB,UAAU;AAC7G,gBAAQ,OAAO,WAAW,QAAQ,MAAM,WAAW,MAAM;AACzD,gBAAQ,MAAM,MAAM,SAAS;MAC/B,OAAO;AACL,gBAAQ,OAAO,WAAW,QAAQ,OAAO,SAAS,WAAW,MAAM;MACrE;AAEA,eAAS,YAAY,QAAQ;IAC/B;IACA,SAAS,MAAK;AACZ,YAAM,iBAAiB,QAAQ,eAAe,WAAW,MAAM;AAC/D,cAAQ,eAAe,gBAAgB,IAAI;AAE3C,aAAO;QACL,WAAW,MAAK;AACd,gBAAM,MAAM,QAAQ,kBAAkB,cAAc;AACpD,iBAAO,IAAI,aAAa;QAC1B;QACA,QAAQ,MAAK;AACX,kBAAQ,eAAe,cAAc;QACvC;;IAEJ;IACA,eAAe,CAAC,SAAQ;AACtB,YAAM,YAAY;QAChB,QAAQ,MAAK;AACX,gBAAM,WAAW,QAAQ,iBAAiB,IAAI;AAC9C,iBAAO,SAAS,cAAc,QAAQ;QACxC;QACA,OAAO,MAAK;AACV,cAAI;AACF,oBAAQ,gBAAgB,WAAW,IAAI;AAGvC,mBAAO;UACT,SAAS,OAAY;AACnB,kBAAM,IAAI,YAAY;cACpB,MAAM,MAAM,QAAQ;cACpB;cACA,MAAM;aACP;UACH;QACF;;AAGF,aAAO;IACT;;AAGF,WAAS,YAAY,QAAQ;AAE7B,SAAO;AACT;;;ACnOA,YAAYC,UAAS;;;ACIrB,YAAY,SAAS;AAErB,IAAM,gBAAgB,OAAO,eAAe,YAAW;AAAE,CAAC,EAAE;AAT5D;AAWM,IAAO,YAAP,cAA6B,SAAI;;;;;EAKrC,YAAY,MAAM,QAAM;AACtB,UAAM,MAAM,MAAM;AANhB;EAOJ;;;;;;EAOA,eAAe,YAAU;AAGvB,UAAM,cAAc,IAAI,WAAW,MAAM,CAAC,CAAC;AAC3C,WAAO,KAAK,WAAW,aAAa;EACtC;;;;;;EAOA,YAAY,OAAK;AACf,UAAM,IAAI,MAAM,eAAe;EACjC;;;;;;;;EASA,MAAM,UAAU,OAAO,OAAO,WAAS;AACrC,WAAW;EACb;;;;;;EAOA,QAAQ,UAAU,SAAO;AACvB,WAAW;EACb;;;;;;;EAQA,QAAQ,UAAU,OAAO,SAAO;AAC9B,WAAW;EACb;;;;;;EAOA,cAAc,UAAU,MAAI;AAE1B,UAAM,EAAE,MAAM,QAAO,IAAK,IAAI,YAAW,EAAG,WAAW,UAAU,IAAI;AACrE,QAAI,OAAO,SAAS;AAAQ,aAAW;AACvC,QAAI,WAAW,KAAK;AAAQ,aAAW;AACvC,SAAK,OAAO,IAAI;AAChB,WAAW;EACb;;;;;EAMA,cAAc,MAAI;AAChB,WAAW;EACb;;;;;EAMA,OAAO,OAAK;AACV,WAAW;EACb;;;;;;;EAQA,MAAM,OAAO,OAAO,SAAO;AACzB,UAAM,KAAK,CAAC;AACZ,WAAW;EACb;;;;;;;EAQA,OAAO,OAAO,OAAO,SAAO;AAC1B,WAAW;EACb;;;;;;EAOA,UAAU,OAAO,MAAI;AACnB,WAAW;EACb;;;;;;EAOA,MAAM,OAAO,OAAK;AAChB,WAAW;EACb;;;;;;EAOA,UAAU,OAAO,OAAK;AACpB,WAAW;EACb;;;;;;EAOA,MAAM,OAAO,UAAQ;AACnB,WAAW;EACb;;;;;;EAOA,QAAQ,OAAO,UAAQ;AACrB,WAAW;EACb;;;;;;EAOA,mBAAmB,OAAO,SAAO;AAC/B,YAAQ,SAAS,GAAG,GAAG,IAAI;AAC3B,WAAW;EACb;;;;;;;EAQA,aAAa,OAAO,IAAI,MAAI;AAC1B,WAAW;EACb;;;;;EAMA,YAAY,OAAK;AACf,WAAO,MAAM,YAAY,KAAK;EAChC;;;;;EAMA,uBAAuB,OAAK;AAC1B,WAAO;EACT;;;;;;;;;EAUA,MAAM,MAAM,OAAO,OAAO,OAAO,WAAS;AAnN5C;AAoNI,UAAM,WAAW,sBAAK,yCAAL,WAAqB,OAAO;AAC7C,UAAM,gBAAgB,sBAAK,4CAAL,WAAwB,SAAS;AACvD,eAAK,WAAL,8BAAc,SAAS,UAAU,OAAO,OAAO,MAAM,SAAS,EAAE;AAChE,WAAO,KAAK,MAAM,UAAU,OAAO,OAAO,aAAa;EACzD;;;;;;;EAQA,QAAQ,MAAM,OAAO,SAAO;AAhO9B;AAiOI,UAAM,WAAW,KAAK,QAAQ,aAAa,KAAK;AAChD,eAAK,WAAL,8BAAc,WAAW,UAAU;AACnC,WAAO,KAAK,QAAQ,UAAU,OAAO;EACvC;;;;;;;;EASA,QAAQ,MAAM,OAAO,OAAO,SAAO;AA7OrC;AA8OI,UAAM,WAAW,KAAK,QAAQ,aAAa,KAAK;AAChD,UAAM,cAAc,sBAAK,4CAAL,WAAwB,SAAS;AACrD,eAAK,WAAL,8BAAc,WAAW,UAAU;AACnC,WAAO,KAAK,QAAQ,UAAU,OAAO,WAAW;EAClD;;;;;;;;EASA,cAAc,MAAM,OAAO,MAAM,MAAI;AA3PvC;AA4PI,UAAM,WAAW,KAAK,QAAQ,aAAa,KAAK;AAChD,UAAM,YAAY,KAAK,QAAQ,OAAO,SAAS,MAAM,OAAO,IAAI;AAChE,eAAK,WAAL,8BAAc,iBAAiB,UAAU;AACzC,WAAO,KAAK,cAAc,UAAU,SAAS;EAC/C;;;;;;;EAQA,cAAc,MAAM,MAAM,MAAI;AAxQhC;AAyQI,UAAM,YAAY,KAAK,QAAQ,OAAO,SAAS,MAAM,OAAO,IAAI;AAChE,eAAK,WAAL,8BAAc,iBAAiB;AAC/B,WAAO,KAAK,cAAc,SAAS;EACrC;;;;;EAMA,OAAO,OAAK;AAlRd;AAmRI,eAAK,WAAL,8BAAc,UAAU;AACxB,WAAO,KAAK,OAAO,KAAK;EAC1B;;;;;;;;;EAUA,MAAM,OAAO,OAAO,MAAM,WAAW,WAAS;AA/RhD;AAgSI,UAAM,aAAa,sBAAK,wCAAL,WAAoB,OAAO;AAC9C,UAAM,UAAU,WAAW,WAAW,SAAS;AAC/C,eAAK,WAAL,8BAAc,SAAS,OAAO,MAAM;AACpC,WAAO,KAAK,MAAM,OAAO,YAAY,OAAO;EAC9C;;;;;;;;;EAUA,OAAO,OAAO,OAAO,MAAM,WAAW,WAAS;AA9SjD;AA+SI,UAAM,aAAa,sBAAK,wCAAL,WAAoB,OAAO;AAC9C,UAAM,UAAU,WAAW,WAAW,SAAS;AAC/C,eAAK,WAAL,8BAAc,UAAU,OAAO,YAAY;AAC3C,WAAO,KAAK,OAAO,OAAO,YAAY,OAAO;EAC/C;;;;;;;EAQA,UAAU,OAAO,QAAQ,QAAM;AA3TjC;AA4TI,UAAM,OAAO,WAAW,QAAQ,MAAM;AACtC,eAAK,WAAL,8BAAc,aAAa,OAAO;AAClC,WAAO,KAAK,UAAU,OAAO,IAAI;EACnC;;;;;;EAOA,MAAM,OAAO,OAAK;AAtUpB;AAuUI,eAAK,WAAL,8BAAc,SAAS,OAAO;AAC9B,WAAO,KAAK,MAAM,OAAO,KAAK;EAChC;;;;;;;EAQA,UAAU,OAAO,OAAK;AAjVxB;AAkVI,UAAM,YAAY,sBAAK,4CAAL,WAAwB,YAAY;AACtD,eAAK,WAAL,8BAAc,aAAa;AAC3B,WAAO,KAAK,UAAU,OAAO,SAAS;EACxC;;;;;;EAOA,MAAM,OAAO,UAAQ;AA5VvB;AA6VI,eAAK,WAAL,8BAAc,SAAS,OAAO;AAC9B,WAAO,KAAK,MAAM,OAAO,QAAQ;EACnC;;;;;;EAOA,QAAQ,OAAO,UAAQ;AAtWzB;AAuWI,eAAK,WAAL,8BAAc,WAAW,OAAO;AAChC,WAAO,KAAK,QAAQ,OAAO,QAAQ;EACrC;;;;;;EAOA,mBAAmB,OAAO,SAAO;AAhXnC;AAiXI,UAAM,cAAc,sBAAK,4CAAL,WAAwB,SAAS;AACrD,eAAK,WAAL,8BAAc,sBAAsB;AACpC,WAAO,KAAK,mBAAmB,OAAO,WAAW;EACnD;;;;;;;EAQA,aAAa,OAAO,IAAI,MAAI;AA5X9B;AA6XI,UAAM,WAAW,IAAI,SAAS,KAAK,QAAQ,OAAO,QAAQ,KAAK,QAAQ,OAAO,aAAa,IAAI;AAC/F,eAAK,WAAL,8BAAc,gBAAgB,OAAO,IAAI;AACzC,WAAO,KAAK,aAAa,OAAO,IAAI,QAAQ;EAC9C;;;;;EAMA,YAAY,OAAK;AAtYnB;AAuYI,eAAK,WAAL,8BAAc,eAAe;AAC7B,WAAO,KAAK,YAAY,KAAK;EAC/B;;;;;EAMA,uBAAuB,OAAK;AA/Y9B;AAgZI,eAAK,WAAL,8BAAc,0BAA0B;AACxC,WAAO,KAAK,uBAAuB,KAAK;EAC1C;;AAvYI;;;;;;;;;AAiZJ,uBAAkB,SAAC,MAAM,YAAU;AACjC,QAAM,aAAa,SAAS,UAAU,IAAI;AAC1C,QAAM,SAAS,MAAM,IAAI;AACzB,QAAM,SAAS,MAAM,IAAI;AACzB,QAAM,eAAe,MACnB,IAAI,SAAS,KAAK,QAAQ,OAAO,QAAQ,KAAK,QAAQ,OAAO,aAAa,YAAY,UAAU;AAClG,MAAI,WAAW,aAAY;AAC3B,SAAO,IAAI,MAAM,UAAU;IACzB,IAAI,GAAG,MAAI;AACT,UAAI,SAAS,OAAO,eAAe,GAAG;AAEpC,mBAAW,aAAY;MACzB;AACA,UAAI,SAAS,QAAQ;AACnB,eAAO,SAAUC,aAAY,cAAY;AACvC,cAAI,CAAC;AAAc,kBAAM,IAAI,MAAM,uBAAuB;AAC1D,iBAAO,SAAS,IAAI,EAAEA,aAAY,YAAY;QAChD;MACF;AACA,UAAI,SAAS,QAAQ;AACnB,eAAO,SAAUA,aAAY,OAAO,cAAY;AAC9C,cAAI,CAAC;AAAc,kBAAM,IAAI,MAAM,uBAAuB;AAC1D,iBAAO,SAAS,IAAI,EAAEA,aAAY,OAAO,YAAY;QACvD;MACF;AACA,UAAI,OAAO,SAAS,YAAY,eAAe,KAAK,IAAI,GAAG;AACzD,cAAM,IAAI,MAAM,cAAc;MAChC;AACA,YAAM,SAAS,SAAS,IAAI;AAC5B,aAAO,OAAO,WAAW,aAAa,OAAO,KAAK,QAAQ,IAAI;IAChE;GACD;AACH;;;;;AAMA,mBAAc,SAAC,YAAY,YAAU;AACnC,MAAI,SAAS,KAAK,QAAQ,OAAO,SAAS,YAAY,aAAa,UAAU;AAC7E,SAAO,IAAI,MAAM,QAAQ;IACvB,KAAK,CAAC,GAAG,MAAM,aAAY;AACzB,UAAI,OAAO,OAAO,eAAe,GAAG;AAElC,iBAAS,KAAK,QAAQ,OAAO,SAAS,YAAY,aAAa,UAAU;MAC3E;AACA,YAAM,SAAS,OAAO,IAAI;AAC1B,aAAO,OAAO,WAAW,aAAa,OAAO,KAAK,MAAM,IAAI;IAC9D;GACD;AACH;AAEA,oBAAe,SAAC,OAAO,OAAK;AAC1B,MAAI,QAAY,qBAAiB;AAI/B,QAAI,QAAQ;AACZ,QAAI,QAAQ;AACZ,UAAM,YAAY,CAAA;AAClB,WAAO,OAAO;AACZ,YAAM,WAAW,KAAK,QAAQ,OAAO,OAAO;AAC5C,UAAI,UAAU;AACZ,kBAAU,KAAK,QAAQ;MACzB,OAAO;AACL,YAAI,CAAC,KAAK,QAAQ,OAAO,KAAK;AAAG,kBAAQ;AACzC,gBAAQ,OAAO;UACb,KAAK,GAAG;AAEN,sBAAU,KAAK,IAAI,WAAW,CAAC,CAAC;AAChC,oBAAQ;AACR;UACF;UACA,KAAK,GAAG;AAEN,sBAAU,KAAK,IAAI,WAAW,CAAC,CAAC;AAChC,oBAAQ;AACR;UACF;UACA,KAAK,GAAG;AAEN,sBAAU,KAAK,IAAI,WAAW,CAAC,CAAC;AAChC,oBAAQ;AACR;UACF;QACF;MACF;IACF;AACA,WAAO,IAAI,YAAW,EAAG,OAAO,IAAI,WAAW,SAAS,CAAC;EAC3D;AACA,SAAO,QAAQ,KAAK,QAAQ,aAAa,KAAK,IAAI;AACpD;AAIF,SAAS,WAAW,MAAM,MAAI;AAC5B,SAAO,OAAO,aAAkB,QAAQ,OAAO,IAAI,KAAK,KAAK;AAC/D;;;ADtfA,IAAM,cAAc;AAIpB,IAAM,uBAAuB;AAC7B,IAAM,oBAAoB;AAC1B,IAAM,qBAAqB;AAC3B,IAAM,qBAAqB,uBAAuB;AAClD,IAAM,sBAAsB;AAC5B,IAAM,uBAAuB;AAC7B,IAAM,qBAAqB;AAI3B,IAAM,wBACA,2BAA0B,gCAA+B,iCAAgC;AAE/F,IAAM,mBAAmB;AAxBzB;AAgCM,IAAO,uBAAP,MAAO,6BAA4B,UAAS;EA2BhD,YAAY,MAAc,eAAuB,QAAW;AAC1D,UAAM,MAAM,MAAM;AA5BhB;AACJ,+BAAM;AAIN;;;;AACA;AAKA;;;+CAAyB,oBAAI,IAAG;AAKhC;;;+CAAyB,oBAAI,IAAG;AAChC,gDAA0B,oBAAI,IAAG;AAEjC,qCAAe,oBAAI,IAAG;AAUpB,uBAAK,gBAAiB;EACxB;EATA,aAAa,OAAO,MAAc,eAAuB,QAAW;AAClE,UAAM,MAAM,IAAI,qBAAoB,MAAM,eAAe,MAAM;AAC/D,UAAM,IAAI,QAAO;AACjB,WAAO;EACT;EAOA,gBAAgB,OAAa;AAC3B,UAAM,OAAO,sBAAK,4CAAL,WAAc;AAC3B,UAAM,eAAe,mBAAK,wBAAuB,IAAI,IAAI;AACzD,WAAO,mBAAK,wBAAuB,IAAI,YAAY;EACrD;EAEA,kBAAkB,OAAa;AAC7B,UAAM,OAAO,sBAAK,4CAAL,WAAc;AAC3B,UAAM,eAAe,mBAAK,wBAAuB,IAAI,IAAI;AACzD,iBAAa,SAAS,kBAAkB;EAG1C;EAEA,MAAM,OAAe,QAAgB,OAAe,WAAmB;AACrE,QAAI;AAEF,YAAM,OAAO,QAAQ,sBAAK,4CAAL,WAAc,SAAS,KAAK,OAAM,EAAG,SAAS,EAAE;AACrE,UAAI,eAAe,mBAAK,wBAAuB,IAAI,IAAI;AACvD,UAAI,CAAC,gBAAgB,QAAY,yBAAoB;AAEnD,YAAI,KAAK,QAAO,IAAK,KAAK,YAAW,GAAI;AAEvC;AAAC,WAAC,YAAY,IAAI,mBAAK,yBAAwB,KAAI;AACnD,gCAAK,sDAAL,WAAwB,cAAe,MAAM;QAC/C,OAAO;AAGL,gBAAM,IAAI,MAAM,oBAAoB;QACtC;MACF;AACA,UAAI,CAAC,cAAc;AACjB,cAAM,IAAI,MAAM,gBAAgB;MAClC;AAGA,YAAM,OAAO,EAAE,MAAM,OAAO,aAAY;AACxC,yBAAK,cAAa,IAAI,QAAQ,IAAI;AAElC,gBAAU,SAAS,GAAG,OAAO,IAAI;AACjC,aAAW;IACb,SAAS,GAAQ;AACf,cAAQ,MAAM,EAAE,OAAO;AACvB,aAAW;IACb;EACF;EAEA,OAAO,QAAc;AACnB,UAAM,OAAO,mBAAK,cAAa,IAAI,MAAM;AACzC,QAAI,MAAM;AACR,WAAK,aAAa,MAAK;AACvB,yBAAK,cAAa,OAAO,MAAM;AAC/B,UAAI,KAAK,QAAY,gCAA2B;AAC9C,8BAAK,+CAAL,WAAiB,KAAK;MACxB;IACF;AACA,WAAW;EACb;EAEA,MAAM,QAAgB,OAAmB,SAAe;AACtD,UAAM,OAAO,mBAAK,cAAa,IAAI,MAAM;AACzC,UAAM,SAAS,KAAK,aAAa,KAAK,MAAM,SAAQ,GAAI,EAAE,IAAI,qBAAqB,QAAO,CAAE;AAC5F,QAAI,SAAS,MAAM,YAAY;AAC7B,YAAM,KAAK,GAAG,QAAQ,MAAM,UAAU;AACtC,aAAW;IACb;AACA,WAAW;EACb;EAEA,OAAO,QAAgB,OAAmB,SAAe;AACvD,UAAM,OAAO,mBAAK,cAAa,IAAI,MAAM;AACzC,UAAM,SAAS,KAAK,aAAa,MAAM,MAAM,SAAQ,GAAI,EAAE,IAAI,qBAAqB,QAAO,CAAE;AAC7F,WAAO,WAAW,MAAM,aAAiB,iBAAgB;EAC3D;EAEA,UAAU,QAAgB,OAAa;AACrC,UAAM,OAAO,mBAAK,cAAa,IAAI,MAAM;AACzC,SAAK,aAAa,SAAS,qBAAqB,KAAK;AACrD,WAAW;EACb;EAEA,MAAM,QAAgB,QAAc;AAClC,UAAM,OAAO,mBAAK,cAAa,IAAI,MAAM;AACzC,SAAK,aAAa,MAAK;AACvB,WAAW;EACb;EAEA,UAAU,QAAgB,SAAiB;AACzC,UAAM,OAAO,mBAAK,cAAa,IAAI,MAAM;AACzC,UAAM,OAAO,KAAK,aAAa,QAAO,IAAK;AAC3C,YAAQ,YAAY,GAAG,OAAO,IAAI,GAAG,IAAI;AACzC,WAAW;EACb;EAEA,YAAY,SAAe;AACzB,WAAO;EACT;EAEA,uBAAuB,SAAe;AACpC,WAAW;EACb;EAEA,QAAQ,OAAe,OAAe,SAAiB;AACrD,UAAM,OAAO,sBAAK,4CAAL,WAAc;AAC3B,YAAQ,SAAS,GAAG,mBAAK,wBAAuB,IAAI,IAAI,IAAI,IAAI,GAAG,IAAI;AACvE,WAAW;EACb;EAEA,QAAQ,OAAe,UAAgB;AACrC,UAAM,OAAO,sBAAK,4CAAL,WAAc;AAC3B,0BAAK,+CAAL,WAAiB;AACjB,WAAW;EACb;EAEA,MAAM,QAAK;AACT,0BAAK,yDAAL;EACF;EAEA,MAAM,UAAO;AACX,QAAI,CAAC,mBAAK,mBAAkB;AAE1B,UAAI,SAAS,MAAM,UAAU,QAAQ,aAAY;AACjD,iBAAW,KAAK,mBAAK,gBAAe,MAAM,GAAG,GAAG;AAC9C,YAAI,GAAG;AACL,mBAAS,MAAM,OAAO,mBAAmB,GAAG,EAAE,QAAQ,KAAI,CAAE;QAC9D;MACF;AACA,yBAAK,kBAAmB;AAExB,YAAM,sBAAK,yDAAL;AACN,UAAI,KAAK,YAAW,MAAO,GAAG;AAC5B,cAAM,KAAK,YAAY,gBAAgB;MACzC;IACF;AACA,WAAO;EACT;;;;EAKA,UAAO;AACL,WAAO,mBAAK,wBAAuB;EACrC;;;;EAKA,cAAW;AACT,WAAO,mBAAK,wBAAuB;EACrC;;;;EAKA,MAAM,YAAY,GAAS;AACzB,aAAS,IAAI,GAAG,IAAI,GAAG,EAAE,GAAG;AAC1B,YAAM,OAAO,KAAK,OAAM,EAAG,SAAS,EAAE,EAAE,QAAQ,MAAM,EAAE;AACxD,YAAM,SAAS,MAAM,mBAAK,kBAAkB,cAAc,MAAM,EAAE,QAAQ,KAAI,CAAE;AAChF,YAAM,eAAe,MAAM,OAAO,uBAAsB;AACxD,yBAAK,wBAAuB,IAAI,cAAc,IAAI;AAElD,4BAAK,sDAAL,WAAwB,cAAc,IAAI;IAC5C;AACA,WAAO;EACT;;;;;;EAOA,MAAM,eAAe,GAAS;AAC5B,QAAI,WAAW;AACf,eAAW,gBAAgB,MAAM,KAAK,mBAAK,wBAAuB,GAAG;AACnE,UAAI,YAAY,KAAK,KAAK,QAAO,MAAO,KAAK,YAAW;AAAI,eAAO;AAEnE,YAAM,OAAO,mBAAK,wBAAuB,IAAI,YAAY;AACzD,mBAAa,MAAK;AAClB,YAAM,mBAAK,kBAAkB,YAAY,IAAI;AAC7C,yBAAK,wBAAuB,OAAO,YAAY;AAC/C,yBAAK,yBAAwB,OAAO,YAAY;AAChD,QAAE;IACJ;AACA,WAAO;EACT;;AAnNA;AACA;AAKA;AAKA;AACA;AAEA;AAnBI;AA0NE,0BAAqB,iBAAA;AAEzB,QAAM,QAAQ,CAAA;AACd,mBAAiB,CAAC,MAAM,MAAM,KAAK,mBAAK,mBAAmB;AACzD,QAAI,OAAO,SAAS,QAAQ;AAC1B,YAAM,KAAK,CAAC,MAAM,MAAM,CAAC;IAC3B;EACF;AAGA,QAAM,QAAQ,IACZ,MAAM,IAAI,OAAO,CAAC,MAAM,MAAM,MAAK;AACjC,UAAM,eAAe,MAAM,OAAO,uBAAsB;AACxD,uBAAK,wBAAuB,IAAI,cAAc,IAAI;AAClD,UAAM,OAAO,sBAAK,sDAAL,WAAwB;AACrC,QAAI,MAAM;AACR,yBAAK,wBAAuB,IAAI,MAAM,YAAY;IACpD,OAAO;AACL,yBAAK,yBAAwB,IAAI,YAAY;IAC/C;EACF,CAAC,CAAC;AAEN;AAEA,0BAAqB,WAAA;AACnB,aAAW,gBAAgB,mBAAK,wBAAuB,KAAI,GAAI;AAC7D,iBAAa,MAAK;EACpB;AACA,qBAAK,wBAAuB,MAAK;AACjC,qBAAK,wBAAuB,MAAK;AACjC,qBAAK,yBAAwB,MAAK;AACpC;;;;;;AAOA,uBAAkB,SAAC,cAAwC;AAEzD,QAAM,SAAS,IAAI,WAAW,kBAAkB;AAChD,eAAa,KAAK,QAAQ,EAAE,IAAI,EAAC,CAAE;AAGnC,QAAM,WAAW,IAAI,SAAS,OAAO,QAAQ,OAAO,UAAU;AAC9D,QAAM,QAAQ,SAAS,UAAU,mBAAmB;AACpD,MAAI,OAAO,CAAC,MAAM,QAAY,mCAA8B,QAAQ,2BAA2B,IAAI;AACjG,YAAQ,KAAK,qCAAqC,MAAM,SAAS,EAAE,CAAC,EAAE;AACtE,0BAAK,sDAAL,WAAwB,cAAc,IAAI;AAC1C,WAAO;EACT;AAEA,QAAM,aAAa,IAAI,YAAY,qBAAqB,CAAC;AACzD,eAAa,KAAK,YAAY,EAAE,IAAI,qBAAoB,CAAE;AAG1D,QAAM,iBAAiB,sBAAK,kDAAL,WAAoB;AAC3C,MAAI,WAAW,MAAM,CAAC,OAAO,MAAM,UAAU,eAAe,CAAC,CAAC,GAAG;AAE/D,UAAM,YAAY,OAAO,QAAQ,CAAC;AAClC,QAAI,cAAc,GAAG;AAKnB,mBAAa,SAAS,kBAAkB;IAC1C;AACA,WAAO,IAAI,YAAW,EAAG,OAAO,OAAO,SAAS,GAAG,SAAS,CAAC;EAC/D,OAAO;AAEL,YAAQ,KAAK,sCAAsC;AACnD,0BAAK,sDAAL,WAAwB,cAAc,IAAI;AAC1C,WAAO;EACT;AACF;;;;AAKA,uBAAkB,SAAC,cAA0C,MAAc,OAAa;AAEtF,QAAM,SAAS,IAAI,WAAW,kBAAkB;AAChD,QAAM,gBAAgB,IAAI,YAAW,EAAG,WAAW,MAAM,MAAM;AAC/D,MAAI,cAAc,WAAW,sBAAsB;AACjD,UAAM,IAAI,MAAM,eAAe;EACjC;AAGA,QAAM,WAAW,IAAI,SAAS,OAAO,QAAQ,OAAO,UAAU;AAC9D,WAAS,UAAU,qBAAqB,KAAK;AAG7C,QAAM,SAAS,sBAAK,kDAAL,WAAoB;AACnC,eAAa,MAAM,QAAQ,EAAE,IAAI,EAAC,CAAE;AACpC,eAAa,MAAM,QAAQ,EAAE,IAAI,qBAAoB,CAAE;AACvD,eAAa,MAAK;AAElB,MAAI,MAAM;AACR,uBAAK,wBAAuB,IAAI,MAAM,YAAY;AAClD,uBAAK,yBAAwB,OAAO,YAAY;EAClD,OAAO;AAGL,iBAAa,SAAS,kBAAkB;AACxC,uBAAK,yBAAwB,IAAI,YAAY;EAC/C;AACF;;;;;;AAOA,mBAAc,SAAC,QAAkB;AAC/B,MAAI,CAAC,OAAO,CAAC,GAAG;AAEd,WAAO,IAAI,YAAY,CAAC,YAAe,UAAa,CAAC;EACvD;AAEA,MAAI,KAAK;AACT,MAAI,KAAK;AAET,aAAW,SAAS,QAAQ;AAC1B,SAAK,KAAK,KAAK,KAAK,OAAO,UAAa;AACxC,SAAK,KAAK,KAAK,KAAK,OAAO,UAAa;EAC1C;AAEA,OAAK,KAAK,KAAK,KAAM,OAAO,IAAK,UAAa,IAAI,KAAK,KAAK,KAAM,OAAO,IAAK,UAAa;AAC3F,OAAK,KAAK,KAAK,KAAM,OAAO,IAAK,UAAa,IAAI,KAAK,KAAK,KAAM,OAAO,IAAK,UAAa;AAE3F,SAAO,IAAI,YAAY,CAAC,OAAO,GAAG,OAAO,CAAC,CAAC;AAC7C;;;;AAKA,aAAQ,SAAC,WAAuB;AAC9B,QAAM,MAAM,OAAO,cAAc,WAAW,IAAI,IAAI,WAAW,mBAAmB,IAAI;AACtF,SAAO,IAAI;AACb;;;;;AAMA,gBAAW,SAAC,MAAY;AACtB,QAAM,eAAe,mBAAK,wBAAuB,IAAI,IAAI;AACzD,MAAI,cAAc;AAEhB,uBAAK,wBAAuB,OAAO,IAAI;AACvC,0BAAK,sDAAL,WAAwB,cAAc,IAAI;EAC5C;AACF;AAlXI,IAAO,sBAAP;;;AE3BN,IAAM,YAAY,eAAO,cAAc,CAAC,EAAE,KAAK,eAAO,OAAO;AAC7D,IAAM,aAAa,oBAAI,IAAG;AAEnB,IAAM,aAAa,CAAC,EACzB,SACA,WACA,SAAQ,MAMR,eAAO,IAAI,aAAS;AAElB,QAAM,WAAW,UAAU,WAAW,iBAAiB,GAAG;AAC1D,QAAM,cAAc,SAAS,WAAW,IAAI,KAAK,IAAI,QAAQ;AAC7D,QAAM,UAAU,OAAO,WAAW;AAElC,MAAI,QAAQ,eAAe,IAAI,OAAO,MAAM,OAAO;AACjD,UAAMC,OAAM,OAAO,eAAO,QAAQ,MAAM,oBAAoB,OAAO,SAAS,WAAY,QAAgB,MAAM,CAAC;AAE/G,YAAQ,aAAaA,MAAK,KAAK;AAC/B,eAAW,IAAI,SAASA,IAAG;EAC7B;AAEA,QAAM,YAAY,QAAQ,YAAY,UAAU,QAAW,OAAO;AAClE,QAAM,MAAM,WAAW,IAAI,OAAO;AAElC,SAAO,EAAE,WAAW,IAAG;AACzB,CAAC,EAAE,KAAK,UAAU,YAAY,CAAC,CAAC;;;AClClC,YAAYC,UAAS;AAErB,IAAMC,eAAc;AACpB,IAAMC,wBAAuB;AAC7B,IAAMC,qBAAoB;AAC1B,IAAMC,sBAAqB;AAC3B,IAAMC,sBAAqBH,wBAAuBC;AAClD,IAAMG,uBAAsBJ;AAC5B,IAAMK,wBAAuBF;AACtB,IAAMG,sBAAqBP;AAElC,IAAMQ,yBACA,2BAA0B,gCAA+B,iCAAgC;AAE/F,IAAM,cAAc,IAAI,YAAW;AAE5B,IAAM,wBAAwB,OAAO,SAA+B;AAEzE,QAAM,SAAS,IAAI,WAAW,MAAM,KAAK,MAAM,GAAGJ,mBAAkB,EAAE,YAAW,CAAE;AAGnF,QAAM,WAAW,IAAI,SAAS,OAAO,QAAQ,OAAO,UAAU;AAC9D,QAAM,QAAQ,SAAS,UAAUC,oBAAmB;AACpD,MAAI,OAAO,CAAC,MAAM,QAAY,mCAA8B,QAAQG,4BAA2B,IAAI;AACjG,YAAQ,KAAK,qCAAqC,MAAM,SAAS,EAAE,CAAC,EAAE;AACtE,WAAO;EACT;AAEA,QAAM,aAAa,IAAI,YACrB,MAAM,KAAK,MAAMF,uBAAsBA,wBAAuBH,mBAAkB,EAAE,YAAW,CAAE;AAIjG,QAAM,iBAAiB,cAAc,MAAM;AAC3C,MAAI,WAAW,MAAM,CAAC,OAAO,MAAM,UAAU,eAAe,CAAC,CAAC,GAAG;AAE/D,UAAM,YAAY,OAAO,QAAQ,CAAC;AAClC,QAAI,cAAc,GAAG;IAGrB;AACA,WAAO,YAAY,OAAO,OAAO,SAAS,GAAG,SAAS,CAAC;EACzD,OAAO;AAEL,YAAQ,KAAK,sCAAsC;AACnD,WAAO;EACT;AACF;AAEA,IAAM,gBAAgB,CAAC,WAAmC;AACxD,MAAI,CAAC,OAAO,CAAC,GAAG;AAEd,WAAO,IAAI,YAAY,CAAC,YAAe,UAAa,CAAC;EACvD;AAEA,MAAI,KAAK;AACT,MAAI,KAAK;AAET,aAAW,SAAS,QAAQ;AAC1B,SAAK,KAAK,KAAK,KAAK,OAAO,UAAa;AACxC,SAAK,KAAK,KAAK,KAAK,OAAO,UAAa;EAC1C;AAEA,OAAK,KAAK,KAAK,KAAM,OAAO,IAAK,UAAa,IAAI,KAAK,KAAK,KAAM,OAAO,IAAK,UAAa;AAC3F,OAAK,KAAK,KAAK,KAAM,OAAO,IAAK,UAAa,IAAI,KAAK,KAAK,KAAM,OAAO,IAAK,UAAa;AAE3F,SAAO,IAAI,YAAY,CAAC,OAAO,GAAG,OAAO,CAAC,CAAC;AAC7C;;;ACXO,IAAM,kBACX,CAAC,EAAE,QAAO,MACV,CAAC,UACC,eAAO,IAAI,aAAS;AAClB,MAAI,MAAM,SAAS,aAAa;AAC9B,UAAM,EAAE,WAAAM,YAAW,KAAAC,KAAG,IAAK,eAAe,OAAO;AACjD,WAAO,aAA0C;MAC/C;MACA,UAAU;QACR,MAAM;QACN,KAAAA;QACA,WAAAD;QACA,UAAU,MAAK;QAAE;QACjB,aAAa,MAAM,gBAAgB,MAAK;QAAE;QAC1C,iBAAiB;UACf,UAAU;;;KAGf;EACH;AAGA,QAAM,yBAAyB;AAE/B,MAAI,aAAa,MAAM;AAEvB,MAAI,MAAM,SAAS,SAAS,wBAAwB;AAClD,WAAO,eAAO,WACZ,yBAAyB,MAAM,QAAQ,UAAU,sBAAsB,eAAe,MAAM,SAAS,MAAM,cAAc;AAE3H,iBAAa,QAAQ,aAAK,OAAO,MAAM,QAAQ,CAAC;EAClD;AAEA,QAAM,EAAE,WAAW,IAAG,IAAK,OAAO,WAAW;IAC3C;IACA,WAAW,MAAM;IACjB,UAAU;GACX;AAED,SAAO,aAAsC;IAC3C;IACA,UAAU;MACR,MAAM;MACN;MACA;MACA,UAAU,MAAM,IAAI,kBAAkB,MAAM,QAAQ;MACpD,aAAa,MAAM,gBAAgB,MAAK;MAAE;MAC1C,iBAAiB;QACf,UAAU;QACV,eAAe,MAAM;QACrB,cAAc,IAAI,gBAAgB,UAAU;;;GAGjD;AACH,CAAC;;;AC9GL,YAAY,cAAc;AAC1B,OAAO,qBAAqB;AAErB,IAAM,kBAAkB,YAAW;AACxC,QAAM,SAAS,MAAM,gBAAe;AAGpC,QAAM,UAAmB,iBAAQ,MAAM;AAEvC,UAAQ,SAAS;AACjB,SAAO;AACT;;;ACXA;;;;;;;AAKO,IAAM,oBACX,OAAO,cAAc,eAAe,UAAU,YAAY;;EAErD,IAAI,MACH,CAAA,GACA;IACE,KAAK,MACH,QAAQ,OACN,IAAI,MAAM,kFAAkF,CAAC;GAElG;IAEH,UAAU,QAAQ,aAAY;AAE7B,IAAM,eAAe,OAAO,eAAkC;AACnE,QAAM,aAAa,MAAM;AACzB,MAAI,eAAe;AAAW,WAAO;AAErC,MAAI,YAAY;AAChB,QAAM,iBAAiB,yCAAY,MAAM,KAAK,OAAO;AACrD,SAAO,eAAe,SAAS,GAAG;AAChC,gBAAY,MAAM,UAAU,mBAAmB,eAAe,MAAK,CAAG;EACxE;AAEA,SAAO;AACT;AAEO,IAAM,YAAY,OACvB,mBAAmF,mBACnF,QAAgB,OAAO,mBACvB,SAAiB,OACA;AACjB,MAAI,QAAQ;AAAG;AAEf,QAAM,kBAAkB,MAAM;AAC9B,QAAM,UAAU,gBAAgB,OAAM;AAEtC,mBAAiB,SAAS,SAAS;AACjC,UAAM,cAAc,MAAM,SAAS;AACnC,UAAM,OAAO,MAAM,SAAS,SAAS,MAAM,MAAM,QAAO,EAAG,KAAK,CAAC,SAAS,YAAY,KAAK,IAAI,CAAC,IAAI;AACpG,YAAQ,IAAI,GAAG,MAAM,GAAG,cAAc,OAAO,IAAI,IAAI,MAAM,IAAI,IAAI,OAAO,IAAI,IAAI,MAAM,EAAE,EAAE;AAE5F,QAAI,aAAa;AACf,YAAM,wBAAwB,MAAM,gBAAgB,mBAAmB,MAAM,IAAI;AACjF,YAAM,UAAU,uBAAuB,QAAQ,GAAG,GAAG,MAAM,IAAI;IACjE;EACF;AACF;AAEO,IAAM,YAAY,OAAO,oBAA8C;AAC5E,MAAI,gBAAgB,SAAS;AAAa;AAE1C,mBAAiB,aAAa,gBAAgB,KAAI,GAAI;AACpD,UAAM,gBAAgB,YAAY,WAAW,EAAE,WAAW,KAAI,CAAE;EAClE;AACF;;;ACpDM,IAAO,uBAAP,cAAoC,eAAO,YAAW,EAAyB,wBAAwB;EAC3G,OAAO,eAAO;CACf,EAAC;;AAEK,IAAM,sCAAsC,CAAC,EAClD,gBACA,SACA,OAAM,MAMN,eAAO,QAAQ,YAAW;AACxB,QAAM,YAAY,gBAAgB,eAAe,WAAW,OAAO;AACnE,QAAM,mBAAmB,MAAgB,aAAa,SAAS,EAAE,MAAM,MAAM,MAAS;AAEtF,MAAI,qBAAqB,QAAW;AAClC,WAAO;EACT;AAEA,QAAM,eAAe,OAAO,eAAoC;AAC9D,UAAM,OAAO,MAAM,WAAW,QAAO;AACrC,UAAM,WAAW,MAAM,sBAAsB,IAAI;AACjD,WAAO,WAAW,EAAE,UAAU,KAAI,IAAK;EACzC;AAEA,QAAM,cAAc,OAAO,kBAAmF;AAC5G,UAAM,UAAkC,CAAA;AACxC,qBAAiB,SAAS,eAAe;AACvC,UAAI,MAAM,SAAS,QAAQ;AACzB,gBAAQ,KAAK,KAA6B;MAC5C;IACF;AACA,WAAO;EACT;AAEA,QAAM,QAAQ,MAAM,YAAY,iBAAiB,OAAM,CAAE;AAEzD,QAAM,cAAc,MAAM,QAAQ,IAAI,MAAM,IAAI,YAAY,CAAC;AAE7D,QAAM,gBAAgB,MAAM,mBAAmB,MAAM;AAErD,QAAM,YAAY,YAAY,KAAK,CAAC,OAAM,uBAAG,cAAa,aAAa;AAGvE,MAAI,cAAc,QAAW;AAC3B,UAAM,OAAO,MAAM,UAAU,KAAK,MAAME,mBAAkB,EAAE,YAAW;AAKvE,QAAI,KAAK,eAAe,GAAG;AACzB,aAAO;IACT;AAEA,WAAO,IAAI,WAAW,IAAI;EAC5B;AAEA,SAAO;AACT,CAAC,EAAE,KACD,eAAO,yBAAyB;EAC9B,UAAU;EACV,OAAO;CACR,GACD,eAAO,uBAAuB,4DAA4D,GAC1F,eAAO,SAAS,4DAA4D,CAAC;AAG1E,IAAM,sCAAsC,CAAC,EAClD,gBACA,QAAO,MAKP,eAAO,IAAI,aAAS;AAClB,QAAM,YAAY,gBAAgB,eAAe,WAAW,OAAO;AACnE,SAAO,cAAc,SAAS;AAChC,CAAC,EAAE,KACD,eAAO,MAAM;EACX,UAAU,iBAAS;CACpB,GACD,eAAO,SAAS,4DAA4D,CAAC;AAGjF,IAAM,gBAAgB,CAAC,YACrB,eAAO,QAAQ,YAAW;AAExB,QAAM,OAAO,MAAgB;AAG7B,QAAM,YAAY,QAAQ,MAAM,GAAG,EAAE,OAAO,CAAC,SAAS,KAAK,MAAM;AAEjE,MAAI;AAEF,QAAI,aAAa;AACjB,aAAS,IAAI,GAAG,IAAI,UAAU,SAAS,GAAG,KAAK;AAC7C,mBAAa,MAAM,WAAW,mBAAmB,UAAU,CAAC,CAAE;IAChE;AAGA,UAAM,WAAW,YAAY,UAAU,GAAG,EAAE,GAAI,EAAE,WAAW,KAAI,CAAE;EACrE,SAAS,OAAO;AACd,QAAI,iBAAiB,gBAAgB,MAAM,SAAS,iBAAiB;AAEnE;IACF,OAAO;AACL,YAAM;IACR;EACF;AACF,CAAC,EAAE,KACD,gBAAgB,sBAChB,eAAO,SAAS,gDAAgD,EAAE,YAAY,EAAE,aAAa,QAAO,EAAE,CAAE,CAAC;AAGtG,IAAM,kBAAkB,CAAC,WAA+B,YAAmB;AAEhF,MAAI,cAAc,UAAa,cAAc,MAAM,cAAc;AAC/D,WAAO,aAAa,OAAO,IAAI,6BAA6B;AAE9D,MAAI,UAAU,SAAS,GAAG,GAAG;AAC3B,UAAM,IAAI,MACR,6FAA6F,SAAS,IAAI;EAE9G;AAEA,SAAO,GAAG,SAAS,IAAI,6BAA6B;AACtD;AAEO,IAAM,qBAAqB,CAAC,WAA2B;AAC5D,QAAM,mBACJ,OAAO,MAAM,OAAO,WAAW,aAAa,WAAW,UAAU,OAAO,MAAM,OAAO,KAAK,SAAQ;AACpG,SAAO,QAAQ,gBAAgB;AACjC;;;AC3IO,IAAM,sBAAsB,CAAC,YAClC,YAAW,iBAAiB;EAC1B,aAAa,sBAAsB,OAAO;EAC1C,QAAQ,yBAAgB;CACzB;;;ACPH;;;;;;;;;AAcO,IAAM,kBAAkB,eAAO,OAAO;EAC3C,MAAM,eAAO,QAAQ,MAAM;;;;;;;EAO3B,WAAW,eAAO,SAAS,eAAO,MAAM;CACzC;AAYM,IAAM,cAAc,eAAO,MAChC,eAAe;AAOV,IAAM,qBAAqB,eAAO,OAAO,EAAE,KAAK,eAAO,QAAQ,OAAO,eAAO,UAAS,CAAE;AAGzF,IAAW;CAAjB,SAAiBC,oBAAiB;EAChC,MAAa,uBAAuB,eAAO,cAAa,EAAmB,kBAAkB;IAC3F,SAAS,EAAE,MAAM,qBAAa,aAAa,SAAS,eAAO,QAAQ,UAAU,eAAO,OAAM;IAC1F,SAAS,eAAO;IAChB,SAAS;GACV,EAAC;;AAJW,EAAAA,mBAAA,iBAAc;EAM3B,MAAaC,iBAAgB,eAAO,MAAM,cAAc,EAAC;;AAA5C,EAAAD,mBAAA,UAAOC;AACtB,GARiB,sBAAA,oBAAiB,CAAA,EAAA;AAW5B,IAAW;CAAjB,SAAiBC,oBAAiB;EAChC,MAAa,uBAAuB,eAAO,cAAa,EAAmB,kBAAkB;IAC3F,SAAS;MACP,gBAAgB;MAChB,iBAAiB,eAAO;MACxB,SAAS,eAAO;MAChB,UAAU,eAAO;MACjB,iBAAiB,eAAO;MACxB,aAAa,eAAO,YAAY,eAAO,SAAS;;IAElD,SAAS,eAAO;IAChB,SAAS;GACV,EAAC;;AAXW,EAAAA,mBAAA,iBAAc;EAa3B,MAAa,yBAAyB,eAAO,cAAa,EAAqB,oBAAoB;IACjG,SAAS,CAAA;IACT,SAAS;IACT,SAAS;GACV,EAAC;;AAJW,EAAAA,mBAAA,mBAAgB;EAM7B,MAAa,qBAAqB,eAAO,cAAa,EAAiB,gBAAgB;IACrF,SAAS;MACP,OAAO,eAAO,MAAM,uBAAe,UAAU;;IAE/C,SAAS,eAAO;IAChB,SAAS,eAAO,MAAM,iBAAiB,gBAAgB;GACxD,EAAC;;AANW,EAAAA,mBAAA,eAAY;EAQzB,MAAa,mBAAmB,eAAO,cAAa,EAAe,cAAc;IAC/E,SAAS;MACP,QAAQ;;IAEV,SAAS,eAAO,OAAO;MACrB,SAAS,kBAAU;MACnB,cAAc,eAAO;KACtB;IACD,SAAS;GACV,EAAC;;AATW,EAAAA,mBAAA,aAAU;EAWvB,MAAa,eAAe,eAAO,cAAa,EAAW,UAAU;IACnE,SAAS,CAAA;IACT,SAAS,qBAAa;IACtB,SAAS;GACV,EAAC;;AAJW,EAAAA,mBAAA,SAAM;EAMnB,MAAa,uBAAuB,eAAO,cAAa,EAAmB,kBAAkB;IAC3F,SAAS,CAAA;IACT,SAAS,qBAAa;IACtB,SAAS;GACV,EAAC;;AAJW,EAAAA,mBAAA,iBAAc;EAM3B,MAAa,4BAA4B,eAAO,cAAa,EAAwB,uBAAuB;IAC1G,SAAS,CAAA;IACT,SAAS,eAAO,OAAO;MACrB,UAAU,qBAAa;MACvB,kBAAkB;KACnB;IACD,SAAS;GACV,EAAC;;AAPW,EAAAA,mBAAA,sBAAmB;EAShC,MAAa,sBAAsB,eAAO,cAAa,EAAkB,iBAAiB;IACxF,SAAS,CAAA;IACT,SAAS,4BAAoB;IAC7B,SAAS;GACV,EAAC;;AAJW,EAAAA,mBAAA,gBAAa;EAM1B,MAAa,2BAA2B,eAAO,cAAa,EAAuB,sBAAsB;IACvG,SAAS,CAAA;IACT,SAAS,kBAAU;IACnB,SAAS;GACV,EAAC;;AAJW,EAAAA,mBAAA,qBAAkB;EAM/B,MAAa,iBAAiB,eAAO,cAAa,EAAa,YAAY;IACzE,SAAS,CAAA;IACT,SAAS,eAAO;IAChB,SAAS;GACV,EAAC;;AAJW,EAAAA,mBAAA,WAAQ;EAMrB,MAAa,6BAA6B,eAAO,cAAa,EAAyB,wBAAwB;IAC7G,SAAS;MACP,SAASC,aAAS,OAAO;;IAE3B,SAAS,eAAO;IAChB,SAAS;GACV,EAAC;;AANW,EAAAD,mBAAA,uBAAoB;AAQpB,EAAAA,mBAAA,UAAU,eAAO,MAC5B,gBACA,kBACA,cACA,YACA,QACA,gBACA,qBACA,eACA,oBACA,UACA,sBACc,eAAO,gBAAgB;AAGzC,GArGiB,sBAAA,oBAAiB,CAAA,EAAA;AAuG5B,IAAW;CAAjB,SAAiBE,eAAY;EAC3B,MAAa,+CAA+C,eAAO,aAAa,qBAAqB;IACnG,gBAAgB,kBAAkB;GACnC,EAAC;;AAFW,EAAAA,cAAA,yCAAsC;EAInD,MAAa,uBAAuB,eAAO,cAAa,EAAmB,kBAAkB;IAC3F,SAAS;MACP,SAAS,eAAO,MAAM,wCAAwC,eAAO,aAAa,iBAAiB,CAAA,CAAE,CAAC;;;MAGtG,kBAAkB,eAAO,QAAQ,gBAAgB;;IAEnD,SAAS,eAAO;IAChB,SAAS;GACV,EAAC;;AATW,EAAAA,cAAA,iBAAc;EAW3B,MAAa,0BAA0B,eAAO,cAAa,EAAsB,qBAAqB;IACpG,SAAS;MACP,MAAM,qBAAa;;IAErB,SAAS,eAAO;IAChB,SAAS;GACV,EAAC;;AANW,EAAAA,cAAA,oBAAiB;EAQ9B,MAAaH,iBAAgB,eAAO;IAClC;IACA;;IAGA,kBAAkB;IAClB,kBAAkB;IAClB,kBAAkB;IAClB,kBAAkB;IAClB,kBAAkB;IAClB,kBAAkB;IAClB,kBAAkB;IAClB,kBAAkB;IAClB,kBAAkB;IAClB,kBAAkB;IAEJ,eAAO;EAAgB,EACtC;;AAjBY,EAAAG,cAAA,UAAOH;AAkBtB,GA1CiB,iBAAA,eAAY,CAAA,EAAA;",
  "names": ["sql", "value", "mod_exports", "makeSqliteDb", "requestId", "eventName", "syncState", "migrationsReport", "makeSqliteDb", "CreateConnection", "vfs", "VFS", "byteOffset", "vfs", "VFS", "SECTOR_SIZE", "HEADER_MAX_PATH_SIZE", "HEADER_FLAGS_SIZE", "HEADER_DIGEST_SIZE", "HEADER_CORPUS_SIZE", "HEADER_OFFSET_FLAGS", "HEADER_OFFSET_DIGEST", "HEADER_OFFSET_DATA", "PERSISTENT_FILE_TYPES", "dbPointer", "vfs", "HEADER_OFFSET_DATA", "LeaderWorkerOuter", "Request", "LeaderWorkerInner", "mod_exports", "SharedWorker"]
}
